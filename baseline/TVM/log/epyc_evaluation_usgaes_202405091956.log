nohup: ignoring input
----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
Custom sketch rule "SparseDense" added.
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 954	fail_ct: 1094	Time elapsed: 2.17
GA Iter: 0	Max score: 0.9994	Min score: 0.8667	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9833	#Pop: 128	#M+: 1378	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 8.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************strides_mask: num_row = 4096, num_col = 4096, nnz = 264192

==================================================
No: 1	GFLOPS: 909.39 / 909.39	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:1.36, Tstamp:1715255786.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 2	GFLOPS: 699.19 / 909.39	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:1.17, Tstamp:1715255787.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 3	GFLOPS: 354.15 / 909.39	results: MeasureResult(cost:[0.0243], error_no:0, all_cost:0.65, Tstamp:1715255787.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 4	GFLOPS: 212.66 / 909.39	results: MeasureResult(cost:[0.0404], error_no:0, all_cost:1.50, Tstamp:1715255787.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 5	GFLOPS: 262.18 / 909.39	results: MeasureResult(cost:[0.0328], error_no:0, all_cost:1.62, Tstamp:1715255788.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,8)
    compute = ...

==================================================
No: 6	GFLOPS: 640.07 / 909.39	results: MeasureResult(cost:[0.0134], error_no:0, all_cost:1.46, Tstamp:1715255788.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 7	GFLOPS: 876.31 / 909.39	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.00, Tstamp:1715255788.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 8	GFLOPS: 676.56 / 909.39	results: MeasureResult(cost:[0.0127], error_no:0, all_cost:1.24, Tstamp:1715255789.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 9	GFLOPS: 88.30 / 909.39	results: MeasureResult(cost:[0.0973], error_no:0, all_cost:1.23, Tstamp:1715255789.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 10	GFLOPS: 455.05 / 909.39	results: MeasureResult(cost:[0.0189], error_no:0, all_cost:2.01, Tstamp:1715255789.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 11	GFLOPS: 532.10 / 909.39	results: MeasureResult(cost:[0.0161], error_no:0, all_cost:0.80, Tstamp:1715255790.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 12	GFLOPS: 393.98 / 909.39	results: MeasureResult(cost:[0.0218], error_no:0, all_cost:0.71, Tstamp:1715255790.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 13	GFLOPS: 710.09 / 909.39	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:1.26, Tstamp:1715255791.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 14	GFLOPS: 99.83 / 909.39	results: MeasureResult(cost:[0.0860], error_no:0, all_cost:0.82, Tstamp:1715255791.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 15	GFLOPS: 716.43 / 909.39	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.74, Tstamp:1715255791.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 16	GFLOPS: 100.10 / 909.39	results: MeasureResult(cost:[0.0858], error_no:0, all_cost:1.91, Tstamp:1715255792.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,2)
      compute = ...

==================================================
No: 17	GFLOPS: 86.00 / 909.39	results: MeasureResult(cost:[0.0999], error_no:0, all_cost:1.02, Tstamp:1715255792.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 18	GFLOPS: 856.05 / 909.39	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.67, Tstamp:1715255793.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 19	GFLOPS: 551.58 / 909.39	results: MeasureResult(cost:[0.0156], error_no:0, all_cost:0.74, Tstamp:1715255793.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 20	GFLOPS: 401.11 / 909.39	results: MeasureResult(cost:[0.0214], error_no:0, all_cost:0.59, Tstamp:1715255793.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 21	GFLOPS: 1208.93 / 1208.93	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:0.73, Tstamp:1715255794.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 22	GFLOPS: 360.90 / 1208.93	results: MeasureResult(cost:[0.0238], error_no:0, all_cost:1.36, Tstamp:1715255794.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 23	GFLOPS: 700.06 / 1208.93	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:0.78, Tstamp:1715255794.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 16
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 24	GFLOPS: 771.93 / 1208.93	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.67, Tstamp:1715255795.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 25	GFLOPS: 698.48 / 1208.93	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:0.75, Tstamp:1715255795.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 26	GFLOPS: 246.03 / 1208.93	results: MeasureResult(cost:[0.0349], error_no:0, all_cost:0.64, Tstamp:1715255795.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 27	GFLOPS: 98.15 / 1208.93	results: MeasureResult(cost:[0.0875], error_no:0, all_cost:0.84, Tstamp:1715255796.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,2)
      compute = ...

==================================================
No: 28	GFLOPS: 96.40 / 1208.93	results: MeasureResult(cost:[0.0891], error_no:0, all_cost:0.79, Tstamp:1715255796.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 29	GFLOPS: 194.27 / 1208.93	results: MeasureResult(cost:[0.0442], error_no:0, all_cost:0.64, Tstamp:1715255797.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 30	GFLOPS: 245.90 / 1208.93	results: MeasureResult(cost:[0.0349], error_no:0, all_cost:1.51, Tstamp:1715255797.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 31	GFLOPS: 195.75 / 1208.93	results: MeasureResult(cost:[0.0439], error_no:0, all_cost:1.19, Tstamp:1715255797.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 32	GFLOPS: 314.20 / 1208.93	results: MeasureResult(cost:[0.0273], error_no:0, all_cost:0.63, Tstamp:1715255798.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 33	GFLOPS: 86.63 / 1208.93	results: MeasureResult(cost:[0.0992], error_no:0, all_cost:0.89, Tstamp:1715255798.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 34	GFLOPS: 97.77 / 1208.93	results: MeasureResult(cost:[0.0879], error_no:0, all_cost:0.76, Tstamp:1715255799.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 35	GFLOPS: 564.85 / 1208.93	results: MeasureResult(cost:[0.0152], error_no:0, all_cost:0.70, Tstamp:1715255799.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 36	GFLOPS: 1110.10 / 1208.93	results: MeasureResult(cost:[0.0077], error_no:0, all_cost:0.85, Tstamp:1715255799.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 37	GFLOPS: 720.09 / 1208.93	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.87, Tstamp:1715255799.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 38	GFLOPS: 351.78 / 1208.93	results: MeasureResult(cost:[0.0244], error_no:0, all_cost:0.74, Tstamp:1715255800.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 39	GFLOPS: 356.49 / 1208.93	results: MeasureResult(cost:[0.0241], error_no:0, all_cost:0.60, Tstamp:1715255800.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,8)
      compute = ...

==================================================
No: 40	GFLOPS: 652.67 / 1208.93	results: MeasureResult(cost:[0.0132], error_no:0, all_cost:0.47, Tstamp:1715255801.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 41	GFLOPS: 215.18 / 1208.93	results: MeasureResult(cost:[0.0399], error_no:0, all_cost:1.09, Tstamp:1715255801.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 42	GFLOPS: 721.00 / 1208.93	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.64, Tstamp:1715255801.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 43	GFLOPS: 786.53 / 1208.93	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.65, Tstamp:1715255801.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 44	GFLOPS: 819.72 / 1208.93	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:0.82, Tstamp:1715255802.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,256)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 45	GFLOPS: 706.65 / 1208.93	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:0.65, Tstamp:1715255802.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 46	GFLOPS: 887.62 / 1208.93	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.57, Tstamp:1715255802.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 47	GFLOPS: 875.37 / 1208.93	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.69, Tstamp:1715255803.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 48	GFLOPS: 897.97 / 1208.93	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.42, Tstamp:1715255803.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 49	GFLOPS: 654.02 / 1208.93	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:0.47, Tstamp:1715255803.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 50	GFLOPS: 382.77 / 1208.93	results: MeasureResult(cost:[0.0224], error_no:0, all_cost:0.48, Tstamp:1715255804.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 51	GFLOPS: 584.38 / 1208.93	results: MeasureResult(cost:[0.0147], error_no:0, all_cost:0.40, Tstamp:1715255804.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 52	GFLOPS: 614.65 / 1208.93	results: MeasureResult(cost:[0.0140], error_no:0, all_cost:0.39, Tstamp:1715255804.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 53	GFLOPS: 162.19 / 1208.93	results: MeasureResult(cost:[0.0530], error_no:0, all_cost:1.13, Tstamp:1715255805.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 54	GFLOPS: 614.12 / 1208.93	results: MeasureResult(cost:[0.0140], error_no:0, all_cost:0.37, Tstamp:1715255805.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1048576)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for c (0,16)
      compute = ...
  compute = ...

==================================================
No: 55	GFLOPS: 564.82 / 1208.93	results: MeasureResult(cost:[0.0152], error_no:0, all_cost:1.08, Tstamp:1715255805.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 56	GFLOPS: 1060.75 / 1208.93	results: MeasureResult(cost:[0.0081], error_no:0, all_cost:0.34, Tstamp:1715255806.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 57	GFLOPS: 564.23 / 1208.93	results: MeasureResult(cost:[0.0152], error_no:0, all_cost:1.09, Tstamp:1715255806.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,8)
      compute = ...

==================================================
No: 58	GFLOPS: 701.15 / 1208.93	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:0.45, Tstamp:1715255806.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 59	GFLOPS: 899.77 / 1208.93	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.21, Tstamp:1715255806.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 60	GFLOPS: 783.56 / 1208.93	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.37, Tstamp:1715255807.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 61	GFLOPS: 108.41 / 1208.93	results: MeasureResult(cost:[0.0792], error_no:0, all_cost:0.57, Tstamp:1715255807.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 62	GFLOPS: 697.05 / 1208.93	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:0.52, Tstamp:1715255808.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 63	GFLOPS: 179.10 / 1208.93	results: MeasureResult(cost:[0.0480], error_no:0, all_cost:0.47, Tstamp:1715255808.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 64	GFLOPS: 742.45 / 1208.93	results: MeasureResult(cost:[0.0116], error_no:0, all_cost:0.35, Tstamp:1715255808.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,256)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

Time elapsed for measurement: 28.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.98 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 974	fail_ct: 1074	Time elapsed: 2.13
GA Iter: 0	Max score: 1.0000	Min score: 0.8746	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9790	#Pop: 128	#M+: 1375	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 8.34
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 65	GFLOPS: 133.45 / 1208.93	results: MeasureResult(cost:[0.0644], error_no:0, all_cost:2.44, Tstamp:1715255826.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 66	GFLOPS: 1260.20 / 1260.20	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.94, Tstamp:1715255827.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 67	GFLOPS: 175.55 / 1260.20	results: MeasureResult(cost:[0.0489], error_no:0, all_cost:0.89, Tstamp:1715255827.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 68	GFLOPS: 681.68 / 1260.20	results: MeasureResult(cost:[0.0126], error_no:0, all_cost:0.97, Tstamp:1715255827.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 69	GFLOPS: 89.68 / 1260.20	results: MeasureResult(cost:[0.0958], error_no:0, all_cost:1.53, Tstamp:1715255828.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,2)
    compute = ...

==================================================
No: 70	GFLOPS: 393.17 / 1260.20	results: MeasureResult(cost:[0.0218], error_no:0, all_cost:0.74, Tstamp:1715255828.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 71	GFLOPS: 344.74 / 1260.20	results: MeasureResult(cost:[0.0249], error_no:0, all_cost:1.65, Tstamp:1715255829.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,16)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,32)
        compute = ...

==================================================
No: 72	GFLOPS: 1424.25 / 1424.25	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.76, Tstamp:1715255829.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 73	GFLOPS: 93.83 / 1424.25	results: MeasureResult(cost:[0.0915], error_no:0, all_cost:1.06, Tstamp:1715255829.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 74	GFLOPS: 541.46 / 1424.25	results: MeasureResult(cost:[0.0159], error_no:0, all_cost:1.70, Tstamp:1715255830.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 75	GFLOPS: 371.74 / 1424.25	results: MeasureResult(cost:[0.0231], error_no:0, all_cost:1.16, Tstamp:1715255830.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 76	GFLOPS: 797.43 / 1424.25	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.98, Tstamp:1715255831.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 77	GFLOPS: 987.57 / 1424.25	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.79, Tstamp:1715255831.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 78	GFLOPS: 811.05 / 1424.25	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.75, Tstamp:1715255831.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 79	GFLOPS: 762.76 / 1424.25	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.57, Tstamp:1715255831.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,128)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 80	GFLOPS: 785.24 / 1424.25	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.54, Tstamp:1715255832.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 81	GFLOPS: 973.30 / 1424.25	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:0.98, Tstamp:1715255832.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 82	GFLOPS: 918.22 / 1424.25	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:0.81, Tstamp:1715255832.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 83	GFLOPS: 212.13 / 1424.25	results: MeasureResult(cost:[0.0405], error_no:0, all_cost:0.71, Tstamp:1715255833.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 84	GFLOPS: 389.76 / 1424.25	results: MeasureResult(cost:[0.0220], error_no:0, all_cost:1.00, Tstamp:1715255833.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,8)
      compute = ...

==================================================
No: 85	GFLOPS: 588.16 / 1424.25	results: MeasureResult(cost:[0.0146], error_no:0, all_cost:0.78, Tstamp:1715255833.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 86	GFLOPS: 798.44 / 1424.25	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.06, Tstamp:1715255834.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 87	GFLOPS: 352.86 / 1424.25	results: MeasureResult(cost:[0.0243], error_no:0, all_cost:0.82, Tstamp:1715255834.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 88	GFLOPS: 532.08 / 1424.25	results: MeasureResult(cost:[0.0161], error_no:0, all_cost:0.64, Tstamp:1715255834.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 89	GFLOPS: 788.09 / 1424.25	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.66, Tstamp:1715255835.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 90	GFLOPS: 1275.91 / 1424.25	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.54, Tstamp:1715255835.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 91	GFLOPS: 1235.85 / 1424.25	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.68, Tstamp:1715255835.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 92	GFLOPS: 919.27 / 1424.25	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:1.28, Tstamp:1715255836.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 93	GFLOPS: 1257.27 / 1424.25	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.57, Tstamp:1715255836.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 94	GFLOPS: 347.71 / 1424.25	results: MeasureResult(cost:[0.0247], error_no:0, all_cost:0.66, Tstamp:1715255836.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 95	GFLOPS: 752.58 / 1424.25	results: MeasureResult(cost:[0.0114], error_no:0, all_cost:0.72, Tstamp:1715255837.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 96	GFLOPS: 440.87 / 1424.25	results: MeasureResult(cost:[0.0195], error_no:0, all_cost:1.55, Tstamp:1715255837.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 97	GFLOPS: 86.72 / 1424.25	results: MeasureResult(cost:[0.0991], error_no:0, all_cost:0.80, Tstamp:1715255837.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 98	GFLOPS: 173.79 / 1424.25	results: MeasureResult(cost:[0.0494], error_no:0, all_cost:0.89, Tstamp:1715255838.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    for n.1 (0,4)
      compute = ...

==================================================
No: 99	GFLOPS: 1441.98 / 1441.98	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.86, Tstamp:1715255838.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 100	GFLOPS: 411.38 / 1441.98	results: MeasureResult(cost:[0.0209], error_no:0, all_cost:0.79, Tstamp:1715255838.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 101	GFLOPS: 463.52 / 1441.98	results: MeasureResult(cost:[0.0185], error_no:0, all_cost:1.12, Tstamp:1715255839.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,8)
      compute = ...

==================================================
No: 102	GFLOPS: 674.30 / 1441.98	results: MeasureResult(cost:[0.0127], error_no:0, all_cost:0.45, Tstamp:1715255839.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 103	GFLOPS: 799.19 / 1441.98	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.45, Tstamp:1715255839.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 104	GFLOPS: 115.65 / 1441.98	results: MeasureResult(cost:[0.0743], error_no:0, all_cost:0.72, Tstamp:1715255840.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 105	GFLOPS: 302.20 / 1441.98	results: MeasureResult(cost:[0.0284], error_no:0, all_cost:0.57, Tstamp:1715255840.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 106	GFLOPS: 594.65 / 1441.98	results: MeasureResult(cost:[0.0144], error_no:0, all_cost:0.49, Tstamp:1715255840.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 107	GFLOPS: 723.76 / 1441.98	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.39, Tstamp:1715255841.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 108	GFLOPS: 99.66 / 1441.98	results: MeasureResult(cost:[0.0862], error_no:0, all_cost:0.55, Tstamp:1715255841.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,2)
      compute = ...

==================================================
No: 109	GFLOPS: 87.72 / 1441.98	results: MeasureResult(cost:[0.0979], error_no:0, all_cost:0.66, Tstamp:1715255842.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 110	GFLOPS: 177.73 / 1441.98	results: MeasureResult(cost:[0.0483], error_no:0, all_cost:0.49, Tstamp:1715255842.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 111	GFLOPS: 785.48 / 1441.98	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.59, Tstamp:1715255842.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 112	GFLOPS: 613.16 / 1441.98	results: MeasureResult(cost:[0.0140], error_no:0, all_cost:0.39, Tstamp:1715255843.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 113	GFLOPS: 705.47 / 1441.98	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:0.46, Tstamp:1715255843.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 114	GFLOPS: 797.17 / 1441.98	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.29, Tstamp:1715255843.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 115	GFLOPS: 201.66 / 1441.98	results: MeasureResult(cost:[0.0426], error_no:0, all_cost:0.39, Tstamp:1715255844.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 116	GFLOPS: 389.07 / 1441.98	results: MeasureResult(cost:[0.0221], error_no:0, all_cost:0.49, Tstamp:1715255844.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 117	GFLOPS: 1253.26 / 1441.98	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.17, Tstamp:1715255844.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 118	GFLOPS: 712.30 / 1441.98	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.44, Tstamp:1715255845.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 119	GFLOPS: 181.08 / 1441.98	results: MeasureResult(cost:[0.0474], error_no:0, all_cost:0.40, Tstamp:1715255845.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 120	GFLOPS: 369.93 / 1441.98	results: MeasureResult(cost:[0.0232], error_no:0, all_cost:0.96, Tstamp:1715255845.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 121	GFLOPS: 1083.75 / 1441.98	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:0.35, Tstamp:1715255846.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 122	GFLOPS: 745.22 / 1441.98	results: MeasureResult(cost:[0.0115], error_no:0, all_cost:0.56, Tstamp:1715255846.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 123	GFLOPS: 312.08 / 1441.98	results: MeasureResult(cost:[0.0275], error_no:0, all_cost:0.42, Tstamp:1715255846.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 124	GFLOPS: 176.03 / 1441.98	results: MeasureResult(cost:[0.0488], error_no:0, all_cost:0.47, Tstamp:1715255847.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 125	GFLOPS: 176.94 / 1441.98	results: MeasureResult(cost:[0.0485], error_no:0, all_cost:0.49, Tstamp:1715255847.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 126	GFLOPS: 1191.43 / 1441.98	results: MeasureResult(cost:[0.0072], error_no:0, all_cost:0.36, Tstamp:1715255847.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 127	GFLOPS: 702.03 / 1441.98	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:0.62, Tstamp:1715255848.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 128	GFLOPS: 708.18 / 1441.98	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.67, Tstamp:1715255848.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

Time elapsed for measurement: 28.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.84 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 971	fail_ct: 1077	Time elapsed: 2.21
GA Iter: 0	Max score: 1.0090	Min score: 0.6032	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.1126	Min score: 0.7586	#Pop: 128	#M+: 1370	#M-: 67
EvolutionarySearch		#s: 128	Time elapsed: 8.57
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 129	GFLOPS: 1254.99 / 1441.98	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.95, Tstamp:1715255867.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 130	GFLOPS: 1270.20 / 1441.98	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.23, Tstamp:1715255867.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 131	GFLOPS: 1243.95 / 1441.98	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.01, Tstamp:1715255867.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 132	GFLOPS: 1382.83 / 1441.98	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.70, Tstamp:1715255868.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 133	GFLOPS: 1273.67 / 1441.98	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:1.35, Tstamp:1715255868.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 134	GFLOPS: 579.81 / 1441.98	results: MeasureResult(cost:[0.0148], error_no:0, all_cost:0.96, Tstamp:1715255868.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 135	GFLOPS: 1554.96 / 1554.96	results: MeasureResult(cost:[0.0055], error_no:0, all_cost:1.40, Tstamp:1715255869.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 136	GFLOPS: 801.04 / 1554.96	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:2.25, Tstamp:1715255869.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 137	GFLOPS: 1612.94 / 1612.94	results: MeasureResult(cost:[0.0053], error_no:0, all_cost:1.51, Tstamp:1715255869.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 138	GFLOPS: 2013.01 / 2013.01	results: MeasureResult(cost:[0.0043], error_no:0, all_cost:1.78, Tstamp:1715255870.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 139	GFLOPS: 1300.35 / 2013.01	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.94, Tstamp:1715255870.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 140	GFLOPS: 1256.40 / 2013.01	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.60, Tstamp:1715255870.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 141	GFLOPS: 1312.82 / 2013.01	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:1.13, Tstamp:1715255871.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 142	GFLOPS: 1603.54 / 2013.01	results: MeasureResult(cost:[0.0054], error_no:0, all_cost:1.37, Tstamp:1715255871.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 143	GFLOPS: 1249.06 / 2013.01	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.93, Tstamp:1715255872.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 144	GFLOPS: 1477.97 / 2013.01	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:1.31, Tstamp:1715255872.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 145	GFLOPS: 932.31 / 2013.01	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:0.58, Tstamp:1715255872.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 146	GFLOPS: 886.17 / 2013.01	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.94, Tstamp:1715255873.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 147	GFLOPS: 794.61 / 2013.01	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.98, Tstamp:1715255873.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 148	GFLOPS: 1271.70 / 2013.01	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.75, Tstamp:1715255873.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 149	GFLOPS: 1358.12 / 2013.01	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.51, Tstamp:1715255873.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 150	GFLOPS: 1273.69 / 2013.01	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:1.20, Tstamp:1715255874.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 151	GFLOPS: 1474.82 / 2013.01	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:0.65, Tstamp:1715255874.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 152	GFLOPS: 1252.68 / 2013.01	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.71, Tstamp:1715255874.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 153	GFLOPS: 1302.27 / 2013.01	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:1.09, Tstamp:1715255875.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 154	GFLOPS: 1153.79 / 2013.01	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:0.78, Tstamp:1715255875.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 155	GFLOPS: 1277.35 / 2013.01	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.61, Tstamp:1715255875.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 156	GFLOPS: 1231.85 / 2013.01	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.68, Tstamp:1715255876.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 157	GFLOPS: 1403.05 / 2013.01	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.46, Tstamp:1715255876.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 158	GFLOPS: 1302.50 / 2013.01	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.60, Tstamp:1715255876.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 159	GFLOPS: 1399.03 / 2013.01	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.61, Tstamp:1715255877.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 160	GFLOPS: 1271.23 / 2013.01	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.68, Tstamp:1715255877.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 161	GFLOPS: 1315.43 / 2013.01	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.86, Tstamp:1715255877.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 162	GFLOPS: 1272.64 / 2013.01	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.69, Tstamp:1715255878.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 163	GFLOPS: 1275.45 / 2013.01	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.87, Tstamp:1715255878.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 164	GFLOPS: 1402.12 / 2013.01	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.39, Tstamp:1715255878.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 165	GFLOPS: 1518.10 / 2013.01	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:0.85, Tstamp:1715255879.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 166	GFLOPS: 2091.08 / 2091.08	results: MeasureResult(cost:[0.0041], error_no:0, all_cost:1.40, Tstamp:1715255879.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 167	GFLOPS: 1448.13 / 2091.08	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.55, Tstamp:1715255879.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 168	GFLOPS: 1299.51 / 2091.08	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.64, Tstamp:1715255880.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 169	GFLOPS: 1269.69 / 2091.08	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.79, Tstamp:1715255880.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 170	GFLOPS: 1361.14 / 2091.08	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.44, Tstamp:1715255880.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 171	GFLOPS: 1398.42 / 2091.08	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.39, Tstamp:1715255881.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 172	GFLOPS: 1524.28 / 2091.08	results: MeasureResult(cost:[0.0056], error_no:0, all_cost:0.91, Tstamp:1715255881.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 173	GFLOPS: 1534.67 / 2091.08	results: MeasureResult(cost:[0.0056], error_no:0, all_cost:0.84, Tstamp:1715255881.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 174	GFLOPS: 1223.87 / 2091.08	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.64, Tstamp:1715255882.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,64)
    compute = ...

==================================================
No: 175	GFLOPS: 1190.78 / 2091.08	results: MeasureResult(cost:[0.0072], error_no:0, all_cost:0.54, Tstamp:1715255882.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 176	GFLOPS: 1638.49 / 2091.08	results: MeasureResult(cost:[0.0052], error_no:0, all_cost:0.95, Tstamp:1715255882.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 177	GFLOPS: 2042.41 / 2091.08	results: MeasureResult(cost:[0.0042], error_no:0, all_cost:1.40, Tstamp:1715255883.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 178	GFLOPS: 678.87 / 2091.08	results: MeasureResult(cost:[0.0127], error_no:0, all_cost:1.43, Tstamp:1715255883.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 179	GFLOPS: 824.82 / 2091.08	results: MeasureResult(cost:[0.0104], error_no:0, all_cost:1.52, Tstamp:1715255883.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 180	GFLOPS: 754.16 / 2091.08	results: MeasureResult(cost:[0.0114], error_no:0, all_cost:1.54, Tstamp:1715255884.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 181	GFLOPS: 1177.71 / 2091.08	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:1.19, Tstamp:1715255884.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 182	GFLOPS: 1204.47 / 2091.08	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:0.37, Tstamp:1715255884.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 183	GFLOPS: 1227.17 / 2091.08	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.50, Tstamp:1715255884.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,32)
    compute = ...

==================================================
No: 184	GFLOPS: 1518.20 / 2091.08	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:0.69, Tstamp:1715255885.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 185	GFLOPS: 1238.73 / 2091.08	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.44, Tstamp:1715255885.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 186	GFLOPS: 1153.69 / 2091.08	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:1.15, Tstamp:1715255885.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 187	GFLOPS: 1218.17 / 2091.08	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:0.49, Tstamp:1715255886.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 188	GFLOPS: 1334.30 / 2091.08	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:1.09, Tstamp:1715255886.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 189	GFLOPS: 1122.39 / 2091.08	results: MeasureResult(cost:[0.0077], error_no:0, all_cost:1.26, Tstamp:1715255886.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 190	GFLOPS: 768.01 / 2091.08	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.38, Tstamp:1715255886.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 191	GFLOPS: 338.47 / 2091.08	results: MeasureResult(cost:[0.0254], error_no:0, all_cost:0.49, Tstamp:1715255887.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 192	GFLOPS: 970.63 / 2091.08	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:0.34, Tstamp:1715255887.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

Time elapsed for measurement: 27.32 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.76 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 969	fail_ct: 1079	Time elapsed: 2.23
GA Iter: 0	Max score: 0.8665	Min score: 0.3962	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9428	Min score: 0.5405	#Pop: 128	#M+: 1383	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 8.63
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 193	GFLOPS: 2101.59 / 2101.59	results: MeasureResult(cost:[0.0041], error_no:0, all_cost:2.32, Tstamp:1715255906.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 194	GFLOPS: 1975.81 / 2101.59	results: MeasureResult(cost:[0.0043], error_no:0, all_cost:2.23, Tstamp:1715255906.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 195	GFLOPS: 1094.71 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.82, Tstamp:1715255907.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 196	GFLOPS: 2006.96 / 2101.59	results: MeasureResult(cost:[0.0043], error_no:0, all_cost:2.03, Tstamp:1715255907.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 197	GFLOPS: 752.88 / 2101.59	results: MeasureResult(cost:[0.0114], error_no:0, all_cost:1.93, Tstamp:1715255907.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 198	GFLOPS: 2000.40 / 2101.59	results: MeasureResult(cost:[0.0043], error_no:0, all_cost:2.37, Tstamp:1715255908.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 199	GFLOPS: 762.85 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:2.24, Tstamp:1715255908.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 200	GFLOPS: 1943.75 / 2101.59	results: MeasureResult(cost:[0.0044], error_no:0, all_cost:1.72, Tstamp:1715255908.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 201	GFLOPS: 958.71 / 2101.59	results: MeasureResult(cost:[0.0090], error_no:0, all_cost:1.79, Tstamp:1715255908.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 202	GFLOPS: 1635.02 / 2101.59	results: MeasureResult(cost:[0.0053], error_no:0, all_cost:1.74, Tstamp:1715255909.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 203	GFLOPS: 1999.00 / 2101.59	results: MeasureResult(cost:[0.0043], error_no:0, all_cost:1.94, Tstamp:1715255909.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 204	GFLOPS: 1423.98 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.76, Tstamp:1715255909.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 205	GFLOPS: 1531.96 / 2101.59	results: MeasureResult(cost:[0.0056], error_no:0, all_cost:1.12, Tstamp:1715255910.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 206	GFLOPS: 1400.43 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.87, Tstamp:1715255910.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 207	GFLOPS: 797.78 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.81, Tstamp:1715255910.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 208	GFLOPS: 1321.62 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.71, Tstamp:1715255911.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 209	GFLOPS: 704.01 / 2101.59	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:1.36, Tstamp:1715255911.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 210	GFLOPS: 1363.26 / 2101.59	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.53, Tstamp:1715255911.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 211	GFLOPS: 1371.23 / 2101.59	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.70, Tstamp:1715255912.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 212	GFLOPS: 1387.92 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.84, Tstamp:1715255912.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 213	GFLOPS: 1091.40 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:1.05, Tstamp:1715255912.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 214	GFLOPS: 1516.03 / 2101.59	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:0.98, Tstamp:1715255913.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 215	GFLOPS: 1381.84 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.53, Tstamp:1715255913.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 216	GFLOPS: 1419.15 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.97, Tstamp:1715255913.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,32)
    compute = ...

==================================================
No: 217	GFLOPS: 1559.36 / 2101.59	results: MeasureResult(cost:[0.0055], error_no:0, all_cost:1.07, Tstamp:1715255913.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 218	GFLOPS: 1398.22 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.60, Tstamp:1715255914.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 219	GFLOPS: 1411.21 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.37, Tstamp:1715255914.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 220	GFLOPS: 1166.65 / 2101.59	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:0.77, Tstamp:1715255914.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 221	GFLOPS: 755.54 / 2101.59	results: MeasureResult(cost:[0.0114], error_no:0, all_cost:0.99, Tstamp:1715255915.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,64)
    compute = ...

==================================================
No: 222	GFLOPS: 1422.48 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.73, Tstamp:1715255915.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 223	GFLOPS: 1538.88 / 2101.59	results: MeasureResult(cost:[0.0056], error_no:0, all_cost:1.09, Tstamp:1715255915.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 224	GFLOPS: 707.99 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:1.72, Tstamp:1715255916.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 225	GFLOPS: 1386.11 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.46, Tstamp:1715255916.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 226	GFLOPS: 560.10 / 2101.59	results: MeasureResult(cost:[0.0153], error_no:0, all_cost:1.14, Tstamp:1715255916.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 227	GFLOPS: 1290.65 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.86, Tstamp:1715255917.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 228	GFLOPS: 708.71 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.58, Tstamp:1715255917.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 229	GFLOPS: 1228.77 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.42, Tstamp:1715255918.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    compute auto_unroll: 16
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 230	GFLOPS: 1399.25 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.44, Tstamp:1715255918.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 231	GFLOPS: 1236.70 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.51, Tstamp:1715255918.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 232	GFLOPS: 1387.22 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.60, Tstamp:1715255919.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 233	GFLOPS: 1146.04 / 2101.59	results: MeasureResult(cost:[0.0075], error_no:0, all_cost:0.51, Tstamp:1715255919.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 234	GFLOPS: 1308.49 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.56, Tstamp:1715255919.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 235	GFLOPS: 1331.04 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.34, Tstamp:1715255920.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 236	GFLOPS: 1421.09 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.14, Tstamp:1715255920.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 237	GFLOPS: 1247.08 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.41, Tstamp:1715255920.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 238	GFLOPS: 1077.25 / 2101.59	results: MeasureResult(cost:[0.0080], error_no:0, all_cost:0.47, Tstamp:1715255920.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 239	GFLOPS: 1239.26 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.41, Tstamp:1715255921.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 240	GFLOPS: 1452.63 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.73, Tstamp:1715255921.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 241	GFLOPS: 1444.76 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.47, Tstamp:1715255921.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 242	GFLOPS: 1398.59 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.34, Tstamp:1715255922.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 243	GFLOPS: 1234.47 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.32, Tstamp:1715255922.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 244	GFLOPS: 1274.20 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.52, Tstamp:1715255922.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 245	GFLOPS: 1041.90 / 2101.59	results: MeasureResult(cost:[0.0082], error_no:0, all_cost:1.35, Tstamp:1715255923.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 246	GFLOPS: 1795.76 / 2101.59	results: MeasureResult(cost:[0.0048], error_no:0, all_cost:0.41, Tstamp:1715255923.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 247	GFLOPS: 1262.90 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.48, Tstamp:1715255923.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 16
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 248	GFLOPS: 1224.20 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.43, Tstamp:1715255924.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 249	GFLOPS: 1463.20 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.58, Tstamp:1715255924.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 250	GFLOPS: 1382.57 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.55, Tstamp:1715255924.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 251	GFLOPS: 1275.85 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.66, Tstamp:1715255925.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 252	GFLOPS: 1320.22 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.79, Tstamp:1715255925.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 253	GFLOPS: 1259.35 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.43, Tstamp:1715255925.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 254	GFLOPS: 749.60 / 2101.59	results: MeasureResult(cost:[0.0115], error_no:0, all_cost:0.85, Tstamp:1715255926.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 255	GFLOPS: 707.06 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.60, Tstamp:1715255926.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 256	GFLOPS: 793.51 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.40, Tstamp:1715255926.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

Time elapsed for measurement: 27.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.85 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 956	fail_ct: 1092	Time elapsed: 2.18
GA Iter: 0	Max score: 0.6964	Min score: 0.3803	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8857	Min score: 0.5497	#Pop: 128	#M+: 1377	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 8.55
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 257	GFLOPS: 805.22 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:2.52, Tstamp:1715255945.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 258	GFLOPS: 2030.19 / 2101.59	results: MeasureResult(cost:[0.0042], error_no:0, all_cost:2.36, Tstamp:1715255945.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 259	GFLOPS: 1967.68 / 2101.59	results: MeasureResult(cost:[0.0044], error_no:0, all_cost:1.72, Tstamp:1715255946.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 260	GFLOPS: 753.04 / 2101.59	results: MeasureResult(cost:[0.0114], error_no:0, all_cost:2.48, Tstamp:1715255946.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 261	GFLOPS: 566.27 / 2101.59	results: MeasureResult(cost:[0.0152], error_no:0, all_cost:1.18, Tstamp:1715255946.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 262	GFLOPS: 1439.85 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.02, Tstamp:1715255947.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 263	GFLOPS: 815.88 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:2.04, Tstamp:1715255947.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 264	GFLOPS: 1272.33 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.18, Tstamp:1715255947.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 265	GFLOPS: 1249.07 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.19, Tstamp:1715255947.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 266	GFLOPS: 1261.66 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.36, Tstamp:1715255948.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 267	GFLOPS: 1487.90 / 2101.59	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:1.56, Tstamp:1715255948.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 268	GFLOPS: 1425.56 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.03, Tstamp:1715255948.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 269	GFLOPS: 1325.42 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:1.42, Tstamp:1715255949.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 270	GFLOPS: 1431.24 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.82, Tstamp:1715255949.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 271	GFLOPS: 1561.86 / 2101.59	results: MeasureResult(cost:[0.0055], error_no:0, all_cost:1.12, Tstamp:1715255949.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 272	GFLOPS: 1520.23 / 2101.59	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:1.57, Tstamp:1715255950.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 273	GFLOPS: 410.62 / 2101.59	results: MeasureResult(cost:[0.0209], error_no:0, all_cost:1.43, Tstamp:1715255950.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 16
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 274	GFLOPS: 1245.66 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.30, Tstamp:1715255951.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 275	GFLOPS: 1465.39 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:1.19, Tstamp:1715255951.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 276	GFLOPS: 1305.37 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:1.04, Tstamp:1715255951.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 277	GFLOPS: 1277.02 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.95, Tstamp:1715255951.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 278	GFLOPS: 1545.80 / 2101.59	results: MeasureResult(cost:[0.0056], error_no:0, all_cost:1.24, Tstamp:1715255952.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 279	GFLOPS: 1169.54 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:0.80, Tstamp:1715255952.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 280	GFLOPS: 1255.73 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.97, Tstamp:1715255952.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 281	GFLOPS: 1789.02 / 2101.59	results: MeasureResult(cost:[0.0048], error_no:0, all_cost:0.59, Tstamp:1715255953.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 282	GFLOPS: 1237.72 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.71, Tstamp:1715255953.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 283	GFLOPS: 1365.28 / 2101.59	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.53, Tstamp:1715255953.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 284	GFLOPS: 1450.56 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.52, Tstamp:1715255954.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 285	GFLOPS: 1431.91 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.54, Tstamp:1715255954.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 286	GFLOPS: 1455.79 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.95, Tstamp:1715255954.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 287	GFLOPS: 472.68 / 2101.59	results: MeasureResult(cost:[0.0182], error_no:0, all_cost:0.73, Tstamp:1715255955.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 288	GFLOPS: 1409.69 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.63, Tstamp:1715255955.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 289	GFLOPS: 1386.96 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.53, Tstamp:1715255955.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 290	GFLOPS: 1278.62 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.64, Tstamp:1715255956.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 291	GFLOPS: 1241.51 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.74, Tstamp:1715255956.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 292	GFLOPS: 1337.46 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.85, Tstamp:1715255956.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 293	GFLOPS: 760.05 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:1.24, Tstamp:1715255957.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 294	GFLOPS: 1420.25 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.12, Tstamp:1715255957.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 295	GFLOPS: 1466.40 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.59, Tstamp:1715255957.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 296	GFLOPS: 1267.80 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.44, Tstamp:1715255958.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 297	GFLOPS: 1262.63 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.45, Tstamp:1715255958.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 298	GFLOPS: 1131.11 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:0.41, Tstamp:1715255958.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 299	GFLOPS: 1237.76 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.52, Tstamp:1715255958.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 300	GFLOPS: 1426.66 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.37, Tstamp:1715255959.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 301	GFLOPS: 1264.67 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.58, Tstamp:1715255959.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 16
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 302	GFLOPS: 1269.76 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.62, Tstamp:1715255959.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 303	GFLOPS: 1464.60 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.58, Tstamp:1715255960.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 304	GFLOPS: 1336.03 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.57, Tstamp:1715255960.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 305	GFLOPS: 1252.99 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.60, Tstamp:1715255960.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 306	GFLOPS: 1244.96 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.49, Tstamp:1715255960.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 307	GFLOPS: 1449.75 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.71, Tstamp:1715255961.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 308	GFLOPS: 649.76 / 2101.59	results: MeasureResult(cost:[0.0132], error_no:0, all_cost:0.79, Tstamp:1715255961.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 309	GFLOPS: 1257.78 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.53, Tstamp:1715255961.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 310	GFLOPS: 1259.98 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.44, Tstamp:1715255962.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 311	GFLOPS: 1245.85 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.39, Tstamp:1715255962.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 312	GFLOPS: 803.64 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.51, Tstamp:1715255962.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 313	GFLOPS: 1194.06 / 2101.59	results: MeasureResult(cost:[0.0072], error_no:0, all_cost:0.54, Tstamp:1715255962.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 314	GFLOPS: 1228.77 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.44, Tstamp:1715255963.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 315	GFLOPS: 1341.18 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.37, Tstamp:1715255963.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 316	GFLOPS: 1315.00 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.56, Tstamp:1715255963.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 317	GFLOPS: 1257.46 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.58, Tstamp:1715255964.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 318	GFLOPS: 422.50 / 2101.59	results: MeasureResult(cost:[0.0203], error_no:0, all_cost:1.17, Tstamp:1715255964.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 319	GFLOPS: 714.85 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.54, Tstamp:1715255965.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 320	GFLOPS: 183.90 / 2101.59	results: MeasureResult(cost:[0.0467], error_no:0, all_cost:0.46, Tstamp:1715255965.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 26.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.44 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 967	fail_ct: 1081	Time elapsed: 2.20
GA Iter: 0	Max score: 0.7586	Min score: 0.3925	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8016	Min score: 0.5161	#Pop: 128	#M+: 1373	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 8.62
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 321	GFLOPS: 777.35 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:2.64, Tstamp:1715255984.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 322	GFLOPS: 1130.25 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:0.86, Tstamp:1715255985.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 323	GFLOPS: 680.14 / 2101.59	results: MeasureResult(cost:[0.0126], error_no:0, all_cost:2.36, Tstamp:1715255985.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 324	GFLOPS: 686.41 / 2101.59	results: MeasureResult(cost:[0.0125], error_no:0, all_cost:2.05, Tstamp:1715255985.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 325	GFLOPS: 1116.05 / 2101.59	results: MeasureResult(cost:[0.0077], error_no:0, all_cost:0.98, Tstamp:1715255986.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 326	GFLOPS: 1369.85 / 2101.59	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.93, Tstamp:1715255986.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 327	GFLOPS: 817.18 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:2.21, Tstamp:1715255987.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 328	GFLOPS: 1143.18 / 2101.59	results: MeasureResult(cost:[0.0075], error_no:0, all_cost:0.90, Tstamp:1715255987.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 329	GFLOPS: 1410.16 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.64, Tstamp:1715255987.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 330	GFLOPS: 1440.31 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.53, Tstamp:1715255987.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,32)
      compute = ...

==================================================
No: 331	GFLOPS: 1412.01 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.69, Tstamp:1715255988.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 332	GFLOPS: 1447.21 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.65, Tstamp:1715255988.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 333	GFLOPS: 1411.91 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.86, Tstamp:1715255988.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 334	GFLOPS: 721.67 / 2101.59	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:1.82, Tstamp:1715255989.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 335	GFLOPS: 1344.28 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.55, Tstamp:1715255989.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 336	GFLOPS: 1361.04 / 2101.59	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.62, Tstamp:1715255989.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,32)
      compute = ...

==================================================
No: 337	GFLOPS: 1264.80 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.74, Tstamp:1715255990.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 338	GFLOPS: 1423.35 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.64, Tstamp:1715255990.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 339	GFLOPS: 1392.24 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.60, Tstamp:1715255990.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 340	GFLOPS: 1021.34 / 2101.59	results: MeasureResult(cost:[0.0084], error_no:0, all_cost:1.14, Tstamp:1715255990.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 341	GFLOPS: 1272.10 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.99, Tstamp:1715255991.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 342	GFLOPS: 1258.71 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.65, Tstamp:1715255991.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 343	GFLOPS: 1399.58 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.63, Tstamp:1715255991.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 344	GFLOPS: 1250.90 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.67, Tstamp:1715255992.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 345	GFLOPS: 1257.40 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.34, Tstamp:1715255992.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 346	GFLOPS: 1275.20 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.78, Tstamp:1715255992.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 347	GFLOPS: 1313.24 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:1.03, Tstamp:1715255993.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 16
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 348	GFLOPS: 1280.41 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.99, Tstamp:1715255993.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 349	GFLOPS: 1241.22 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.05, Tstamp:1715255993.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 350	GFLOPS: 1233.20 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.75, Tstamp:1715255993.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 351	GFLOPS: 1251.19 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.52, Tstamp:1715255994.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 352	GFLOPS: 1332.07 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:1.03, Tstamp:1715255994.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 353	GFLOPS: 1263.98 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.79, Tstamp:1715255994.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 354	GFLOPS: 1271.08 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.71, Tstamp:1715255995.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 355	GFLOPS: 1310.12 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.80, Tstamp:1715255995.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 356	GFLOPS: 1279.61 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.78, Tstamp:1715255995.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 357	GFLOPS: 1243.76 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.83, Tstamp:1715255995.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 358	GFLOPS: 1305.11 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.91, Tstamp:1715255996.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 359	GFLOPS: 1066.71 / 2101.59	results: MeasureResult(cost:[0.0081], error_no:0, all_cost:0.47, Tstamp:1715255996.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,4096)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 360	GFLOPS: 1243.49 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.63, Tstamp:1715255996.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 361	GFLOPS: 1244.75 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.47, Tstamp:1715255997.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 362	GFLOPS: 1434.28 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.57, Tstamp:1715255997.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 363	GFLOPS: 1272.62 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.85, Tstamp:1715255997.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 364	GFLOPS: 1328.35 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.85, Tstamp:1715255998.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 365	GFLOPS: 1431.69 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.88, Tstamp:1715255998.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 366	GFLOPS: 1234.07 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.04, Tstamp:1715255998.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 367	GFLOPS: 1276.02 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.74, Tstamp:1715255999.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 368	GFLOPS: 1272.38 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.74, Tstamp:1715255999.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 369	GFLOPS: 1247.66 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.40, Tstamp:1715255999.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 370	GFLOPS: 1231.44 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.45, Tstamp:1715255999.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 371	GFLOPS: 1329.88 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.63, Tstamp:1715256000.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 372	GFLOPS: 1263.04 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.64, Tstamp:1715256000.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 373	GFLOPS: 1266.40 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.57, Tstamp:1715256000.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 374	GFLOPS: 1337.58 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.42, Tstamp:1715256001.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,32)
    compute = ...

==================================================
No: 375	GFLOPS: 1459.93 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.89, Tstamp:1715256001.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 376	GFLOPS: 1441.97 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.90, Tstamp:1715256001.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 377	GFLOPS: 1340.13 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.63, Tstamp:1715256002.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 378	GFLOPS: 939.24 / 2101.59	results: MeasureResult(cost:[0.0091], error_no:0, all_cost:1.05, Tstamp:1715256002.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 379	GFLOPS: 1276.68 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.90, Tstamp:1715256002.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 380	GFLOPS: 1250.17 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.49, Tstamp:1715256002.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 381	GFLOPS: 1221.12 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.12, Tstamp:1715256003.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 382	GFLOPS: 112.94 / 2101.59	results: MeasureResult(cost:[0.0761], error_no:0, all_cost:0.81, Tstamp:1715256003.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 383	GFLOPS: 718.05 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.52, Tstamp:1715256003.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 384	GFLOPS: 620.36 / 2101.59	results: MeasureResult(cost:[0.0138], error_no:0, all_cost:0.47, Tstamp:1715256004.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

Time elapsed for measurement: 26.60 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.90 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 954	fail_ct: 1094	Time elapsed: 2.19
GA Iter: 0	Max score: 0.5940	Min score: 0.3773	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7524	Min score: 0.4766	#Pop: 128	#M+: 1381	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 8.66
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 385	GFLOPS: 1506.21 / 2101.59	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:2.06, Tstamp:1715256023.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 386	GFLOPS: 1487.92 / 2101.59	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:1.89, Tstamp:1715256023.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 387	GFLOPS: 1586.71 / 2101.59	results: MeasureResult(cost:[0.0054], error_no:0, all_cost:2.33, Tstamp:1715256023.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 388	GFLOPS: 1393.13 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.94, Tstamp:1715256024.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 389	GFLOPS: 376.48 / 2101.59	results: MeasureResult(cost:[0.0228], error_no:0, all_cost:1.16, Tstamp:1715256024.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 390	GFLOPS: 1470.52 / 2101.59	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:1.11, Tstamp:1715256024.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 391	GFLOPS: 1361.66 / 2101.59	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:1.11, Tstamp:1715256025.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 392	GFLOPS: 1199.34 / 2101.59	results: MeasureResult(cost:[0.0072], error_no:0, all_cost:0.66, Tstamp:1715256025.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 393	GFLOPS: 1276.07 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.99, Tstamp:1715256025.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 394	GFLOPS: 1331.57 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.64, Tstamp:1715256025.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,64)
    compute = ...

==================================================
No: 395	GFLOPS: 1271.02 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.01, Tstamp:1715256026.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 396	GFLOPS: 1234.39 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.13, Tstamp:1715256026.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 397	GFLOPS: 1206.94 / 2101.59	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:1.26, Tstamp:1715256026.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,128)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 398	GFLOPS: 1263.54 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.12, Tstamp:1715256026.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 399	GFLOPS: 1396.69 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.77, Tstamp:1715256027.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 400	GFLOPS: 1267.30 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.02, Tstamp:1715256027.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 401	GFLOPS: 1336.54 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.54, Tstamp:1715256027.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 402	GFLOPS: 1271.64 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.24, Tstamp:1715256028.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 403	GFLOPS: 1249.18 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.08, Tstamp:1715256028.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 404	GFLOPS: 1127.65 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:1.33, Tstamp:1715256028.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 405	GFLOPS: 1135.16 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:1.44, Tstamp:1715256028.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 406	GFLOPS: 1290.98 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:1.21, Tstamp:1715256029.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 407	GFLOPS: 808.51 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.74, Tstamp:1715256029.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,32)
        compute = ...

==================================================
No: 408	GFLOPS: 1205.81 / 2101.59	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:0.77, Tstamp:1715256029.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,32)
    compute = ...

==================================================
No: 409	GFLOPS: 1321.27 / 2101.59	results: MeasureResult(cost:[0.0065], error_no:0, all_cost:0.96, Tstamp:1715256030.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 410	GFLOPS: 1493.02 / 2101.59	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:1.07, Tstamp:1715256030.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 411	GFLOPS: 1231.42 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.69, Tstamp:1715256030.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 412	GFLOPS: 577.98 / 2101.59	results: MeasureResult(cost:[0.0149], error_no:0, all_cost:1.08, Tstamp:1715256031.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 413	GFLOPS: 696.23 / 2101.59	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:1.99, Tstamp:1715256031.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,32)
        compute = ...

==================================================
No: 414	GFLOPS: 1426.94 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.51, Tstamp:1715256031.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 415	GFLOPS: 1097.96 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:0.62, Tstamp:1715256032.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 416	GFLOPS: 1250.51 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.41, Tstamp:1715256032.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 417	GFLOPS: 1240.14 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.68, Tstamp:1715256032.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 418	GFLOPS: 1138.51 / 2101.59	results: MeasureResult(cost:[0.0075], error_no:0, all_cost:1.37, Tstamp:1715256032.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 419	GFLOPS: 734.11 / 2101.59	results: MeasureResult(cost:[0.0117], error_no:0, all_cost:1.75, Tstamp:1715256033.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 420	GFLOPS: 1181.03 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:0.54, Tstamp:1715256033.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,64)
    compute = ...

==================================================
No: 421	GFLOPS: 1107.46 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:0.65, Tstamp:1715256033.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,2)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 422	GFLOPS: 1424.31 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.60, Tstamp:1715256034.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 423	GFLOPS: 818.29 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:1.07, Tstamp:1715256034.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 424	GFLOPS: 1124.56 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:0.52, Tstamp:1715256034.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 425	GFLOPS: 1459.08 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.93, Tstamp:1715256035.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 426	GFLOPS: 1230.45 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.53, Tstamp:1715256035.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 427	GFLOPS: 352.57 / 2101.59	results: MeasureResult(cost:[0.0244], error_no:0, all_cost:0.79, Tstamp:1715256035.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 428	GFLOPS: 1223.84 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.47, Tstamp:1715256036.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    compute auto_unroll: 16
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,32)
      compute = ...

==================================================
No: 429	GFLOPS: 987.65 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.52, Tstamp:1715256036.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 430	GFLOPS: 1413.90 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.02, Tstamp:1715256036.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 431	GFLOPS: 1159.41 / 2101.59	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:1.22, Tstamp:1715256036.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 432	GFLOPS: 1196.60 / 2101.59	results: MeasureResult(cost:[0.0072], error_no:0, all_cost:0.38, Tstamp:1715256037.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 433	GFLOPS: 1289.78 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.34, Tstamp:1715256037.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 434	GFLOPS: 1141.87 / 2101.59	results: MeasureResult(cost:[0.0075], error_no:0, all_cost:0.72, Tstamp:1715256037.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,2)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 435	GFLOPS: 810.91 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.70, Tstamp:1715256038.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 436	GFLOPS: 1408.74 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.89, Tstamp:1715256038.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 437	GFLOPS: 1171.25 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:1.14, Tstamp:1715256038.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 438	GFLOPS: 973.79 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:1.19, Tstamp:1715256039.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 439	GFLOPS: 1448.96 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:1.03, Tstamp:1715256039.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 440	GFLOPS: 1415.43 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:0.94, Tstamp:1715256039.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 441	GFLOPS: 1077.30 / 2101.59	results: MeasureResult(cost:[0.0080], error_no:0, all_cost:0.38, Tstamp:1715256040.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 442	GFLOPS: 1504.81 / 2101.59	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:0.97, Tstamp:1715256040.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 443	GFLOPS: 1135.28 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:0.39, Tstamp:1715256040.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,4096)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 444	GFLOPS: 862.65 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.18, Tstamp:1715256041.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 445	GFLOPS: 1146.89 / 2101.59	results: MeasureResult(cost:[0.0075], error_no:0, all_cost:1.63, Tstamp:1715256041.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 446	GFLOPS: 376.03 / 2101.59	results: MeasureResult(cost:[0.0228], error_no:0, all_cost:1.44, Tstamp:1715256041.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 447	GFLOPS: 646.61 / 2101.59	results: MeasureResult(cost:[0.0133], error_no:0, all_cost:0.43, Tstamp:1715256042.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 448	GFLOPS: 225.26 / 2101.59	results: MeasureResult(cost:[0.0381], error_no:0, all_cost:0.40, Tstamp:1715256042.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 26.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.92 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 958	fail_ct: 1090	Time elapsed: 2.27
GA Iter: 0	Max score: 0.6627	Min score: 0.3804	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6774	Min score: 0.4713	#Pop: 128	#M+: 1381	#M-: 79
EvolutionarySearch		#s: 128	Time elapsed: 8.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 449	GFLOPS: 1436.16 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.16, Tstamp:1715256061.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 450	GFLOPS: 1439.62 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:2.00, Tstamp:1715256061.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 451	GFLOPS: 1400.28 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.26, Tstamp:1715256061.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 452	GFLOPS: 1242.92 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:1.91, Tstamp:1715256062.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 453	GFLOPS: 1448.87 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:1.87, Tstamp:1715256062.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 454	GFLOPS: 1114.80 / 2101.59	results: MeasureResult(cost:[0.0077], error_no:0, all_cost:1.63, Tstamp:1715256062.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 455	GFLOPS: 1397.17 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.71, Tstamp:1715256063.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 456	GFLOPS: 1254.55 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:1.59, Tstamp:1715256063.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 457	GFLOPS: 1439.64 / 2101.59	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.66, Tstamp:1715256063.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 458	GFLOPS: 1408.95 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.44, Tstamp:1715256064.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 459	GFLOPS: 593.74 / 2101.59	results: MeasureResult(cost:[0.0145], error_no:0, all_cost:2.03, Tstamp:1715256064.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,32)
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 460	GFLOPS: 1449.44 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:1.49, Tstamp:1715256064.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 461	GFLOPS: 1398.94 / 2101.59	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.24, Tstamp:1715256065.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 462	GFLOPS: 1283.56 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.95, Tstamp:1715256065.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 463	GFLOPS: 1448.86 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.82, Tstamp:1715256065.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 464	GFLOPS: 1379.44 / 2101.59	results: MeasureResult(cost:[0.0062], error_no:0, all_cost:0.61, Tstamp:1715256066.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 465	GFLOPS: 922.49 / 2101.59	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:1.58, Tstamp:1715256066.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 466	GFLOPS: 889.42 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.21, Tstamp:1715256066.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 467	GFLOPS: 1176.15 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:0.75, Tstamp:1715256066.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 468	GFLOPS: 977.91 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:1.08, Tstamp:1715256067.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 469	GFLOPS: 617.37 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.52, Tstamp:1715256067.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,64)
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 470	GFLOPS: 617.25 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.70, Tstamp:1715256067.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 471	GFLOPS: 1093.54 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:1.46, Tstamp:1715256068.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 472	GFLOPS: 1451.23 / 2101.59	results: MeasureResult(cost:[0.0059], error_no:0, all_cost:0.85, Tstamp:1715256068.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,32)
    compute = ...

==================================================
No: 473	GFLOPS: 1337.11 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.49, Tstamp:1715256068.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,64)
    compute = ...

==================================================
No: 474	GFLOPS: 1344.19 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.71, Tstamp:1715256069.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,32)
    compute = ...

==================================================
No: 475	GFLOPS: 866.45 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:1.41, Tstamp:1715256069.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 476	GFLOPS: 974.16 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:1.43, Tstamp:1715256069.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 477	GFLOPS: 1094.21 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:1.09, Tstamp:1715256070.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 478	GFLOPS: 877.42 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.34, Tstamp:1715256070.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 479	GFLOPS: 926.06 / 2101.59	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:1.45, Tstamp:1715256070.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 480	GFLOPS: 931.49 / 2101.59	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:1.52, Tstamp:1715256071.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 481	GFLOPS: 901.50 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.98, Tstamp:1715256071.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 482	GFLOPS: 916.95 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:1.43, Tstamp:1715256071.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 483	GFLOPS: 1137.76 / 2101.59	results: MeasureResult(cost:[0.0075], error_no:0, all_cost:1.34, Tstamp:1715256071.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 484	GFLOPS: 1099.22 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.32, Tstamp:1715256072.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 485	GFLOPS: 1130.63 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:1.26, Tstamp:1715256072.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 486	GFLOPS: 855.16 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.42, Tstamp:1715256072.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 487	GFLOPS: 1090.69 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:1.36, Tstamp:1715256072.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 488	GFLOPS: 1130.34 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:1.16, Tstamp:1715256073.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 489	GFLOPS: 1348.06 / 2101.59	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.45, Tstamp:1715256073.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 490	GFLOPS: 935.80 / 2101.59	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:1.31, Tstamp:1715256073.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 491	GFLOPS: 932.24 / 2101.59	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:1.18, Tstamp:1715256074.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 492	GFLOPS: 860.36 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.28, Tstamp:1715256074.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 493	GFLOPS: 1170.25 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:1.13, Tstamp:1715256074.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 494	GFLOPS: 983.29 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.82, Tstamp:1715256074.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 495	GFLOPS: 1231.38 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.41, Tstamp:1715256075.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 496	GFLOPS: 893.83 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.24, Tstamp:1715256075.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 497	GFLOPS: 1079.72 / 2101.59	results: MeasureResult(cost:[0.0080], error_no:0, all_cost:0.98, Tstamp:1715256075.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 498	GFLOPS: 733.58 / 2101.59	results: MeasureResult(cost:[0.0117], error_no:0, all_cost:1.33, Tstamp:1715256076.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 499	GFLOPS: 1277.74 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.55, Tstamp:1715256076.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 500	GFLOPS: 911.78 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:0.67, Tstamp:1715256076.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 501	GFLOPS: 1280.23 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:0.53, Tstamp:1715256076.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 502	GFLOPS: 1101.70 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.08, Tstamp:1715256077.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 503	GFLOPS: 1085.65 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:0.99, Tstamp:1715256077.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 504	GFLOPS: 872.50 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.13, Tstamp:1715256077.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 505	GFLOPS: 1036.92 / 2101.59	results: MeasureResult(cost:[0.0083], error_no:0, all_cost:0.53, Tstamp:1715256078.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,2)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 506	GFLOPS: 957.20 / 2101.59	results: MeasureResult(cost:[0.0090], error_no:0, all_cost:0.72, Tstamp:1715256078.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 507	GFLOPS: 1175.69 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:0.39, Tstamp:1715256078.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 508	GFLOPS: 1300.40 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.79, Tstamp:1715256079.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 509	GFLOPS: 894.43 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.01, Tstamp:1715256079.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 510	GFLOPS: 851.44 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.68, Tstamp:1715256079.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 511	GFLOPS: 608.77 / 2101.59	results: MeasureResult(cost:[0.0141], error_no:0, all_cost:0.41, Tstamp:1715256080.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 512	GFLOPS: 460.52 / 2101.59	results: MeasureResult(cost:[0.0187], error_no:0, all_cost:0.70, Tstamp:1715256080.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 25.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.80 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 973	fail_ct: 1075	Time elapsed: 2.22
GA Iter: 0	Max score: 0.6179	Min score: 0.3769	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6179	Min score: 0.4354	#Pop: 128	#M+: 1379	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 8.78
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 513	GFLOPS: 1298.11 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:1.11, Tstamp:1715256099.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 514	GFLOPS: 1227.96 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.02, Tstamp:1715256099.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,64)
    compute = ...

==================================================
No: 515	GFLOPS: 1259.04 / 2101.59	results: MeasureResult(cost:[0.0068], error_no:0, all_cost:0.99, Tstamp:1715256100.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 516	GFLOPS: 819.71 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:0.92, Tstamp:1715256100.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 517	GFLOPS: 1219.27 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.94, Tstamp:1715256101.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,64)
    compute = ...

==================================================
No: 518	GFLOPS: 1180.92 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:1.04, Tstamp:1715256101.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,32)
    compute = ...

==================================================
No: 519	GFLOPS: 1235.34 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:1.08, Tstamp:1715256101.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,32)
    compute = ...

==================================================
No: 520	GFLOPS: 1287.35 / 2101.59	results: MeasureResult(cost:[0.0067], error_no:0, all_cost:1.20, Tstamp:1715256102.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 521	GFLOPS: 884.46 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.96, Tstamp:1715256102.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 522	GFLOPS: 1234.70 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.99, Tstamp:1715256102.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 523	GFLOPS: 762.59 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:1.26, Tstamp:1715256102.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 524	GFLOPS: 1249.78 / 2101.59	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.96, Tstamp:1715256103.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 525	GFLOPS: 1153.13 / 2101.59	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:0.87, Tstamp:1715256103.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 526	GFLOPS: 1102.21 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.62, Tstamp:1715256103.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 527	GFLOPS: 1137.17 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:1.71, Tstamp:1715256104.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 528	GFLOPS: 1122.38 / 2101.59	results: MeasureResult(cost:[0.0077], error_no:0, all_cost:0.77, Tstamp:1715256104.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,2)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 529	GFLOPS: 1121.07 / 2101.59	results: MeasureResult(cost:[0.0077], error_no:0, all_cost:1.72, Tstamp:1715256104.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 530	GFLOPS: 875.48 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.66, Tstamp:1715256104.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 531	GFLOPS: 1212.02 / 2101.59	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:0.79, Tstamp:1715256105.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,256)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 532	GFLOPS: 1005.06 / 2101.59	results: MeasureResult(cost:[0.0085], error_no:0, all_cost:0.86, Tstamp:1715256105.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 533	GFLOPS: 979.86 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:0.55, Tstamp:1715256105.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 534	GFLOPS: 1060.30 / 2101.59	results: MeasureResult(cost:[0.0081], error_no:0, all_cost:0.59, Tstamp:1715256106.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,4096)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 535	GFLOPS: 968.99 / 2101.59	results: MeasureResult(cost:[0.0089], error_no:0, all_cost:0.59, Tstamp:1715256106.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 536	GFLOPS: 671.01 / 2101.59	results: MeasureResult(cost:[0.0128], error_no:0, all_cost:0.57, Tstamp:1715256106.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 537	GFLOPS: 1178.91 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:0.75, Tstamp:1715256106.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 538	GFLOPS: 1107.62 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.19, Tstamp:1715256107.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 539	GFLOPS: 1496.73 / 2101.59	results: MeasureResult(cost:[0.0057], error_no:0, all_cost:1.14, Tstamp:1715256107.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,64)
    compute = ...

==================================================
No: 540	GFLOPS: 1106.96 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:0.38, Tstamp:1715256107.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 541	GFLOPS: 1094.84 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:0.85, Tstamp:1715256108.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 542	GFLOPS: 988.55 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:1.63, Tstamp:1715256108.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 543	GFLOPS: 654.09 / 2101.59	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:0.82, Tstamp:1715256108.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 544	GFLOPS: 1304.36 / 2101.59	results: MeasureResult(cost:[0.0066], error_no:0, all_cost:0.59, Tstamp:1715256108.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 545	GFLOPS: 1219.93 / 2101.59	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.50, Tstamp:1715256109.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,128)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,32)
      compute = ...

==================================================
No: 546	GFLOPS: 1103.42 / 2101.59	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.18, Tstamp:1715256109.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 547	GFLOPS: 981.44 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:0.41, Tstamp:1715256109.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 548	GFLOPS: 855.68 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.23, Tstamp:1715256109.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 549	GFLOPS: 976.84 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:1.57, Tstamp:1715256110.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 550	GFLOPS: 953.44 / 2101.59	results: MeasureResult(cost:[0.0090], error_no:0, all_cost:1.51, Tstamp:1715256110.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 551	GFLOPS: 716.42 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:1.31, Tstamp:1715256110.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 552	GFLOPS: 582.08 / 2101.59	results: MeasureResult(cost:[0.0148], error_no:0, all_cost:0.42, Tstamp:1715256111.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 553	GFLOPS: 827.60 / 2101.59	results: MeasureResult(cost:[0.0104], error_no:0, all_cost:1.07, Tstamp:1715256111.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 554	GFLOPS: 578.00 / 2101.59	results: MeasureResult(cost:[0.0149], error_no:0, all_cost:0.40, Tstamp:1715256111.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 555	GFLOPS: 903.27 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.24, Tstamp:1715256111.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 556	GFLOPS: 900.03 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.68, Tstamp:1715256112.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 557	GFLOPS: 551.49 / 2101.59	results: MeasureResult(cost:[0.0156], error_no:0, all_cost:0.47, Tstamp:1715256112.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 558	GFLOPS: 571.08 / 2101.59	results: MeasureResult(cost:[0.0150], error_no:0, all_cost:0.46, Tstamp:1715256112.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 559	GFLOPS: 898.85 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.75, Tstamp:1715256113.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 560	GFLOPS: 894.74 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.55, Tstamp:1715256113.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 561	GFLOPS: 981.71 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.48, Tstamp:1715256113.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 562	GFLOPS: 897.51 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.63, Tstamp:1715256113.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 563	GFLOPS: 887.89 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.56, Tstamp:1715256114.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 564	GFLOPS: 971.26 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:0.38, Tstamp:1715256114.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 565	GFLOPS: 858.59 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:0.66, Tstamp:1715256114.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,256)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 566	GFLOPS: 846.87 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.36, Tstamp:1715256115.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 567	GFLOPS: 961.63 / 2101.59	results: MeasureResult(cost:[0.0089], error_no:0, all_cost:0.39, Tstamp:1715256115.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 568	GFLOPS: 812.82 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.06, Tstamp:1715256115.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 569	GFLOPS: 821.40 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:0.67, Tstamp:1715256115.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,256)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 570	GFLOPS: 895.93 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.44, Tstamp:1715256116.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 571	GFLOPS: 867.07 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:0.72, Tstamp:1715256116.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 572	GFLOPS: 921.58 / 2101.59	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:0.70, Tstamp:1715256116.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 573	GFLOPS: 883.21 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.66, Tstamp:1715256116.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 574	GFLOPS: 844.80 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:1.17, Tstamp:1715256117.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 575	GFLOPS: 107.70 / 2101.59	results: MeasureResult(cost:[0.0798], error_no:0, all_cost:1.19, Tstamp:1715256117.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 576	GFLOPS: 804.52 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.03, Tstamp:1715256117.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

Time elapsed for measurement: 25.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.08 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 963	fail_ct: 1085	Time elapsed: 2.23
GA Iter: 0	Max score: 0.5233	Min score: 0.3674	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.5648	Min score: 0.4154	#Pop: 128	#M+: 1389	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 8.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 577	GFLOPS: 787.83 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.91, Tstamp:1715256137.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 578	GFLOPS: 1132.23 / 2101.59	results: MeasureResult(cost:[0.0076], error_no:0, all_cost:2.19, Tstamp:1715256137.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 579	GFLOPS: 557.71 / 2101.59	results: MeasureResult(cost:[0.0154], error_no:0, all_cost:2.58, Tstamp:1715256137.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 580	GFLOPS: 1179.75 / 2101.59	results: MeasureResult(cost:[0.0073], error_no:0, all_cost:1.45, Tstamp:1715256138.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 581	GFLOPS: 545.41 / 2101.59	results: MeasureResult(cost:[0.0157], error_no:0, all_cost:0.96, Tstamp:1715256138.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 582	GFLOPS: 594.22 / 2101.59	results: MeasureResult(cost:[0.0145], error_no:0, all_cost:0.77, Tstamp:1715256138.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,32)
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 583	GFLOPS: 991.80 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.75, Tstamp:1715256139.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 584	GFLOPS: 756.05 / 2101.59	results: MeasureResult(cost:[0.0114], error_no:0, all_cost:0.77, Tstamp:1715256139.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 585	GFLOPS: 747.46 / 2101.59	results: MeasureResult(cost:[0.0115], error_no:0, all_cost:0.88, Tstamp:1715256139.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 586	GFLOPS: 984.52 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.82, Tstamp:1715256140.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 587	GFLOPS: 991.48 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.84, Tstamp:1715256140.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 588	GFLOPS: 812.69 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.73, Tstamp:1715256140.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 589	GFLOPS: 564.53 / 2101.59	results: MeasureResult(cost:[0.0152], error_no:0, all_cost:0.77, Tstamp:1715256140.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 590	GFLOPS: 553.79 / 2101.59	results: MeasureResult(cost:[0.0155], error_no:0, all_cost:0.85, Tstamp:1715256141.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 591	GFLOPS: 1004.14 / 2101.59	results: MeasureResult(cost:[0.0086], error_no:0, all_cost:0.76, Tstamp:1715256141.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 592	GFLOPS: 1004.98 / 2101.59	results: MeasureResult(cost:[0.0085], error_no:0, all_cost:1.12, Tstamp:1715256142.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 593	GFLOPS: 851.42 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:1.56, Tstamp:1715256142.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 594	GFLOPS: 943.08 / 2101.59	results: MeasureResult(cost:[0.0091], error_no:0, all_cost:1.35, Tstamp:1715256142.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 595	GFLOPS: 856.31 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.41, Tstamp:1715256142.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 596	GFLOPS: 994.66 / 2101.59	results: MeasureResult(cost:[0.0086], error_no:0, all_cost:0.81, Tstamp:1715256143.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 597	GFLOPS: 964.60 / 2101.59	results: MeasureResult(cost:[0.0089], error_no:0, all_cost:0.69, Tstamp:1715256143.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 598	GFLOPS: 906.71 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.29, Tstamp:1715256143.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 599	GFLOPS: 994.57 / 2101.59	results: MeasureResult(cost:[0.0086], error_no:0, all_cost:0.50, Tstamp:1715256144.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 600	GFLOPS: 882.01 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.53, Tstamp:1715256144.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 601	GFLOPS: 541.62 / 2101.59	results: MeasureResult(cost:[0.0159], error_no:0, all_cost:0.60, Tstamp:1715256144.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 602	GFLOPS: 937.27 / 2101.59	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:1.07, Tstamp:1715256145.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 603	GFLOPS: 909.34 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:1.07, Tstamp:1715256145.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 604	GFLOPS: 985.13 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.65, Tstamp:1715256145.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 605	GFLOPS: 989.10 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.64, Tstamp:1715256145.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 606	GFLOPS: 986.09 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.46, Tstamp:1715256146.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 607	GFLOPS: 847.76 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.55, Tstamp:1715256146.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 608	GFLOPS: 976.16 / 2101.59	results: MeasureResult(cost:[0.0088], error_no:0, all_cost:0.67, Tstamp:1715256146.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 609	GFLOPS: 790.87 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:1.15, Tstamp:1715256147.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 610	GFLOPS: 1066.49 / 2101.59	results: MeasureResult(cost:[0.0081], error_no:0, all_cost:1.57, Tstamp:1715256147.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,32)
        compute = ...

==================================================
No: 611	GFLOPS: 1004.63 / 2101.59	results: MeasureResult(cost:[0.0086], error_no:0, all_cost:1.14, Tstamp:1715256147.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 612	GFLOPS: 896.87 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.88, Tstamp:1715256148.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 613	GFLOPS: 996.05 / 2101.59	results: MeasureResult(cost:[0.0086], error_no:0, all_cost:0.40, Tstamp:1715256148.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 614	GFLOPS: 872.17 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.81, Tstamp:1715256148.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 615	GFLOPS: 787.02 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:1.20, Tstamp:1715256148.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 616	GFLOPS: 814.01 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.06, Tstamp:1715256149.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 617	GFLOPS: 1030.04 / 2101.59	results: MeasureResult(cost:[0.0083], error_no:0, all_cost:0.55, Tstamp:1715256149.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 618	GFLOPS: 985.59 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.39, Tstamp:1715256149.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 619	GFLOPS: 983.56 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.35, Tstamp:1715256150.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 620	GFLOPS: 411.05 / 2101.59	results: MeasureResult(cost:[0.0209], error_no:0, all_cost:0.43, Tstamp:1715256150.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 621	GFLOPS: 922.60 / 2101.59	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:0.66, Tstamp:1715256150.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 622	GFLOPS: 986.88 / 2101.59	results: MeasureResult(cost:[0.0087], error_no:0, all_cost:0.52, Tstamp:1715256151.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 623	GFLOPS: 885.57 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.04, Tstamp:1715256151.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 624	GFLOPS: 798.63 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.26, Tstamp:1715256151.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 625	GFLOPS: 178.40 / 2101.59	results: MeasureResult(cost:[0.0482], error_no:0, all_cost:1.13, Tstamp:1715256152.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,4)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 626	GFLOPS: 827.73 / 2101.59	results: MeasureResult(cost:[0.0104], error_no:0, all_cost:0.96, Tstamp:1715256152.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 627	GFLOPS: 903.91 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.68, Tstamp:1715256152.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 628	GFLOPS: 876.13 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.53, Tstamp:1715256152.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 629	GFLOPS: 825.08 / 2101.59	results: MeasureResult(cost:[0.0104], error_no:0, all_cost:0.64, Tstamp:1715256153.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 630	GFLOPS: 892.80 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.44, Tstamp:1715256153.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 631	GFLOPS: 900.39 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.54, Tstamp:1715256153.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 632	GFLOPS: 894.14 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.42, Tstamp:1715256154.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 633	GFLOPS: 876.63 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.41, Tstamp:1715256154.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 634	GFLOPS: 876.00 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.64, Tstamp:1715256154.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 635	GFLOPS: 901.76 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.91, Tstamp:1715256154.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 636	GFLOPS: 933.66 / 2101.59	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:1.02, Tstamp:1715256155.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 637	GFLOPS: 857.88 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.15, Tstamp:1715256155.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 638	GFLOPS: 894.57 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.12, Tstamp:1715256155.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 639	GFLOPS: 557.96 / 2101.59	results: MeasureResult(cost:[0.0154], error_no:0, all_cost:0.87, Tstamp:1715256156.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 640	GFLOPS: 706.19 / 2101.59	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:0.56, Tstamp:1715256156.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

Time elapsed for measurement: 26.11 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.97 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 943	fail_ct: 1105	Time elapsed: 2.21
GA Iter: 0	Max score: 0.4659	Min score: 0.3625	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.4825	Min score: 0.3984	#Pop: 128	#M+: 1373	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 8.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 641	GFLOPS: 600.93 / 2101.59	results: MeasureResult(cost:[0.0143], error_no:0, all_cost:0.83, Tstamp:1715256175.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 642	GFLOPS: 557.39 / 2101.59	results: MeasureResult(cost:[0.0154], error_no:0, all_cost:0.63, Tstamp:1715256175.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,64)
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 643	GFLOPS: 789.03 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:1.35, Tstamp:1715256176.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 644	GFLOPS: 896.94 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.43, Tstamp:1715256176.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 645	GFLOPS: 807.40 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.11, Tstamp:1715256176.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 646	GFLOPS: 884.68 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.30, Tstamp:1715256176.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 647	GFLOPS: 889.73 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.10, Tstamp:1715256177.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 648	GFLOPS: 859.29 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.19, Tstamp:1715256177.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 649	GFLOPS: 882.09 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.09, Tstamp:1715256177.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 650	GFLOPS: 888.33 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.17, Tstamp:1715256178.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 651	GFLOPS: 881.34 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.04, Tstamp:1715256178.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 652	GFLOPS: 892.31 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.08, Tstamp:1715256178.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 653	GFLOPS: 887.79 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.82, Tstamp:1715256178.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 654	GFLOPS: 908.87 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.01, Tstamp:1715256179.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 655	GFLOPS: 906.64 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.98, Tstamp:1715256179.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 656	GFLOPS: 605.75 / 2101.59	results: MeasureResult(cost:[0.0142], error_no:0, all_cost:0.60, Tstamp:1715256180.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,4096)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 657	GFLOPS: 862.75 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:2.03, Tstamp:1715256180.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,128)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 658	GFLOPS: 895.17 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.80, Tstamp:1715256180.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 659	GFLOPS: 1061.12 / 2101.59	results: MeasureResult(cost:[0.0081], error_no:0, all_cost:1.85, Tstamp:1715256181.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,64)
        compute = ...

==================================================
No: 660	GFLOPS: 317.77 / 2101.59	results: MeasureResult(cost:[0.0270], error_no:0, all_cost:0.66, Tstamp:1715256181.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 661	GFLOPS: 880.15 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.95, Tstamp:1715256181.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 662	GFLOPS: 901.04 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.75, Tstamp:1715256181.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 663	GFLOPS: 861.03 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.00, Tstamp:1715256182.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 664	GFLOPS: 897.39 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.96, Tstamp:1715256182.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 665	GFLOPS: 888.43 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.82, Tstamp:1715256182.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 666	GFLOPS: 879.84 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:0.44, Tstamp:1715256183.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 667	GFLOPS: 870.53 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:1.14, Tstamp:1715256183.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 668	GFLOPS: 1087.67 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:0.78, Tstamp:1715256183.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 669	GFLOPS: 904.11 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.54, Tstamp:1715256183.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 670	GFLOPS: 866.15 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:0.80, Tstamp:1715256184.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 671	GFLOPS: 843.65 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:1.17, Tstamp:1715256184.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 672	GFLOPS: 713.80 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.70, Tstamp:1715256184.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 673	GFLOPS: 884.53 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.60, Tstamp:1715256185.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 674	GFLOPS: 852.72 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.44, Tstamp:1715256185.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 675	GFLOPS: 645.85 / 2101.59	results: MeasureResult(cost:[0.0133], error_no:0, all_cost:0.54, Tstamp:1715256185.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 676	GFLOPS: 846.17 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:1.14, Tstamp:1715256185.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 677	GFLOPS: 890.65 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.44, Tstamp:1715256186.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 678	GFLOPS: 859.53 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:0.56, Tstamp:1715256186.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 679	GFLOPS: 858.21 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:0.52, Tstamp:1715256186.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 680	GFLOPS: 799.15 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.33, Tstamp:1715256187.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 681	GFLOPS: 740.85 / 2101.59	results: MeasureResult(cost:[0.0116], error_no:0, all_cost:0.47, Tstamp:1715256187.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 682	GFLOPS: 843.42 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.38, Tstamp:1715256187.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 683	GFLOPS: 604.63 / 2101.59	results: MeasureResult(cost:[0.0142], error_no:0, all_cost:0.40, Tstamp:1715256187.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 684	GFLOPS: 905.51 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:0.48, Tstamp:1715256188.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 685	GFLOPS: 917.29 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:0.61, Tstamp:1715256188.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 686	GFLOPS: 627.23 / 2101.59	results: MeasureResult(cost:[0.0137], error_no:0, all_cost:0.41, Tstamp:1715256188.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,64)
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 687	GFLOPS: 576.06 / 2101.59	results: MeasureResult(cost:[0.0149], error_no:0, all_cost:0.44, Tstamp:1715256189.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 688	GFLOPS: 559.11 / 2101.59	results: MeasureResult(cost:[0.0154], error_no:0, all_cost:0.44, Tstamp:1715256189.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 689	GFLOPS: 728.43 / 2101.59	results: MeasureResult(cost:[0.0118], error_no:0, all_cost:0.41, Tstamp:1715256189.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 690	GFLOPS: 848.02 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.36, Tstamp:1715256190.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 691	GFLOPS: 843.65 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.41, Tstamp:1715256190.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 692	GFLOPS: 835.68 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.37, Tstamp:1715256190.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 693	GFLOPS: 859.78 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.25, Tstamp:1715256191.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 694	GFLOPS: 843.63 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:1.08, Tstamp:1715256191.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 695	GFLOPS: 727.97 / 2101.59	results: MeasureResult(cost:[0.0118], error_no:0, all_cost:0.36, Tstamp:1715256191.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 696	GFLOPS: 883.26 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.83, Tstamp:1715256192.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 697	GFLOPS: 867.94 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:0.69, Tstamp:1715256192.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 698	GFLOPS: 835.65 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.36, Tstamp:1715256192.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 699	GFLOPS: 839.91 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.36, Tstamp:1715256193.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 700	GFLOPS: 906.24 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.09, Tstamp:1715256193.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 701	GFLOPS: 909.58 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:0.46, Tstamp:1715256193.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 702	GFLOPS: 93.17 / 2101.59	results: MeasureResult(cost:[0.0922], error_no:0, all_cost:0.67, Tstamp:1715256194.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 703	GFLOPS: 98.27 / 2101.59	results: MeasureResult(cost:[0.0874], error_no:0, all_cost:0.55, Tstamp:1715256194.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 704	GFLOPS: 192.69 / 2101.59	results: MeasureResult(cost:[0.0446], error_no:0, all_cost:0.71, Tstamp:1715256194.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 26.51 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.86 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 957	fail_ct: 1091	Time elapsed: 2.25
GA Iter: 0	Max score: 0.6029	Min score: 0.3574	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6029	Min score: 0.3744	#Pop: 128	#M+: 1390	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 8.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 705	GFLOPS: 628.82 / 2101.59	results: MeasureResult(cost:[0.0137], error_no:0, all_cost:1.62, Tstamp:1715256213.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 706	GFLOPS: 617.17 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.62, Tstamp:1715256213.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 707	GFLOPS: 615.22 / 2101.59	results: MeasureResult(cost:[0.0140], error_no:0, all_cost:0.83, Tstamp:1715256214.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,524288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 708	GFLOPS: 614.41 / 2101.59	results: MeasureResult(cost:[0.0140], error_no:0, all_cost:0.66, Tstamp:1715256214.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 709	GFLOPS: 302.52 / 2101.59	results: MeasureResult(cost:[0.0284], error_no:0, all_cost:0.65, Tstamp:1715256214.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 710	GFLOPS: 763.66 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:2.44, Tstamp:1715256215.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 711	GFLOPS: 1045.18 / 2101.59	results: MeasureResult(cost:[0.0082], error_no:0, all_cost:1.43, Tstamp:1715256215.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 712	GFLOPS: 966.65 / 2101.59	results: MeasureResult(cost:[0.0089], error_no:0, all_cost:1.41, Tstamp:1715256215.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 713	GFLOPS: 909.73 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:1.34, Tstamp:1715256216.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 714	GFLOPS: 890.27 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.60, Tstamp:1715256216.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 715	GFLOPS: 610.79 / 2101.59	results: MeasureResult(cost:[0.0141], error_no:0, all_cost:0.73, Tstamp:1715256216.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,4096)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 716	GFLOPS: 898.44 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.41, Tstamp:1715256217.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 717	GFLOPS: 836.37 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.53, Tstamp:1715256217.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 718	GFLOPS: 844.95 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.81, Tstamp:1715256217.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 719	GFLOPS: 852.53 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.78, Tstamp:1715256218.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 720	GFLOPS: 853.96 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.57, Tstamp:1715256218.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 721	GFLOPS: 810.78 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.71, Tstamp:1715256218.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 722	GFLOPS: 877.37 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.60, Tstamp:1715256219.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 723	GFLOPS: 849.87 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.53, Tstamp:1715256219.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 724	GFLOPS: 834.75 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.62, Tstamp:1715256219.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 725	GFLOPS: 926.91 / 2101.59	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:1.45, Tstamp:1715256219.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 726	GFLOPS: 637.74 / 2101.59	results: MeasureResult(cost:[0.0135], error_no:0, all_cost:0.67, Tstamp:1715256220.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 727	GFLOPS: 833.92 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.61, Tstamp:1715256220.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 728	GFLOPS: 885.96 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.84, Tstamp:1715256220.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 729	GFLOPS: 854.43 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.60, Tstamp:1715256221.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 730	GFLOPS: 810.31 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.43, Tstamp:1715256221.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 731	GFLOPS: 876.61 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.34, Tstamp:1715256221.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 732	GFLOPS: 872.99 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.34, Tstamp:1715256221.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 733	GFLOPS: 838.86 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.92, Tstamp:1715256222.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,256)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 734	GFLOPS: 800.81 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.38, Tstamp:1715256222.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 735	GFLOPS: 874.41 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.33, Tstamp:1715256222.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 736	GFLOPS: 900.68 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.48, Tstamp:1715256223.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 737	GFLOPS: 789.12 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:1.23, Tstamp:1715256223.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 738	GFLOPS: 891.35 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.25, Tstamp:1715256223.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 739	GFLOPS: 1028.58 / 2101.59	results: MeasureResult(cost:[0.0084], error_no:0, all_cost:1.35, Tstamp:1715256223.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 740	GFLOPS: 909.07 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:1.36, Tstamp:1715256224.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 741	GFLOPS: 874.43 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.51, Tstamp:1715256224.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 742	GFLOPS: 830.97 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:1.11, Tstamp:1715256224.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 743	GFLOPS: 795.43 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.50, Tstamp:1715256225.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,64)
        compute = ...

==================================================
No: 744	GFLOPS: 921.07 / 2101.59	results: MeasureResult(cost:[0.0093], error_no:0, all_cost:1.45, Tstamp:1715256225.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 745	GFLOPS: 902.51 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.22, Tstamp:1715256225.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 746	GFLOPS: 882.14 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.29, Tstamp:1715256225.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 747	GFLOPS: 853.16 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:1.18, Tstamp:1715256226.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 748	GFLOPS: 815.70 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:1.20, Tstamp:1715256226.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 749	GFLOPS: 856.20 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.29, Tstamp:1715256226.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 750	GFLOPS: 907.84 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.45, Tstamp:1715256227.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 751	GFLOPS: 914.64 / 2101.59	results: MeasureResult(cost:[0.0094], error_no:0, all_cost:1.24, Tstamp:1715256227.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 752	GFLOPS: 899.71 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.20, Tstamp:1715256227.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 753	GFLOPS: 577.26 / 2101.59	results: MeasureResult(cost:[0.0149], error_no:0, all_cost:0.45, Tstamp:1715256227.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 754	GFLOPS: 869.26 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:1.36, Tstamp:1715256228.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 755	GFLOPS: 895.04 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.20, Tstamp:1715256228.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 756	GFLOPS: 855.86 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:0.45, Tstamp:1715256228.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 757	GFLOPS: 1030.26 / 2101.59	results: MeasureResult(cost:[0.0083], error_no:0, all_cost:1.27, Tstamp:1715256229.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 758	GFLOPS: 836.81 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.59, Tstamp:1715256229.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 759	GFLOPS: 858.87 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.21, Tstamp:1715256229.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 760	GFLOPS: 879.98 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.34, Tstamp:1715256230.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 761	GFLOPS: 892.21 / 2101.59	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:1.22, Tstamp:1715256230.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 762	GFLOPS: 838.41 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.40, Tstamp:1715256230.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 763	GFLOPS: 837.08 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.43, Tstamp:1715256230.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 764	GFLOPS: 803.49 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.29, Tstamp:1715256231.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 765	GFLOPS: 844.92 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.38, Tstamp:1715256231.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 766	GFLOPS: 702.72 / 2101.59	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:0.67, Tstamp:1715256231.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 767	GFLOPS: 809.93 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.82, Tstamp:1715256232.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 768	GFLOPS: 729.11 / 2101.59	results: MeasureResult(cost:[0.0118], error_no:0, all_cost:0.56, Tstamp:1715256232.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

Time elapsed for measurement: 25.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.07 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 976	fail_ct: 1072	Time elapsed: 2.21
GA Iter: 0	Max score: 0.4321	Min score: 0.3470	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.4938	Min score: 0.3734	#Pop: 128	#M+: 1367	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 8.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 769	GFLOPS: 800.17 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.87, Tstamp:1715256251.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 770	GFLOPS: 1021.59 / 2101.59	results: MeasureResult(cost:[0.0084], error_no:0, all_cost:2.10, Tstamp:1715256251.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 771	GFLOPS: 381.58 / 2101.59	results: MeasureResult(cost:[0.0225], error_no:0, all_cost:2.64, Tstamp:1715256252.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 772	GFLOPS: 765.63 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:1.93, Tstamp:1715256252.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 773	GFLOPS: 405.38 / 2101.59	results: MeasureResult(cost:[0.0212], error_no:0, all_cost:2.47, Tstamp:1715256252.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 774	GFLOPS: 437.96 / 2101.59	results: MeasureResult(cost:[0.0196], error_no:0, all_cost:2.14, Tstamp:1715256253.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 775	GFLOPS: 1022.15 / 2101.59	results: MeasureResult(cost:[0.0084], error_no:0, all_cost:1.25, Tstamp:1715256253.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 776	GFLOPS: 449.97 / 2101.59	results: MeasureResult(cost:[0.0191], error_no:0, all_cost:2.11, Tstamp:1715256253.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 777	GFLOPS: 1007.34 / 2101.59	results: MeasureResult(cost:[0.0085], error_no:0, all_cost:1.40, Tstamp:1715256254.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 778	GFLOPS: 657.20 / 2101.59	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:1.21, Tstamp:1715256254.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 779	GFLOPS: 887.30 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:2.11, Tstamp:1715256254.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 780	GFLOPS: 882.77 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.89, Tstamp:1715256255.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 781	GFLOPS: 783.16 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:1.98, Tstamp:1715256255.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 782	GFLOPS: 659.59 / 2101.59	results: MeasureResult(cost:[0.0130], error_no:0, all_cost:1.30, Tstamp:1715256255.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 783	GFLOPS: 659.63 / 2101.59	results: MeasureResult(cost:[0.0130], error_no:0, all_cost:0.91, Tstamp:1715256255.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 784	GFLOPS: 886.86 / 2101.59	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:1.81, Tstamp:1715256256.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 785	GFLOPS: 820.69 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:1.16, Tstamp:1715256256.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 786	GFLOPS: 877.93 / 2101.59	results: MeasureResult(cost:[0.0098], error_no:0, all_cost:1.92, Tstamp:1715256256.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 787	GFLOPS: 836.39 / 2101.59	results: MeasureResult(cost:[0.0103], error_no:0, all_cost:0.68, Tstamp:1715256257.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 788	GFLOPS: 842.08 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:1.46, Tstamp:1715256257.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 789	GFLOPS: 849.11 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:0.72, Tstamp:1715256257.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 790	GFLOPS: 847.98 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:1.54, Tstamp:1715256258.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 791	GFLOPS: 668.14 / 2101.59	results: MeasureResult(cost:[0.0129], error_no:0, all_cost:0.81, Tstamp:1715256258.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 792	GFLOPS: 653.60 / 2101.59	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:0.89, Tstamp:1715256258.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 793	GFLOPS: 790.74 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:1.60, Tstamp:1715256258.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 794	GFLOPS: 720.18 / 2101.59	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.64, Tstamp:1715256259.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 795	GFLOPS: 905.64 / 2101.59	results: MeasureResult(cost:[0.0095], error_no:0, all_cost:1.62, Tstamp:1715256259.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 796	GFLOPS: 768.58 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:1.40, Tstamp:1715256259.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 797	GFLOPS: 711.56 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.48, Tstamp:1715256260.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 798	GFLOPS: 807.40 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.16, Tstamp:1715256260.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 799	GFLOPS: 621.91 / 2101.59	results: MeasureResult(cost:[0.0138], error_no:0, all_cost:0.66, Tstamp:1715256260.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 800	GFLOPS: 642.41 / 2101.59	results: MeasureResult(cost:[0.0134], error_no:0, all_cost:0.54, Tstamp:1715256261.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 801	GFLOPS: 646.97 / 2101.59	results: MeasureResult(cost:[0.0133], error_no:0, all_cost:0.89, Tstamp:1715256261.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 802	GFLOPS: 719.42 / 2101.59	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.61, Tstamp:1715256261.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 803	GFLOPS: 865.10 / 2101.59	results: MeasureResult(cost:[0.0099], error_no:0, all_cost:0.66, Tstamp:1715256262.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 804	GFLOPS: 717.11 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.61, Tstamp:1715256262.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 805	GFLOPS: 846.09 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.50, Tstamp:1715256262.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 806	GFLOPS: 854.10 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:1.22, Tstamp:1715256263.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 807	GFLOPS: 1090.25 / 2101.59	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:1.34, Tstamp:1715256263.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 808	GFLOPS: 855.26 / 2101.59	results: MeasureResult(cost:[0.0100], error_no:0, all_cost:1.33, Tstamp:1715256263.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 809	GFLOPS: 653.29 / 2101.59	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:0.68, Tstamp:1715256263.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 810	GFLOPS: 657.69 / 2101.59	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:0.48, Tstamp:1715256264.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 811	GFLOPS: 802.61 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.11, Tstamp:1715256264.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 812	GFLOPS: 638.45 / 2101.59	results: MeasureResult(cost:[0.0135], error_no:0, all_cost:0.46, Tstamp:1715256264.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 813	GFLOPS: 644.80 / 2101.59	results: MeasureResult(cost:[0.0133], error_no:0, all_cost:0.56, Tstamp:1715256265.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,8)
        compute = ...

==================================================
No: 814	GFLOPS: 721.22 / 2101.59	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.43, Tstamp:1715256265.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 815	GFLOPS: 636.42 / 2101.59	results: MeasureResult(cost:[0.0135], error_no:0, all_cost:0.60, Tstamp:1715256265.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 816	GFLOPS: 651.69 / 2101.59	results: MeasureResult(cost:[0.0132], error_no:0, all_cost:0.52, Tstamp:1715256265.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 817	GFLOPS: 639.76 / 2101.59	results: MeasureResult(cost:[0.0134], error_no:0, all_cost:0.54, Tstamp:1715256266.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 818	GFLOPS: 715.03 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.43, Tstamp:1715256266.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 819	GFLOPS: 660.19 / 2101.59	results: MeasureResult(cost:[0.0130], error_no:0, all_cost:0.46, Tstamp:1715256266.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 820	GFLOPS: 726.33 / 2101.59	results: MeasureResult(cost:[0.0118], error_no:0, all_cost:0.57, Tstamp:1715256267.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,512)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,8)
        compute = ...

==================================================
No: 821	GFLOPS: 789.17 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.91, Tstamp:1715256267.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,64)
        compute = ...

==================================================
No: 822	GFLOPS: 797.75 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.77, Tstamp:1715256267.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,512)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,8)
      compute = ...

==================================================
No: 823	GFLOPS: 711.71 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.59, Tstamp:1715256268.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 824	GFLOPS: 806.66 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.39, Tstamp:1715256268.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 825	GFLOPS: 806.72 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.96, Tstamp:1715256268.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 826	GFLOPS: 813.92 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.45, Tstamp:1715256269.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 827	GFLOPS: 785.11 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.48, Tstamp:1715256269.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 828	GFLOPS: 807.65 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.39, Tstamp:1715256269.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 829	GFLOPS: 800.52 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.42, Tstamp:1715256270.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 830	GFLOPS: 804.17 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.66, Tstamp:1715256270.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 831	GFLOPS: 179.81 / 2101.59	results: MeasureResult(cost:[0.0478], error_no:0, all_cost:0.48, Tstamp:1715256270.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 832	GFLOPS: 586.21 / 2101.59	results: MeasureResult(cost:[0.0147], error_no:0, all_cost:0.48, Tstamp:1715256271.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

Time elapsed for measurement: 26.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.25 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 965	fail_ct: 1083	Time elapsed: 2.23
GA Iter: 0	Max score: 0.4157	Min score: 0.3447	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.4279	Min score: 0.3672	#Pop: 128	#M+: 1394	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 8.74
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 833	GFLOPS: 797.93 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:1.78, Tstamp:1715256290.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 834	GFLOPS: 618.73 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.74, Tstamp:1715256290.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 835	GFLOPS: 968.29 / 2101.59	results: MeasureResult(cost:[0.0089], error_no:0, all_cost:1.29, Tstamp:1715256291.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 836	GFLOPS: 851.74 / 2101.59	results: MeasureResult(cost:[0.0101], error_no:0, all_cost:2.23, Tstamp:1715256291.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 837	GFLOPS: 506.77 / 2101.59	results: MeasureResult(cost:[0.0170], error_no:0, all_cost:0.96, Tstamp:1715256291.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 838	GFLOPS: 962.97 / 2101.59	results: MeasureResult(cost:[0.0089], error_no:0, all_cost:1.34, Tstamp:1715256292.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 839	GFLOPS: 667.51 / 2101.59	results: MeasureResult(cost:[0.0129], error_no:0, all_cost:0.76, Tstamp:1715256292.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 840	GFLOPS: 654.26 / 2101.59	results: MeasureResult(cost:[0.0131], error_no:0, all_cost:1.18, Tstamp:1715256292.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 841	GFLOPS: 764.97 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.69, Tstamp:1715256293.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 842	GFLOPS: 769.73 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.87, Tstamp:1715256293.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 843	GFLOPS: 561.77 / 2101.59	results: MeasureResult(cost:[0.0153], error_no:0, all_cost:1.23, Tstamp:1715256293.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 844	GFLOPS: 552.77 / 2101.59	results: MeasureResult(cost:[0.0155], error_no:0, all_cost:1.22, Tstamp:1715256294.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 845	GFLOPS: 678.12 / 2101.59	results: MeasureResult(cost:[0.0127], error_no:0, all_cost:1.04, Tstamp:1715256294.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 846	GFLOPS: 760.96 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.58, Tstamp:1715256294.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 847	GFLOPS: 704.05 / 2101.59	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:1.02, Tstamp:1715256295.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 848	GFLOPS: 563.39 / 2101.59	results: MeasureResult(cost:[0.0152], error_no:0, all_cost:1.08, Tstamp:1715256295.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 849	GFLOPS: 704.37 / 2101.59	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:1.02, Tstamp:1715256295.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 850	GFLOPS: 614.92 / 2101.59	results: MeasureResult(cost:[0.0140], error_no:0, all_cost:1.12, Tstamp:1715256296.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 851	GFLOPS: 761.11 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:1.01, Tstamp:1715256296.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 852	GFLOPS: 784.02 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.87, Tstamp:1715256297.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 853	GFLOPS: 845.53 / 2101.59	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:1.08, Tstamp:1715256297.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 854	GFLOPS: 733.06 / 2101.59	results: MeasureResult(cost:[0.0117], error_no:0, all_cost:0.70, Tstamp:1715256297.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 855	GFLOPS: 676.64 / 2101.59	results: MeasureResult(cost:[0.0127], error_no:0, all_cost:0.73, Tstamp:1715256298.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 856	GFLOPS: 484.37 / 2101.59	results: MeasureResult(cost:[0.0177], error_no:0, all_cost:1.92, Tstamp:1715256298.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 857	GFLOPS: 715.91 / 2101.59	results: MeasureResult(cost:[0.0120], error_no:0, all_cost:0.65, Tstamp:1715256298.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 858	GFLOPS: 762.59 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.85, Tstamp:1715256299.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 859	GFLOPS: 704.77 / 2101.59	results: MeasureResult(cost:[0.0122], error_no:0, all_cost:1.58, Tstamp:1715256299.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 860	GFLOPS: 777.11 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.79, Tstamp:1715256299.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 861	GFLOPS: 409.17 / 2101.59	results: MeasureResult(cost:[0.0210], error_no:0, all_cost:1.22, Tstamp:1715256300.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,512)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,8)
        compute = ...

==================================================
No: 862	GFLOPS: 774.04 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.59, Tstamp:1715256300.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 863	GFLOPS: 605.64 / 2101.59	results: MeasureResult(cost:[0.0142], error_no:0, all_cost:0.51, Tstamp:1715256300.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 864	GFLOPS: 690.37 / 2101.59	results: MeasureResult(cost:[0.0124], error_no:0, all_cost:0.51, Tstamp:1715256301.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,64)
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 865	GFLOPS: 773.31 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.65, Tstamp:1715256301.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 866	GFLOPS: 774.94 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.81, Tstamp:1715256301.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 867	GFLOPS: 784.02 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.65, Tstamp:1715256302.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 868	GFLOPS: 783.62 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.54, Tstamp:1715256302.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 869	GFLOPS: 770.44 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.56, Tstamp:1715256302.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 870	GFLOPS: 782.53 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.64, Tstamp:1715256303.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 871	GFLOPS: 659.18 / 2101.59	results: MeasureResult(cost:[0.0130], error_no:0, all_cost:0.73, Tstamp:1715256303.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,128)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 872	GFLOPS: 800.47 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.68, Tstamp:1715256303.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 873	GFLOPS: 936.02 / 2101.59	results: MeasureResult(cost:[0.0092], error_no:0, all_cost:0.74, Tstamp:1715256304.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 874	GFLOPS: 796.21 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.62, Tstamp:1715256304.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 875	GFLOPS: 712.74 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.64, Tstamp:1715256304.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 876	GFLOPS: 723.51 / 2101.59	results: MeasureResult(cost:[0.0119], error_no:0, all_cost:0.63, Tstamp:1715256305.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 877	GFLOPS: 768.72 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.58, Tstamp:1715256305.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

==================================================
No: 878	GFLOPS: 764.21 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.52, Tstamp:1715256305.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 879	GFLOPS: 772.19 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.37, Tstamp:1715256305.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 880	GFLOPS: 785.79 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.57, Tstamp:1715256306.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 881	GFLOPS: 805.86 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.40, Tstamp:1715256306.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 882	GFLOPS: 709.49 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.44, Tstamp:1715256306.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 883	GFLOPS: 712.44 / 2101.59	results: MeasureResult(cost:[0.0121], error_no:0, all_cost:0.65, Tstamp:1715256307.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 884	GFLOPS: 792.23 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.56, Tstamp:1715256307.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 885	GFLOPS: 787.79 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.38, Tstamp:1715256308.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 886	GFLOPS: 811.79 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.41, Tstamp:1715256308.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 887	GFLOPS: 769.67 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.47, Tstamp:1715256308.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 888	GFLOPS: 794.46 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.38, Tstamp:1715256308.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 889	GFLOPS: 767.17 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.37, Tstamp:1715256309.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 890	GFLOPS: 796.70 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.71, Tstamp:1715256309.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 891	GFLOPS: 617.19 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.90, Tstamp:1715256310.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 892	GFLOPS: 813.47 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.37, Tstamp:1715256310.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 893	GFLOPS: 797.91 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.43, Tstamp:1715256310.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 894	GFLOPS: 684.50 / 2101.59	results: MeasureResult(cost:[0.0125], error_no:0, all_cost:0.50, Tstamp:1715256310.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for i.1 (0,256)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 895	GFLOPS: 109.58 / 2101.59	results: MeasureResult(cost:[0.0784], error_no:0, all_cost:1.25, Tstamp:1715256311.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 896	GFLOPS: 546.02 / 2101.59	results: MeasureResult(cost:[0.0157], error_no:0, all_cost:0.52, Tstamp:1715256311.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,64)
      compute = ...

Time elapsed for measurement: 28.33 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.20 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 999	fail_ct: 1049	Time elapsed: 2.28
GA Iter: 0	Max score: 0.4443	Min score: 0.3364	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.4464	Min score: 0.3572	#Pop: 128	#M+: 1384	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 8.82
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 897	GFLOPS: 651.59 / 2101.59	results: MeasureResult(cost:[0.0132], error_no:0, all_cost:0.81, Tstamp:1715256331.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 898	GFLOPS: 557.70 / 2101.59	results: MeasureResult(cost:[0.0154], error_no:0, all_cost:1.06, Tstamp:1715256331.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 899	GFLOPS: 562.12 / 2101.59	results: MeasureResult(cost:[0.0153], error_no:0, all_cost:0.73, Tstamp:1715256331.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 900	GFLOPS: 616.52 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.81, Tstamp:1715256331.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 901	GFLOPS: 421.17 / 2101.59	results: MeasureResult(cost:[0.0204], error_no:0, all_cost:0.97, Tstamp:1715256332.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,4096)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 902	GFLOPS: 619.93 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.98, Tstamp:1715256332.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 903	GFLOPS: 801.94 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.02, Tstamp:1715256332.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 904	GFLOPS: 815.07 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:0.73, Tstamp:1715256333.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 905	GFLOPS: 787.83 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.78, Tstamp:1715256333.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 906	GFLOPS: 802.07 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.90, Tstamp:1715256333.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 907	GFLOPS: 795.84 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.77, Tstamp:1715256334.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 908	GFLOPS: 817.41 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:0.87, Tstamp:1715256334.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 909	GFLOPS: 785.64 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.76, Tstamp:1715256334.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 910	GFLOPS: 777.49 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.65, Tstamp:1715256334.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 911	GFLOPS: 800.18 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.81, Tstamp:1715256335.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 912	GFLOPS: 810.90 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.81, Tstamp:1715256335.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 913	GFLOPS: 812.98 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.86, Tstamp:1715256335.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 914	GFLOPS: 618.45 / 2101.59	results: MeasureResult(cost:[0.0139], error_no:0, all_cost:0.54, Tstamp:1715256336.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,4096)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 915	GFLOPS: 780.06 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.88, Tstamp:1715256336.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 916	GFLOPS: 783.17 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.47, Tstamp:1715256336.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 917	GFLOPS: 695.97 / 2101.59	results: MeasureResult(cost:[0.0123], error_no:0, all_cost:0.77, Tstamp:1715256337.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 918	GFLOPS: 728.29 / 2101.59	results: MeasureResult(cost:[0.0118], error_no:0, all_cost:1.85, Tstamp:1715256337.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 919	GFLOPS: 796.00 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.70, Tstamp:1715256337.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 920	GFLOPS: 808.08 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.54, Tstamp:1715256337.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 921	GFLOPS: 795.13 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.59, Tstamp:1715256338.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 922	GFLOPS: 783.11 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.89, Tstamp:1715256338.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 923	GFLOPS: 993.06 / 2101.59	results: MeasureResult(cost:[0.0086], error_no:0, all_cost:1.10, Tstamp:1715256338.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 924	GFLOPS: 784.94 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.85, Tstamp:1715256339.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 925	GFLOPS: 789.10 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.55, Tstamp:1715256339.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 926	GFLOPS: 791.62 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.66, Tstamp:1715256340.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 927	GFLOPS: 787.14 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.47, Tstamp:1715256340.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 928	GFLOPS: 410.39 / 2101.59	results: MeasureResult(cost:[0.0209], error_no:0, all_cost:0.45, Tstamp:1715256340.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 929	GFLOPS: 785.96 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.57, Tstamp:1715256340.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 930	GFLOPS: 795.48 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.42, Tstamp:1715256341.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 931	GFLOPS: 786.43 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.66, Tstamp:1715256341.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 932	GFLOPS: 795.49 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.83, Tstamp:1715256342.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 933	GFLOPS: 790.54 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.65, Tstamp:1715256342.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 934	GFLOPS: 770.55 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.35, Tstamp:1715256342.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 935	GFLOPS: 807.12 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.53, Tstamp:1715256343.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 936	GFLOPS: 810.26 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.50, Tstamp:1715256343.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 937	GFLOPS: 799.86 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.40, Tstamp:1715256343.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 938	GFLOPS: 782.10 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.40, Tstamp:1715256344.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 939	GFLOPS: 795.50 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.41, Tstamp:1715256344.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 940	GFLOPS: 784.31 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.53, Tstamp:1715256344.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 941	GFLOPS: 779.66 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.42, Tstamp:1715256344.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 942	GFLOPS: 784.59 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.58, Tstamp:1715256345.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 943	GFLOPS: 801.11 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.36, Tstamp:1715256345.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 944	GFLOPS: 783.83 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.38, Tstamp:1715256345.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 945	GFLOPS: 782.32 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.37, Tstamp:1715256346.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 946	GFLOPS: 776.40 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.56, Tstamp:1715256346.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 947	GFLOPS: 790.11 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.38, Tstamp:1715256346.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 948	GFLOPS: 782.76 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.58, Tstamp:1715256347.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 949	GFLOPS: 787.22 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.61, Tstamp:1715256347.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 950	GFLOPS: 768.55 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.38, Tstamp:1715256347.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 951	GFLOPS: 788.01 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.39, Tstamp:1715256347.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 952	GFLOPS: 795.30 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.36, Tstamp:1715256348.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 953	GFLOPS: 788.81 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.52, Tstamp:1715256348.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 954	GFLOPS: 785.89 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.52, Tstamp:1715256349.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 955	GFLOPS: 762.66 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.34, Tstamp:1715256349.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,128)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 956	GFLOPS: 786.02 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.34, Tstamp:1715256349.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 957	GFLOPS: 771.64 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.39, Tstamp:1715256349.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 958	GFLOPS: 737.98 / 2101.59	results: MeasureResult(cost:[0.0116], error_no:0, all_cost:0.85, Tstamp:1715256350.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 959	GFLOPS: 792.80 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.36, Tstamp:1715256350.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 960	GFLOPS: 784.06 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.51, Tstamp:1715256350.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

Time elapsed for measurement: 26.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.04 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 981	fail_ct: 1067	Time elapsed: 2.21
GA Iter: 0	Max score: 0.3802	Min score: 0.3321	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.3945	Min score: 0.3455	#Pop: 128	#M+: 1384	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 8.77
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 40 programs to measure:
........................................****************************************
==================================================
No: 961	GFLOPS: 581.47 / 2101.59	results: MeasureResult(cost:[0.0148], error_no:0, all_cost:0.73, Tstamp:1715256367.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 962	GFLOPS: 771.90 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.65, Tstamp:1715256368.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 963	GFLOPS: 805.23 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:1.21, Tstamp:1715256368.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,256)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 964	GFLOPS: 675.24 / 2101.59	results: MeasureResult(cost:[0.0127], error_no:0, all_cost:0.64, Tstamp:1715256368.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 4096), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 4096), 16)]))
    for i.2 (0,32)
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 965	GFLOPS: 1008.20 / 2101.59	results: MeasureResult(cost:[0.0085], error_no:0, all_cost:1.39, Tstamp:1715256368.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,8)
      compute = ...

==================================================
No: 966	GFLOPS: 1015.71 / 2101.59	results: MeasureResult(cost:[0.0085], error_no:0, all_cost:1.54, Tstamp:1715256369.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 967	GFLOPS: 810.23 / 2101.59	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:0.84, Tstamp:1715256369.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 968	GFLOPS: 763.37 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.54, Tstamp:1715256369.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 969	GFLOPS: 787.81 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.83, Tstamp:1715256370.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 970	GFLOPS: 815.54 / 2101.59	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:0.54, Tstamp:1715256370.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 971	GFLOPS: 793.12 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.37, Tstamp:1715256370.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 972	GFLOPS: 782.40 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.37, Tstamp:1715256370.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 973	GFLOPS: 793.98 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.44, Tstamp:1715256371.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 974	GFLOPS: 691.83 / 2101.59	results: MeasureResult(cost:[0.0124], error_no:0, all_cost:0.52, Tstamp:1715256371.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 975	GFLOPS: 790.64 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.56, Tstamp:1715256371.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 976	GFLOPS: 765.07 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.54, Tstamp:1715256372.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,256)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 977	GFLOPS: 791.92 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.64, Tstamp:1715256372.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 978	GFLOPS: 784.32 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.49, Tstamp:1715256372.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 979	GFLOPS: 789.32 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.49, Tstamp:1715256372.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 980	GFLOPS: 759.62 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.42, Tstamp:1715256373.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    for n.1 (0,16)
      compute = ...

==================================================
No: 981	GFLOPS: 777.50 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.50, Tstamp:1715256373.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 982	GFLOPS: 797.01 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.36, Tstamp:1715256373.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 983	GFLOPS: 773.03 / 2101.59	results: MeasureResult(cost:[0.0111], error_no:0, all_cost:0.36, Tstamp:1715256374.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 984	GFLOPS: 788.37 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.55, Tstamp:1715256374.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 985	GFLOPS: 758.38 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.87, Tstamp:1715256374.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,8)
      compute = ...

==================================================
No: 986	GFLOPS: 769.66 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.37, Tstamp:1715256375.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 987	GFLOPS: 769.82 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.32, Tstamp:1715256375.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 988	GFLOPS: 784.29 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.37, Tstamp:1715256375.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

==================================================
No: 989	GFLOPS: 765.47 / 2101.59	results: MeasureResult(cost:[0.0112], error_no:0, all_cost:0.38, Tstamp:1715256376.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 990	GFLOPS: 759.07 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.39, Tstamp:1715256376.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,256)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,32)
      compute = ...

==================================================
No: 991	GFLOPS: 791.96 / 2101.59	results: MeasureResult(cost:[0.0108], error_no:0, all_cost:0.51, Tstamp:1715256376.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 992	GFLOPS: 778.84 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.58, Tstamp:1715256377.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 993	GFLOPS: 763.42 / 2101.59	results: MeasureResult(cost:[0.0113], error_no:0, all_cost:0.41, Tstamp:1715256377.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 994	GFLOPS: 747.48 / 2101.59	results: MeasureResult(cost:[0.0115], error_no:0, all_cost:0.36, Tstamp:1715256377.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 995	GFLOPS: 782.60 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.52, Tstamp:1715256378.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 996	GFLOPS: 783.15 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.35, Tstamp:1715256378.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 997	GFLOPS: 784.70 / 2101.59	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.36, Tstamp:1715256378.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 998	GFLOPS: 780.25 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.35, Tstamp:1715256378.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 999	GFLOPS: 782.19 / 2101.59	results: MeasureResult(cost:[0.0110], error_no:0, all_cost:0.38, Tstamp:1715256379.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 256) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 256)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 1000	GFLOPS: 801.45 / 2101.59	results: MeasureResult(cost:[0.0107], error_no:0, all_cost:0.69, Tstamp:1715256379.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

Time elapsed for measurement: 16.60 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
Lowered TIR:
@main = primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, compute_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_8: Pointer(float32), float32, [256, 4096], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [16512, 16, 16], []),
             placeholder_2: Buffer(placeholder_10: Pointer(int32), int32, [16512], []),
             placeholder_3: Buffer(placeholder_11: Pointer(int32), int32, [257], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [256, 4096], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, compute_1: compute} {
  for (m.outer.n.outer.fused: int32, 0, 8192) "parallel" {
    allocate(compute_3: Pointer(global float32), float32, [128]), storage_scope = global {
      for (nb_j.inner: int32, 0, 2) {
        let cse_var_1: int32 = (nb_j.inner*16)
         {
          compute_4: Buffer(compute_3, float32, [128], [])[cse_var_1] = 0f32
          compute_4[(cse_var_1 + 1)] = 0f32
          compute_4[(cse_var_1 + 2)] = 0f32
          compute_4[(cse_var_1 + 3)] = 0f32
          compute_4[(cse_var_1 + 4)] = 0f32
          compute_4[(cse_var_1 + 5)] = 0f32
          compute_4[(cse_var_1 + 6)] = 0f32
          compute_4[(cse_var_1 + 7)] = 0f32
          compute_4[(cse_var_1 + 8)] = 0f32
          compute_4[(cse_var_1 + 9)] = 0f32
          compute_4[(cse_var_1 + 10)] = 0f32
          compute_4[(cse_var_1 + 11)] = 0f32
          compute_4[(cse_var_1 + 12)] = 0f32
          compute_4[(cse_var_1 + 13)] = 0f32
          compute_4[(cse_var_1 + 14)] = 0f32
          compute_4[(cse_var_1 + 15)] = 0f32
          compute_4[(cse_var_1 + 32)] = 0f32
          compute_4[(cse_var_1 + 33)] = 0f32
          compute_4[(cse_var_1 + 34)] = 0f32
          compute_4[(cse_var_1 + 35)] = 0f32
          compute_4[(cse_var_1 + 36)] = 0f32
          compute_4[(cse_var_1 + 37)] = 0f32
          compute_4[(cse_var_1 + 38)] = 0f32
          compute_4[(cse_var_1 + 39)] = 0f32
          compute_4[(cse_var_1 + 40)] = 0f32
          compute_4[(cse_var_1 + 41)] = 0f32
          compute_4[(cse_var_1 + 42)] = 0f32
          compute_4[(cse_var_1 + 43)] = 0f32
          compute_4[(cse_var_1 + 44)] = 0f32
          compute_4[(cse_var_1 + 45)] = 0f32
          compute_4[(cse_var_1 + 46)] = 0f32
          compute_4[(cse_var_1 + 47)] = 0f32
          compute_4[(cse_var_1 + 64)] = 0f32
          compute_4[(cse_var_1 + 65)] = 0f32
          compute_4[(cse_var_1 + 66)] = 0f32
          compute_4[(cse_var_1 + 67)] = 0f32
          compute_4[(cse_var_1 + 68)] = 0f32
          compute_4[(cse_var_1 + 69)] = 0f32
          compute_4[(cse_var_1 + 70)] = 0f32
          compute_4[(cse_var_1 + 71)] = 0f32
          compute_4[(cse_var_1 + 72)] = 0f32
          compute_4[(cse_var_1 + 73)] = 0f32
          compute_4[(cse_var_1 + 74)] = 0f32
          compute_4[(cse_var_1 + 75)] = 0f32
          compute_4[(cse_var_1 + 76)] = 0f32
          compute_4[(cse_var_1 + 77)] = 0f32
          compute_4[(cse_var_1 + 78)] = 0f32
          compute_4[(cse_var_1 + 79)] = 0f32
          compute_4[(cse_var_1 + 96)] = 0f32
          compute_4[(cse_var_1 + 97)] = 0f32
          compute_4[(cse_var_1 + 98)] = 0f32
          compute_4[(cse_var_1 + 99)] = 0f32
          compute_4[(cse_var_1 + 100)] = 0f32
          compute_4[(cse_var_1 + 101)] = 0f32
          compute_4[(cse_var_1 + 102)] = 0f32
          compute_4[(cse_var_1 + 103)] = 0f32
          compute_4[(cse_var_1 + 104)] = 0f32
          compute_4[(cse_var_1 + 105)] = 0f32
          compute_4[(cse_var_1 + 106)] = 0f32
          compute_4[(cse_var_1 + 107)] = 0f32
          compute_4[(cse_var_1 + 108)] = 0f32
          compute_4[(cse_var_1 + 109)] = 0f32
          compute_4[(cse_var_1 + 110)] = 0f32
          compute_4[(cse_var_1 + 111)] = 0f32
          for (elem_idx: int32, 0, let cse_var_2: int32 = ((floormod(m.outer.n.outer.fused, 128)*2) + nb_j.inner) in (placeholder_12: Buffer(placeholder_11, int32, [257], [])[(cse_var_2 + 1)] - placeholder_12[cse_var_2])) {
            for (i.inner: int32, 0, 4) {
              let cse_var_21: int32 = (elem_idx*256)
              let cse_var_20: int32 = ((i.inner*32) + cse_var_1)
              let cse_var_19: int32 = ((floormod(m.outer.n.outer.fused, 128)*2) + nb_j.inner)
              let cse_var_18: int32 = (cse_var_20 + 9)
              let cse_var_17: int32 = (cse_var_20 + 8)
              let cse_var_16: int32 = (cse_var_20 + 7)
              let cse_var_15: int32 = (cse_var_20 + 6)
              let cse_var_14: int32 = (cse_var_20 + 5)
              let cse_var_13: int32 = (cse_var_20 + 4)
              let cse_var_12: int32 = (cse_var_20 + 3)
              let cse_var_11: int32 = (cse_var_20 + 2)
              let cse_var_10: int32 = (cse_var_20 + 15)
              let cse_var_9: int32 = (cse_var_20 + 14)
              let cse_var_8: int32 = (cse_var_20 + 13)
              let cse_var_7: int32 = (cse_var_20 + 12)
              let cse_var_6: int32 = (cse_var_20 + 11)
              let cse_var_5: int32 = (cse_var_20 + 10)
              let cse_var_4: int32 = (cse_var_20 + 1)
              let cse_var_3: int32 = ((floordiv(m.outer.n.outer.fused, 128)*16384) + (i.inner*4096))
               {
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13: Buffer(placeholder_9, float32, [4227072], [])[((placeholder_12[cse_var_19]*256) + cse_var_21)]*placeholder_14: Buffer(placeholder_8, float32, [1048576], [])[(cse_var_3 + (placeholder_15: Buffer(placeholder_10, int32, [16512], [])[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 1)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 2)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 3)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 4)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 5)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 6)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 7)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 8)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 9)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 10)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 11)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 12)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 13)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 14)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 15)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 16)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 17)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 18)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 19)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 20)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 21)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 22)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 23)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 24)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 25)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 26)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 27)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 28)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 29)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 30)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 31)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 32)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 33)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 34)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 35)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 36)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 37)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 38)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 39)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 40)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 41)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 42)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 43)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 44)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 45)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 46)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 47)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 48)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 49)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 50)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 51)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 52)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 53)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 54)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 55)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 56)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 57)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 58)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 59)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 60)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 61)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 62)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 63)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 64)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 65)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 66)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 67)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 68)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 69)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 70)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 71)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 72)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 73)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 74)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 75)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 76)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 77)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 78)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 79)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 80)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 81)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 82)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 83)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 84)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 85)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 86)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 87)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 88)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 89)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 90)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 91)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 92)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 93)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 94)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 95)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 96)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 97)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 98)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 99)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 100)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 101)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 102)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 103)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 104)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 105)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 106)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 107)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 108)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 109)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 110)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 111)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 112)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 113)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 114)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 115)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 116)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 117)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 118)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 119)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 120)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 121)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 122)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 123)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 124)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 125)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 126)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 127)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 128)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 129)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 130)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 131)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 132)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 133)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 134)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 135)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 136)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 137)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 138)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 139)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 140)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 141)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 142)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 143)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 144)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 145)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 146)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 147)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 148)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 149)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 150)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 151)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 152)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 153)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 154)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 155)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 156)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 157)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 158)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 159)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 160)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 161)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 162)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 163)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 164)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 165)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 166)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 167)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 168)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 169)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 170)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 171)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 172)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 173)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 174)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 175)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 176)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 177)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 178)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 179)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 180)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 181)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 182)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 183)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 184)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 185)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 186)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 187)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 188)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 189)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 190)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 191)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 192)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 193)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 194)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 195)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 196)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 197)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 198)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 199)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 200)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 201)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 202)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 203)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 204)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 205)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 206)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 207)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 208)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 209)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 210)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 211)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 212)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 213)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 214)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 215)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 216)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 217)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 218)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 219)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 220)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 221)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 222)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 223)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 224)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 225)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 226)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 227)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 228)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 229)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 230)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 231)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 232)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 233)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 234)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 235)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 236)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 237)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 238)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 239)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 240)]*placeholder_14[(cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16))]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 241)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 242)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 243)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 244)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 245)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 246)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 247)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 248)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 249)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 250)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 251)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 252)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 253)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 254)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_19]*256) + cse_var_21) + 255)]*placeholder_14[((cse_var_3 + (placeholder_15[(placeholder_12[cse_var_19] + elem_idx)]*16)) + 15)]))
              }
            }
          }
        }
      }
      for (m.inner: int32, 0, 4) {
        compute_5: Buffer(compute_2, float32, [1048576], [])[ramp((((floordiv(m.outer.n.outer.fused, 128)*16384) + (m.inner*4096)) + (floormod(m.outer.n.outer.fused, 128)*32)), 1, 32)] = compute_4[ramp((m.inner*32), 1, 32)]
      }
    }
  }
}

----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
Custom sketch rule "SparseDense" added.
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 1669	fail_ct: 379	Time elapsed: 2.47
GA Iter: 0	Max score: 0.9991	Min score: 0.9187	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9881	#Pop: 128	#M+: 1384	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 9.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
(256, 4096)
(256, 4096)
strides_mask Execution time of this operator: 4.106 ms
encoder.layer.10.output.dense.weight: num_row = 768, num_col = 3072, nnz = 43965

==================================================
No: 1	GFLOPS: 7484.76 / 7484.76	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.24, Tstamp:1715256403.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,8)
      compute = ...

==================================================
No: 2	GFLOPS: 2999.67 / 7484.76	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.95, Tstamp:1715256404.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 3	GFLOPS: 9838.33 / 9838.33	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.40, Tstamp:1715256404.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 4	GFLOPS: 4551.31 / 9838.33	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.66, Tstamp:1715256404.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 5	GFLOPS: 8717.11 / 9838.33	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.85, Tstamp:1715256404.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 6	GFLOPS: 1790.82 / 9838.33	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.94, Tstamp:1715256405.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 7	GFLOPS: 12781.83 / 12781.83	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.86, Tstamp:1715256405.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 8	GFLOPS: 2736.72 / 12781.83	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:1.25, Tstamp:1715256405.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 9	GFLOPS: 3793.94 / 12781.83	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.18, Tstamp:1715256406.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 10	GFLOPS: 6984.35 / 12781.83	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.80, Tstamp:1715256406.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 11	GFLOPS: 9395.49 / 12781.83	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.18, Tstamp:1715256406.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 12	GFLOPS: 9086.09 / 12781.83	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.80, Tstamp:1715256407.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 13	GFLOPS: 12536.51 / 12781.83	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.68, Tstamp:1715256407.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 14	GFLOPS: 880.24 / 12781.83	results: MeasureResult(cost:[0.0041], error_no:0, all_cost:1.43, Tstamp:1715256407.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 15	GFLOPS: 8909.57 / 12781.83	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.79, Tstamp:1715256408.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 16	GFLOPS: 3078.95 / 12781.83	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.84, Tstamp:1715256408.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 17	GFLOPS: 8212.18 / 12781.83	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.18, Tstamp:1715256408.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 18	GFLOPS: 2130.59 / 12781.83	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.84, Tstamp:1715256409.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 19	GFLOPS: 5042.72 / 12781.83	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.79, Tstamp:1715256409.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 20	GFLOPS: 8148.76 / 12781.83	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.21, Tstamp:1715256409.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 21	GFLOPS: 2072.00 / 12781.83	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.54, Tstamp:1715256409.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 16
  for i.1 (0,192)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 22	GFLOPS: 5227.38 / 12781.83	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.00, Tstamp:1715256410.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 23	GFLOPS: 16089.51 / 16089.51	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715256410.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 24	GFLOPS: 8653.27 / 16089.51	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.56, Tstamp:1715256410.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 25	GFLOPS: 7607.01 / 16089.51	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.79, Tstamp:1715256411.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 26	GFLOPS: 15675.08 / 16089.51	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715256411.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 27	GFLOPS: 4712.38 / 16089.51	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.46, Tstamp:1715256411.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,24)
      compute = ...

==================================================
No: 28	GFLOPS: 6567.06 / 16089.51	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.65, Tstamp:1715256412.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 29	GFLOPS: 4298.83 / 16089.51	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.93, Tstamp:1715256412.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 30	GFLOPS: 2037.65 / 16089.51	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.43, Tstamp:1715256412.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 31	GFLOPS: 6354.53 / 16089.51	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.49, Tstamp:1715256412.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 32	GFLOPS: 691.16 / 16089.51	results: MeasureResult(cost:[0.0052], error_no:0, all_cost:0.72, Tstamp:1715256413.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,192)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 33	GFLOPS: 12567.03 / 16089.51	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715256413.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,24)
      compute = ...

==================================================
No: 34	GFLOPS: 5360.14 / 16089.51	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.98, Tstamp:1715256413.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 35	GFLOPS: 24890.99 / 24890.99	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.41, Tstamp:1715256413.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 36	GFLOPS: 2631.94 / 24890.99	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.67, Tstamp:1715256414.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 37	GFLOPS: 7495.23 / 24890.99	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.40, Tstamp:1715256414.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,24)
      compute = ...

==================================================
No: 38	GFLOPS: 1120.67 / 24890.99	results: MeasureResult(cost:[0.0032], error_no:0, all_cost:2.48, Tstamp:1715256414.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 39	GFLOPS: 4431.84 / 24890.99	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.56, Tstamp:1715256415.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,4)
        compute = ...

==================================================
No: 40	GFLOPS: 11630.97 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715256415.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 41	GFLOPS: 5943.86 / 24890.99	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.55, Tstamp:1715256415.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 42	GFLOPS: 8753.19 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.47, Tstamp:1715256415.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 43	GFLOPS: 3945.37 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.99, Tstamp:1715256416.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 44	GFLOPS: 689.37 / 24890.99	results: MeasureResult(cost:[0.0053], error_no:0, all_cost:0.43, Tstamp:1715256416.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 45	GFLOPS: 1869.72 / 24890.99	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.40, Tstamp:1715256416.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 46	GFLOPS: 5094.27 / 24890.99	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.46, Tstamp:1715256416.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,6)
      compute = ...

==================================================
No: 47	GFLOPS: 4249.00 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.54, Tstamp:1715256417.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 48	GFLOPS: 2077.18 / 24890.99	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.38, Tstamp:1715256417.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 49	GFLOPS: 2067.76 / 24890.99	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.51, Tstamp:1715256417.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,2)
      compute = ...

==================================================
No: 50	GFLOPS: 1566.08 / 24890.99	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:0.54, Tstamp:1715256417.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,256)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 51	GFLOPS: 4417.57 / 24890.99	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.52, Tstamp:1715256418.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 52	GFLOPS: 2726.58 / 24890.99	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.36, Tstamp:1715256418.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 53	GFLOPS: 10720.48 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715256418.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 54	GFLOPS: 3173.42 / 24890.99	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.52, Tstamp:1715256419.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,4)
      compute = ...

==================================================
No: 55	GFLOPS: 1581.08 / 24890.99	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:0.30, Tstamp:1715256419.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 56	GFLOPS: 1760.90 / 24890.99	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:0.39, Tstamp:1715256419.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,4)
      compute = ...

==================================================
No: 57	GFLOPS: 7469.76 / 24890.99	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.63, Tstamp:1715256419.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 58	GFLOPS: 1381.31 / 24890.99	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:0.45, Tstamp:1715256420.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    for n.1 (0,3)
      compute = ...

==================================================
No: 59	GFLOPS: 10089.01 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.79, Tstamp:1715256420.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 60	GFLOPS: 8985.22 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.44, Tstamp:1715256420.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 61	GFLOPS: 1027.84 / 24890.99	results: MeasureResult(cost:[0.0035], error_no:0, all_cost:0.43, Tstamp:1715256420.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 62	GFLOPS: 10260.39 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.73, Tstamp:1715256421.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 63	GFLOPS: 12148.85 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715256421.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 64	GFLOPS: 3638.86 / 24890.99	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:2.82, Tstamp:1715256421.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,12)
      compute = ...

Time elapsed for measurement: 27.02 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.71 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1690	fail_ct: 358	Time elapsed: 2.47
GA Iter: 0	Max score: 0.9993	Min score: 0.9275	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9993	Min score: 0.9868	#Pop: 128	#M+: 1384	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 10.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 65	GFLOPS: 7235.00 / 24890.99	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.08, Tstamp:1715256444.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 66	GFLOPS: 9497.58 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.60, Tstamp:1715256444.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 67	GFLOPS: 1856.18 / 24890.99	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.96, Tstamp:1715256444.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 68	GFLOPS: 7906.26 / 24890.99	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.43, Tstamp:1715256444.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 69	GFLOPS: 11659.90 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.26, Tstamp:1715256445.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,24)
      compute = ...

==================================================
No: 70	GFLOPS: 5515.93 / 24890.99	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.35, Tstamp:1715256445.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 71	GFLOPS: 11292.41 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715256445.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 72	GFLOPS: 4126.57 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.94, Tstamp:1715256446.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 73	GFLOPS: 642.32 / 24890.99	results: MeasureResult(cost:[0.0056], error_no:0, all_cost:1.29, Tstamp:1715256446.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 74	GFLOPS: 18090.21 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.28, Tstamp:1715256446.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 75	GFLOPS: 17691.57 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715256447.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 76	GFLOPS: 1756.87 / 24890.99	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:1.13, Tstamp:1715256447.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 77	GFLOPS: 763.55 / 24890.99	results: MeasureResult(cost:[0.0047], error_no:0, all_cost:0.46, Tstamp:1715256447.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 78	GFLOPS: 3060.18 / 24890.99	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.87, Tstamp:1715256447.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    for n.1 (0,8)
      compute = ...

==================================================
No: 79	GFLOPS: 2616.54 / 24890.99	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:1.76, Tstamp:1715256448.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,192)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 80	GFLOPS: 14995.22 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715256448.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 81	GFLOPS: 16253.56 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715256448.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 82	GFLOPS: 1548.09 / 24890.99	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:1.31, Tstamp:1715256449.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 83	GFLOPS: 4693.93 / 24890.99	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.86, Tstamp:1715256449.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 84	GFLOPS: 17792.86 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715256449.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 85	GFLOPS: 3697.09 / 24890.99	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.87, Tstamp:1715256449.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 86	GFLOPS: 5482.23 / 24890.99	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.90, Tstamp:1715256450.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 87	GFLOPS: 16347.67 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.04, Tstamp:1715256450.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 88	GFLOPS: 1164.74 / 24890.99	results: MeasureResult(cost:[0.0031], error_no:0, all_cost:0.53, Tstamp:1715256450.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,16)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,4)
        compute = ...

==================================================
No: 89	GFLOPS: 12918.24 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715256451.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 90	GFLOPS: 12086.49 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256451.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,24)
    compute = ...

==================================================
No: 91	GFLOPS: 3784.05 / 24890.99	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.47, Tstamp:1715256451.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 92	GFLOPS: 898.56 / 24890.99	results: MeasureResult(cost:[0.0040], error_no:0, all_cost:0.57, Tstamp:1715256451.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 93	GFLOPS: 2115.65 / 24890.99	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.73, Tstamp:1715256452.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 94	GFLOPS: 1066.98 / 24890.99	results: MeasureResult(cost:[0.0034], error_no:0, all_cost:0.59, Tstamp:1715256452.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 95	GFLOPS: 8171.13 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715256452.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 96	GFLOPS: 10157.44 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.76, Tstamp:1715256453.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 97	GFLOPS: 1030.57 / 24890.99	results: MeasureResult(cost:[0.0035], error_no:0, all_cost:0.87, Tstamp:1715256453.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,384)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    for n.1 (0,6)
      compute = ...

==================================================
No: 98	GFLOPS: 3111.58 / 24890.99	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.79, Tstamp:1715256453.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 99	GFLOPS: 1083.38 / 24890.99	results: MeasureResult(cost:[0.0033], error_no:0, all_cost:0.82, Tstamp:1715256453.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 100	GFLOPS: 3605.24 / 24890.99	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.44, Tstamp:1715256454.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 101	GFLOPS: 4158.44 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.52, Tstamp:1715256454.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 102	GFLOPS: 1628.50 / 24890.99	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:0.30, Tstamp:1715256454.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 103	GFLOPS: 3601.17 / 24890.99	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.57, Tstamp:1715256455.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 104	GFLOPS: 7573.72 / 24890.99	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.51, Tstamp:1715256455.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 105	GFLOPS: 3982.13 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.39, Tstamp:1715256455.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 106	GFLOPS: 1067.31 / 24890.99	results: MeasureResult(cost:[0.0034], error_no:0, all_cost:0.31, Tstamp:1715256455.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 107	GFLOPS: 1412.03 / 24890.99	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:2.94, Tstamp:1715256455.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 108	GFLOPS: 3968.96 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.55, Tstamp:1715256456.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 109	GFLOPS: 4209.97 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.33, Tstamp:1715256456.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 110	GFLOPS: 13233.37 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715256456.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 111	GFLOPS: 4970.35 / 24890.99	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.89, Tstamp:1715256457.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 112	GFLOPS: 3496.22 / 24890.99	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.16, Tstamp:1715256457.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 113	GFLOPS: 4625.59 / 24890.99	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.16, Tstamp:1715256457.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 114	GFLOPS: 8550.72 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.48, Tstamp:1715256458.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,24)
      compute = ...

==================================================
No: 115	GFLOPS: 8620.20 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.45, Tstamp:1715256458.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 116	GFLOPS: 8658.99 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.48, Tstamp:1715256458.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 117	GFLOPS: 1853.43 / 24890.99	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:1.07, Tstamp:1715256459.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 118	GFLOPS: 4180.16 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.59, Tstamp:1715256459.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 119	GFLOPS: 5938.97 / 24890.99	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.46, Tstamp:1715256459.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 120	GFLOPS: 19868.91 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.18, Tstamp:1715256460.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 121	GFLOPS: 3050.89 / 24890.99	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:2.83, Tstamp:1715256460.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 122	GFLOPS: 3877.60 / 24890.99	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.48, Tstamp:1715256460.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,8)
      compute = ...

==================================================
No: 123	GFLOPS: 12811.35 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.35, Tstamp:1715256460.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 124	GFLOPS: 14063.37 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.91, Tstamp:1715256461.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 125	GFLOPS: 1941.47 / 24890.99	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.55, Tstamp:1715256461.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 16
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 126	GFLOPS: 5321.91 / 24890.99	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.80, Tstamp:1715256461.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 127	GFLOPS: 2115.39 / 24890.99	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.55, Tstamp:1715256461.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,192)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 128	GFLOPS: 1379.95 / 24890.99	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:0.38, Tstamp:1715256462.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 26.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.97 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1655	fail_ct: 393	Time elapsed: 2.51
GA Iter: 0	Max score: 0.9218	Min score: 0.4227	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9218	Min score: 0.6501	#Pop: 128	#M+: 1377	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 9.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 129	GFLOPS: 6117.15 / 24890.99	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.74, Tstamp:1715256483.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 130	GFLOPS: 18734.71 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.72, Tstamp:1715256483.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 131	GFLOPS: 16022.85 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.40, Tstamp:1715256483.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 132	GFLOPS: 14924.29 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.43, Tstamp:1715256484.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 133	GFLOPS: 16612.92 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.08, Tstamp:1715256484.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 134	GFLOPS: 22661.36 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.11, Tstamp:1715256484.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 135	GFLOPS: 17973.00 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715256485.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 136	GFLOPS: 18140.87 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715256485.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 137	GFLOPS: 17929.97 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715256485.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 138	GFLOPS: 23298.00 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.26, Tstamp:1715256485.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 139	GFLOPS: 16142.27 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.27, Tstamp:1715256486.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 140	GFLOPS: 16554.26 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.04, Tstamp:1715256486.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 141	GFLOPS: 16619.14 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715256486.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 142	GFLOPS: 15770.73 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715256487.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 143	GFLOPS: 8343.92 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.85, Tstamp:1715256487.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 144	GFLOPS: 17813.20 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.69, Tstamp:1715256487.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 145	GFLOPS: 11378.76 / 24890.99	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.21, Tstamp:1715256488.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 146	GFLOPS: 16191.71 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.96, Tstamp:1715256488.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 147	GFLOPS: 15486.97 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.39, Tstamp:1715256488.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 148	GFLOPS: 9460.40 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.41, Tstamp:1715256489.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 149	GFLOPS: 17419.64 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.81, Tstamp:1715256489.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 150	GFLOPS: 20101.43 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.78, Tstamp:1715256489.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 151	GFLOPS: 21655.88 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.67, Tstamp:1715256489.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 152	GFLOPS: 15670.87 / 24890.99	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715256490.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 153	GFLOPS: 10024.83 / 24890.99	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.63, Tstamp:1715256490.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 154	GFLOPS: 26725.48 / 26725.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715256490.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 155	GFLOPS: 13594.01 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.86, Tstamp:1715256491.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 156	GFLOPS: 16444.56 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256491.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 157	GFLOPS: 23011.07 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.40, Tstamp:1715256491.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 158	GFLOPS: 22659.87 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.48, Tstamp:1715256492.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 159	GFLOPS: 24118.58 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715256492.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 160	GFLOPS: 10988.73 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.50, Tstamp:1715256492.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 161	GFLOPS: 15508.07 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256493.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 162	GFLOPS: 15374.35 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715256493.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 163	GFLOPS: 10072.52 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.42, Tstamp:1715256493.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 164	GFLOPS: 19757.09 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.39, Tstamp:1715256494.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 165	GFLOPS: 17744.68 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715256494.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 166	GFLOPS: 16560.33 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256494.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 167	GFLOPS: 16260.02 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256494.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 168	GFLOPS: 16033.16 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715256495.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 169	GFLOPS: 15285.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256495.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 170	GFLOPS: 16467.49 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715256495.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 171	GFLOPS: 15923.86 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256496.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 172	GFLOPS: 10290.35 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.42, Tstamp:1715256496.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 173	GFLOPS: 17661.67 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.08, Tstamp:1715256496.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 174	GFLOPS: 18962.63 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.86, Tstamp:1715256497.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 175	GFLOPS: 11691.22 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715256497.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 176	GFLOPS: 16548.32 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715256497.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 177	GFLOPS: 17678.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256498.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 178	GFLOPS: 16546.89 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715256498.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 179	GFLOPS: 16909.50 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.39, Tstamp:1715256498.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 180	GFLOPS: 15011.73 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715256499.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 181	GFLOPS: 16261.50 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715256499.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 182	GFLOPS: 15991.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715256499.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 183	GFLOPS: 16360.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256499.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 184	GFLOPS: 16188.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715256500.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 185	GFLOPS: 15414.32 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715256500.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 186	GFLOPS: 15842.69 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715256500.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 187	GFLOPS: 16110.36 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715256500.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 188	GFLOPS: 14936.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715256501.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 189	GFLOPS: 14896.49 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256501.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 190	GFLOPS: 1482.48 / 26725.48	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.60, Tstamp:1715256501.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 191	GFLOPS: 4449.63 / 26725.48	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.47, Tstamp:1715256502.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 192	GFLOPS: 4065.77 / 26725.48	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.67, Tstamp:1715256502.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 27.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.05 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1682	fail_ct: 366	Time elapsed: 2.52
GA Iter: 0	Max score: 0.8130	Min score: 0.3880	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8884	Min score: 0.6271	#Pop: 128	#M+: 1386	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 10.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 193	GFLOPS: 20968.89 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.78, Tstamp:1715256524.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 194	GFLOPS: 23498.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.71, Tstamp:1715256524.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 195	GFLOPS: 20236.42 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.87, Tstamp:1715256524.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 196	GFLOPS: 5223.92 / 26725.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.66, Tstamp:1715256525.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 197	GFLOPS: 18639.50 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.50, Tstamp:1715256525.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 198	GFLOPS: 12095.97 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.88, Tstamp:1715256525.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 199	GFLOPS: 17257.28 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715256526.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 200	GFLOPS: 17261.27 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715256526.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 201	GFLOPS: 17774.18 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.93, Tstamp:1715256526.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 202	GFLOPS: 17754.88 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715256527.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 203	GFLOPS: 17643.98 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715256527.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 204	GFLOPS: 26027.28 / 26725.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.84, Tstamp:1715256527.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 205	GFLOPS: 17622.54 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.00, Tstamp:1715256528.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 206	GFLOPS: 18757.45 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.66, Tstamp:1715256528.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 207	GFLOPS: 16127.09 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715256528.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 208	GFLOPS: 15752.90 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715256529.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 209	GFLOPS: 15961.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715256529.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 210	GFLOPS: 19074.99 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715256529.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 211	GFLOPS: 15865.15 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.19, Tstamp:1715256530.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 212	GFLOPS: 16193.97 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715256530.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 213	GFLOPS: 19838.07 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715256530.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 214	GFLOPS: 14063.02 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.38, Tstamp:1715256530.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 215	GFLOPS: 16216.84 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.23, Tstamp:1715256531.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 216	GFLOPS: 15998.99 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.06, Tstamp:1715256531.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 217	GFLOPS: 16192.41 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715256531.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 218	GFLOPS: 16070.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.00, Tstamp:1715256532.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 219	GFLOPS: 16189.57 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256532.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 220	GFLOPS: 23690.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.36, Tstamp:1715256532.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 221	GFLOPS: 16255.75 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715256532.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 222	GFLOPS: 22724.99 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.87, Tstamp:1715256533.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 223	GFLOPS: 18731.03 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.14, Tstamp:1715256533.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 224	GFLOPS: 20439.91 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.59, Tstamp:1715256533.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 225	GFLOPS: 17358.72 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715256534.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 226	GFLOPS: 17176.90 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256534.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 227	GFLOPS: 16386.61 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715256534.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 228	GFLOPS: 17853.72 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256535.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 229	GFLOPS: 17529.78 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715256535.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 230	GFLOPS: 14902.84 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.53, Tstamp:1715256535.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 231	GFLOPS: 15319.99 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715256536.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 232	GFLOPS: 16765.12 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256536.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 233	GFLOPS: 17321.11 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256536.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 234	GFLOPS: 14795.98 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715256536.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 235	GFLOPS: 22378.09 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.35, Tstamp:1715256537.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 236	GFLOPS: 17458.37 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256537.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 237	GFLOPS: 17275.15 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.39, Tstamp:1715256537.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 238	GFLOPS: 16765.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.77, Tstamp:1715256538.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 239	GFLOPS: 26173.99 / 26725.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715256538.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 240	GFLOPS: 15765.83 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256538.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 241	GFLOPS: 19690.18 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715256539.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 242	GFLOPS: 17933.00 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715256539.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 243	GFLOPS: 16154.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715256539.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 244	GFLOPS: 14685.37 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715256540.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 245	GFLOPS: 16332.88 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256540.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 246	GFLOPS: 18693.82 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715256540.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 247	GFLOPS: 16282.29 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.44, Tstamp:1715256540.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 248	GFLOPS: 11184.26 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.21, Tstamp:1715256541.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 249	GFLOPS: 17572.11 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256541.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 250	GFLOPS: 17871.95 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.39, Tstamp:1715256541.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 251	GFLOPS: 16162.78 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256542.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 252	GFLOPS: 17250.10 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715256542.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 253	GFLOPS: 16667.77 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.20, Tstamp:1715256542.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 254	GFLOPS: 3484.72 / 26725.48	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.50, Tstamp:1715256543.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 255	GFLOPS: 9789.77 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.09, Tstamp:1715256543.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 256	GFLOPS: 6325.46 / 26725.48	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.46, Tstamp:1715256543.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

Time elapsed for measurement: 27.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.87 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1666	fail_ct: 382	Time elapsed: 2.61
GA Iter: 0	Max score: 0.7744	Min score: 0.3833	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9427	Min score: 0.5860	#Pop: 128	#M+: 1388	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 10.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 257	GFLOPS: 25529.80 / 26725.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.44, Tstamp:1715256566.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 258	GFLOPS: 22632.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.48, Tstamp:1715256566.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 259	GFLOPS: 22647.29 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.56, Tstamp:1715256567.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 260	GFLOPS: 20789.78 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.62, Tstamp:1715256567.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 261	GFLOPS: 21621.97 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.34, Tstamp:1715256567.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 262	GFLOPS: 21389.00 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.26, Tstamp:1715256568.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 263	GFLOPS: 21213.89 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.41, Tstamp:1715256568.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 264	GFLOPS: 19203.89 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.12, Tstamp:1715256568.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 265	GFLOPS: 17164.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.25, Tstamp:1715256568.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 266	GFLOPS: 8096.12 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.20, Tstamp:1715256569.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 267	GFLOPS: 18907.55 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.66, Tstamp:1715256569.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 268	GFLOPS: 18890.50 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.64, Tstamp:1715256569.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 269	GFLOPS: 18129.38 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.14, Tstamp:1715256569.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 270	GFLOPS: 18135.88 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.59, Tstamp:1715256570.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 271	GFLOPS: 17838.70 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715256570.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 272	GFLOPS: 17732.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715256571.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 273	GFLOPS: 17482.69 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715256571.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 274	GFLOPS: 18112.10 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715256571.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 275	GFLOPS: 22513.48 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.66, Tstamp:1715256572.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 276	GFLOPS: 17855.97 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715256572.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 277	GFLOPS: 16340.47 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256572.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 278	GFLOPS: 16522.11 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715256573.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 279	GFLOPS: 17336.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256573.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 280	GFLOPS: 17954.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256573.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 281	GFLOPS: 16860.30 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715256574.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 282	GFLOPS: 17705.15 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715256574.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 283	GFLOPS: 17444.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256574.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 284	GFLOPS: 17769.77 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715256574.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 285	GFLOPS: 17529.45 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715256575.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 286	GFLOPS: 18098.96 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256575.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 287	GFLOPS: 18386.58 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715256575.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 288	GFLOPS: 22814.50 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.22, Tstamp:1715256576.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 289	GFLOPS: 17577.54 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715256576.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 290	GFLOPS: 17930.74 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715256576.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 291	GFLOPS: 18083.82 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256577.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 292	GFLOPS: 18247.43 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715256577.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 293	GFLOPS: 16889.79 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256577.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 294	GFLOPS: 17224.95 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256578.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 295	GFLOPS: 14939.69 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715256578.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 296	GFLOPS: 17521.24 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715256578.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 297	GFLOPS: 17799.19 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256579.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 298	GFLOPS: 17492.59 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256579.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 299	GFLOPS: 17517.04 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256579.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 300	GFLOPS: 15241.16 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.32, Tstamp:1715256580.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 301	GFLOPS: 16203.75 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256580.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 302	GFLOPS: 17658.87 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256580.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 303	GFLOPS: 16682.68 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715256581.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 304	GFLOPS: 16908.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715256581.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 305	GFLOPS: 16300.91 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.37, Tstamp:1715256581.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 306	GFLOPS: 19111.72 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256582.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 307	GFLOPS: 17050.60 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.35, Tstamp:1715256582.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 308	GFLOPS: 17916.81 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.37, Tstamp:1715256582.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 309	GFLOPS: 18660.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715256583.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 310	GFLOPS: 12221.13 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.40, Tstamp:1715256583.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 311	GFLOPS: 15841.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715256583.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 312	GFLOPS: 17842.15 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715256584.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 313	GFLOPS: 18520.89 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715256584.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 314	GFLOPS: 17704.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256584.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 315	GFLOPS: 17681.20 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256585.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 316	GFLOPS: 17562.50 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256585.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 317	GFLOPS: 14756.84 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715256585.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 318	GFLOPS: 1616.03 / 26725.48	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:2.63, Tstamp:1715256586.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 319	GFLOPS: 2519.19 / 26725.48	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.99, Tstamp:1715256586.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 320	GFLOPS: 5368.49 / 26725.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.58, Tstamp:1715256586.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,192)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 29.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.89 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1654	fail_ct: 394	Time elapsed: 2.55
GA Iter: 0	Max score: 0.6421	Min score: 0.3711	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7677	Min score: 0.5757	#Pop: 128	#M+: 1384	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 10.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 321	GFLOPS: 4284.42 / 26725.48	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.40, Tstamp:1715256607.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 322	GFLOPS: 5262.92 / 26725.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.03, Tstamp:1715256608.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 323	GFLOPS: 18552.20 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.62, Tstamp:1715256608.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 324	GFLOPS: 15924.83 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715256608.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 325	GFLOPS: 18781.32 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.06, Tstamp:1715256609.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 326	GFLOPS: 18831.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.97, Tstamp:1715256609.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 327	GFLOPS: 22310.25 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715256609.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 328	GFLOPS: 15493.43 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.73, Tstamp:1715256610.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 329	GFLOPS: 17981.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.68, Tstamp:1715256610.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 330	GFLOPS: 16263.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.79, Tstamp:1715256610.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 331	GFLOPS: 18375.77 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.16, Tstamp:1715256610.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 332	GFLOPS: 15624.98 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.07, Tstamp:1715256611.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 333	GFLOPS: 16167.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715256611.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 334	GFLOPS: 17264.54 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.46, Tstamp:1715256611.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 335	GFLOPS: 18515.12 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.13, Tstamp:1715256612.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 336	GFLOPS: 16087.35 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.26, Tstamp:1715256612.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 337	GFLOPS: 16271.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715256612.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 338	GFLOPS: 16066.37 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715256613.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 339	GFLOPS: 15826.44 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715256613.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 340	GFLOPS: 16296.07 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715256613.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 341	GFLOPS: 16336.29 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.93, Tstamp:1715256613.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 342	GFLOPS: 16410.54 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715256614.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 343	GFLOPS: 18698.55 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.20, Tstamp:1715256614.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 344	GFLOPS: 16312.41 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715256614.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 345	GFLOPS: 16164.83 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.06, Tstamp:1715256614.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 346	GFLOPS: 16606.96 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715256615.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 347	GFLOPS: 14502.63 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715256615.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 348	GFLOPS: 14500.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715256616.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 349	GFLOPS: 13976.40 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715256616.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 350	GFLOPS: 14390.52 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715256616.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 351	GFLOPS: 14416.94 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715256616.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 352	GFLOPS: 16684.67 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715256617.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 353	GFLOPS: 17325.67 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715256617.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 354	GFLOPS: 16475.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715256617.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 355	GFLOPS: 16153.70 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715256618.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 356	GFLOPS: 15104.63 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715256618.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 357	GFLOPS: 16263.87 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.78, Tstamp:1715256618.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 358	GFLOPS: 14076.98 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.44, Tstamp:1715256619.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 359	GFLOPS: 16978.30 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715256619.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 360	GFLOPS: 15805.67 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715256619.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 361	GFLOPS: 16597.95 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715256620.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 362	GFLOPS: 16880.18 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256620.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 363	GFLOPS: 15961.74 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.19, Tstamp:1715256620.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 364	GFLOPS: 16278.34 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715256620.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 365	GFLOPS: 13288.87 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.24, Tstamp:1715256621.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 366	GFLOPS: 16329.60 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715256621.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 367	GFLOPS: 9803.40 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.51, Tstamp:1715256621.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 368	GFLOPS: 16550.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256622.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 369	GFLOPS: 15850.44 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256622.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 370	GFLOPS: 16306.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715256622.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 371	GFLOPS: 14533.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715256623.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 372	GFLOPS: 16751.33 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256623.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 373	GFLOPS: 19026.04 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715256623.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 374	GFLOPS: 24539.12 / 26725.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715256624.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 375	GFLOPS: 15890.22 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715256624.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 376	GFLOPS: 16593.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256624.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 377	GFLOPS: 14163.44 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715256625.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 378	GFLOPS: 13925.07 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715256625.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 379	GFLOPS: 16312.59 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256625.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 380	GFLOPS: 16440.56 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256626.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 381	GFLOPS: 16106.33 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256626.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 382	GFLOPS: 12529.55 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715256626.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 383	GFLOPS: 5737.21 / 26725.48	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.76, Tstamp:1715256627.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,48)
      compute = ...

==================================================
No: 384	GFLOPS: 2513.57 / 26725.48	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.48, Tstamp:1715256627.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

Time elapsed for measurement: 26.78 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.90 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1651	fail_ct: 397	Time elapsed: 2.55
GA Iter: 0	Max score: 0.6028	Min score: 0.3662	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8347	Min score: 0.5338	#Pop: 128	#M+: 1375	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 10.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 385	GFLOPS: 22331.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.26, Tstamp:1715256648.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 386	GFLOPS: 11857.23 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.24, Tstamp:1715256648.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 387	GFLOPS: 10358.61 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.39, Tstamp:1715256649.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 388	GFLOPS: 10729.13 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.62, Tstamp:1715256649.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 389	GFLOPS: 16156.25 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715256649.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 390	GFLOPS: 16487.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.60, Tstamp:1715256650.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 391	GFLOPS: 16526.74 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.14, Tstamp:1715256650.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 392	GFLOPS: 16083.52 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.18, Tstamp:1715256650.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 393	GFLOPS: 16930.54 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.59, Tstamp:1715256651.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 394	GFLOPS: 16381.58 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.06, Tstamp:1715256651.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 395	GFLOPS: 16154.98 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256651.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 396	GFLOPS: 16327.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715256652.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 397	GFLOPS: 16422.69 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715256652.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 398	GFLOPS: 16078.20 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715256652.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 399	GFLOPS: 16956.03 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256653.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 400	GFLOPS: 16637.99 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715256653.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 401	GFLOPS: 15988.34 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715256653.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 402	GFLOPS: 16918.70 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715256654.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 403	GFLOPS: 16400.68 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715256654.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 404	GFLOPS: 15368.24 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715256654.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 405	GFLOPS: 15339.76 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715256654.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 406	GFLOPS: 15187.02 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.91, Tstamp:1715256655.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 407	GFLOPS: 15323.87 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.99, Tstamp:1715256655.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 408	GFLOPS: 16243.78 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.77, Tstamp:1715256655.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 409	GFLOPS: 15094.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256656.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 410	GFLOPS: 14446.77 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256656.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 411	GFLOPS: 16597.70 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715256656.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 412	GFLOPS: 16445.04 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715256657.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 413	GFLOPS: 17912.43 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715256657.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 414	GFLOPS: 15187.82 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715256657.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 415	GFLOPS: 15390.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715256657.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 416	GFLOPS: 16339.04 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256658.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 417	GFLOPS: 17671.23 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715256658.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 418	GFLOPS: 16367.60 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256658.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 419	GFLOPS: 16509.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715256659.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 420	GFLOPS: 16415.35 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256659.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 421	GFLOPS: 17039.42 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256660.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 422	GFLOPS: 16532.30 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715256660.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 423	GFLOPS: 16585.83 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715256660.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 424	GFLOPS: 16057.06 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256661.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 425	GFLOPS: 16285.20 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256661.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 426	GFLOPS: 13377.40 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715256661.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 427	GFLOPS: 16709.32 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715256661.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 428	GFLOPS: 16034.97 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256662.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 429	GFLOPS: 15485.36 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256662.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 430	GFLOPS: 16117.41 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256662.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 431	GFLOPS: 16279.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715256663.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 432	GFLOPS: 15195.58 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715256663.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 433	GFLOPS: 15427.25 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715256663.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 434	GFLOPS: 15033.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715256664.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 435	GFLOPS: 13095.43 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715256664.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 436	GFLOPS: 16439.06 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715256664.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 437	GFLOPS: 11755.55 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715256665.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 438	GFLOPS: 11536.31 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715256665.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 439	GFLOPS: 16531.81 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715256665.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 440	GFLOPS: 16071.10 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.20, Tstamp:1715256665.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 441	GFLOPS: 10660.85 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715256666.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 442	GFLOPS: 15747.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715256666.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 443	GFLOPS: 16564.01 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715256666.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 444	GFLOPS: 13842.29 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715256667.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,24)
    compute = ...

==================================================
No: 445	GFLOPS: 13785.85 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715256667.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 446	GFLOPS: 4204.48 / 26725.48	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.55, Tstamp:1715256667.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 447	GFLOPS: 19110.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.33, Tstamp:1715256667.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,24)
      compute = ...

==================================================
No: 448	GFLOPS: 1065.70 / 26725.48	results: MeasureResult(cost:[0.0034], error_no:0, all_cost:0.89, Tstamp:1715256668.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 27.08 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.12 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1662	fail_ct: 386	Time elapsed: 2.58
GA Iter: 0	Max score: 0.7251	Min score: 0.3794	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7251	Min score: 0.5062	#Pop: 128	#M+: 1381	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 449	GFLOPS: 10176.86 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.87, Tstamp:1715256689.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 450	GFLOPS: 16560.77 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.42, Tstamp:1715256689.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 451	GFLOPS: 17394.28 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715256690.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 452	GFLOPS: 17508.95 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.00, Tstamp:1715256690.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 453	GFLOPS: 18441.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.27, Tstamp:1715256690.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 454	GFLOPS: 10214.99 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.98, Tstamp:1715256690.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 455	GFLOPS: 16043.79 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715256691.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 456	GFLOPS: 16383.77 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715256691.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 457	GFLOPS: 16384.86 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.21, Tstamp:1715256691.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 458	GFLOPS: 16339.86 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715256692.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 459	GFLOPS: 15275.81 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.76, Tstamp:1715256692.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 460	GFLOPS: 16299.09 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715256692.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 461	GFLOPS: 16218.30 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715256693.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 462	GFLOPS: 17205.69 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.70, Tstamp:1715256693.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,24)
      compute = ...

==================================================
No: 463	GFLOPS: 16437.02 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.50, Tstamp:1715256693.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,24)
      compute = ...

==================================================
No: 464	GFLOPS: 16184.79 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715256693.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 465	GFLOPS: 15142.03 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715256694.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 466	GFLOPS: 16915.54 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.46, Tstamp:1715256694.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 467	GFLOPS: 14954.58 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715256694.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 468	GFLOPS: 15062.57 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715256695.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 469	GFLOPS: 14967.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715256695.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 470	GFLOPS: 14931.68 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256695.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 471	GFLOPS: 14956.04 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715256696.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 472	GFLOPS: 10215.30 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.81, Tstamp:1715256696.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 473	GFLOPS: 15097.56 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715256696.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 474	GFLOPS: 15324.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.55, Tstamp:1715256697.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 475	GFLOPS: 15593.73 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256697.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 476	GFLOPS: 16957.18 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.34, Tstamp:1715256697.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 477	GFLOPS: 15148.03 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715256697.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 478	GFLOPS: 15320.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256698.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 479	GFLOPS: 15341.10 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715256698.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 480	GFLOPS: 15380.47 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715256699.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 481	GFLOPS: 15153.52 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715256699.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 482	GFLOPS: 15115.75 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715256699.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 483	GFLOPS: 14877.43 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.13, Tstamp:1715256699.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 484	GFLOPS: 14589.28 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715256700.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 485	GFLOPS: 14785.70 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715256700.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 486	GFLOPS: 15174.82 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715256700.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 487	GFLOPS: 14764.16 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715256701.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 488	GFLOPS: 14425.80 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715256701.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 489	GFLOPS: 14738.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.77, Tstamp:1715256701.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 490	GFLOPS: 15136.74 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.54, Tstamp:1715256702.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 491	GFLOPS: 15580.41 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256702.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 492	GFLOPS: 16246.24 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715256702.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 493	GFLOPS: 16158.64 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715256703.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 494	GFLOPS: 15755.36 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.26, Tstamp:1715256703.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 495	GFLOPS: 15839.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.78, Tstamp:1715256703.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 496	GFLOPS: 15734.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256704.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 497	GFLOPS: 15096.52 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715256704.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 498	GFLOPS: 14995.11 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256704.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 499	GFLOPS: 17648.87 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.35, Tstamp:1715256704.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 500	GFLOPS: 14104.33 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715256705.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 501	GFLOPS: 13298.82 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715256705.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 502	GFLOPS: 12717.72 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.54, Tstamp:1715256705.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 503	GFLOPS: 13425.77 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715256706.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 504	GFLOPS: 13532.91 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.38, Tstamp:1715256706.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 505	GFLOPS: 13280.67 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715256706.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 506	GFLOPS: 13837.85 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715256707.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 507	GFLOPS: 16064.63 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.37, Tstamp:1715256707.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 508	GFLOPS: 14278.32 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715256707.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 509	GFLOPS: 14229.95 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715256707.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 510	GFLOPS: 971.08 / 26725.48	results: MeasureResult(cost:[0.0037], error_no:0, all_cost:0.54, Tstamp:1715256708.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 511	GFLOPS: 8496.45 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.42, Tstamp:1715256708.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 512	GFLOPS: 924.52 / 26725.48	results: MeasureResult(cost:[0.0039], error_no:0, all_cost:0.51, Tstamp:1715256708.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 26.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.82 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1667	fail_ct: 381	Time elapsed: 2.56
GA Iter: 0	Max score: 0.5868	Min score: 0.3682	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6559	Min score: 0.4766	#Pop: 128	#M+: 1390	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 10.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 513	GFLOPS: 7722.24 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.83, Tstamp:1715256731.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 514	GFLOPS: 7068.18 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.75, Tstamp:1715256731.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,24)
      compute = ...

==================================================
No: 515	GFLOPS: 6593.91 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.66, Tstamp:1715256732.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,24)
      compute = ...

==================================================
No: 516	GFLOPS: 16206.02 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.71, Tstamp:1715256732.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,24)
      compute = ...

==================================================
No: 517	GFLOPS: 16067.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.52, Tstamp:1715256732.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 518	GFLOPS: 16377.42 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715256732.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,24)
      compute = ...

==================================================
No: 519	GFLOPS: 16197.74 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.06, Tstamp:1715256733.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 520	GFLOPS: 16108.14 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.21, Tstamp:1715256733.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 521	GFLOPS: 13875.26 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.51, Tstamp:1715256733.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 522	GFLOPS: 16374.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.56, Tstamp:1715256734.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,24)
      compute = ...

==================================================
No: 523	GFLOPS: 8425.84 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.73, Tstamp:1715256734.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for c (0,16)
      compute = ...
  compute = ...

==================================================
No: 524	GFLOPS: 14491.61 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.30, Tstamp:1715256734.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 525	GFLOPS: 15650.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.69, Tstamp:1715256735.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 526	GFLOPS: 15959.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.93, Tstamp:1715256735.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 527	GFLOPS: 16834.98 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.16, Tstamp:1715256735.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 528	GFLOPS: 12373.45 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715256736.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 529	GFLOPS: 12428.04 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715256736.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 530	GFLOPS: 12176.96 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.06, Tstamp:1715256736.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 531	GFLOPS: 15283.83 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.51, Tstamp:1715256736.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 532	GFLOPS: 14457.93 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.99, Tstamp:1715256737.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 533	GFLOPS: 12876.04 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.68, Tstamp:1715256737.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 534	GFLOPS: 11246.17 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715256737.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 535	GFLOPS: 14948.97 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256738.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 536	GFLOPS: 14648.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715256738.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 537	GFLOPS: 13333.71 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.49, Tstamp:1715256738.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 538	GFLOPS: 14953.40 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715256739.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 539	GFLOPS: 14822.83 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715256739.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 540	GFLOPS: 12317.46 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715256739.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 541	GFLOPS: 12363.26 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715256740.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 542	GFLOPS: 8058.55 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.45, Tstamp:1715256740.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for c (0,16)
      compute = ...
  compute = ...

==================================================
No: 543	GFLOPS: 13637.76 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715256740.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 544	GFLOPS: 12268.74 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715256741.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 545	GFLOPS: 14453.53 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715256741.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 546	GFLOPS: 14064.94 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.88, Tstamp:1715256741.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 547	GFLOPS: 14967.57 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.03, Tstamp:1715256742.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 548	GFLOPS: 14590.49 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.03, Tstamp:1715256742.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 549	GFLOPS: 15240.12 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715256742.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 550	GFLOPS: 15044.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715256743.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 551	GFLOPS: 14835.39 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715256743.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 552	GFLOPS: 15082.24 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715256743.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 553	GFLOPS: 14983.12 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715256743.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 554	GFLOPS: 12748.37 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.00, Tstamp:1715256744.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 555	GFLOPS: 14400.78 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715256744.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 556	GFLOPS: 13950.85 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715256744.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 557	GFLOPS: 13876.12 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715256745.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 558	GFLOPS: 14666.36 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715256745.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 559	GFLOPS: 14634.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256745.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 560	GFLOPS: 15018.73 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256746.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 561	GFLOPS: 14946.73 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715256746.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 562	GFLOPS: 14607.82 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256746.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 563	GFLOPS: 14325.71 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.81, Tstamp:1715256747.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 564	GFLOPS: 14008.94 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715256747.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,24)
      compute = ...

==================================================
No: 565	GFLOPS: 14427.82 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715256748.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 566	GFLOPS: 9240.37 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.22, Tstamp:1715256748.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 567	GFLOPS: 13108.57 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715256748.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 568	GFLOPS: 13369.01 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715256748.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 569	GFLOPS: 13641.69 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715256749.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 570	GFLOPS: 13486.33 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715256749.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 571	GFLOPS: 12924.77 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715256749.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 572	GFLOPS: 13481.97 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715256750.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 573	GFLOPS: 13203.64 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715256750.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 574	GFLOPS: 2004.06 / 26725.48	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.33, Tstamp:1715256750.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 575	GFLOPS: 3263.63 / 26725.48	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:2.79, Tstamp:1715256751.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 576	GFLOPS: 1963.08 / 26725.48	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.43, Tstamp:1715256751.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 29.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.86 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1656	fail_ct: 392	Time elapsed: 2.55
GA Iter: 0	Max score: 0.5222	Min score: 0.3609	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6624	Min score: 0.4603	#Pop: 128	#M+: 1387	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 10.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 577	GFLOPS: 4268.64 / 26725.48	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:3.08, Tstamp:1715256772.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 578	GFLOPS: 16120.25 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.17, Tstamp:1715256772.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 579	GFLOPS: 15913.34 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715256773.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 580	GFLOPS: 14717.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715256773.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 581	GFLOPS: 11534.38 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.30, Tstamp:1715256773.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 582	GFLOPS: 15010.75 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715256774.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 583	GFLOPS: 15033.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.30, Tstamp:1715256774.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 584	GFLOPS: 14663.76 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.23, Tstamp:1715256774.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 585	GFLOPS: 14674.49 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715256775.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 586	GFLOPS: 15329.33 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.20, Tstamp:1715256775.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 587	GFLOPS: 14698.33 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715256775.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 588	GFLOPS: 13970.45 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.41, Tstamp:1715256776.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 589	GFLOPS: 15275.27 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.54, Tstamp:1715256776.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 590	GFLOPS: 16275.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.93, Tstamp:1715256776.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 591	GFLOPS: 13852.54 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.39, Tstamp:1715256777.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 592	GFLOPS: 14021.46 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.14, Tstamp:1715256777.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 593	GFLOPS: 14025.19 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715256777.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 594	GFLOPS: 17545.92 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715256778.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 595	GFLOPS: 14463.98 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715256778.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 596	GFLOPS: 13738.60 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715256778.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,24)
    compute = ...

==================================================
No: 597	GFLOPS: 13597.26 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.37, Tstamp:1715256778.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 598	GFLOPS: 19914.62 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.71, Tstamp:1715256779.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 599	GFLOPS: 13981.08 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715256779.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 600	GFLOPS: 17714.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.88, Tstamp:1715256779.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 601	GFLOPS: 12545.10 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.06, Tstamp:1715256780.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 602	GFLOPS: 12745.08 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715256780.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 603	GFLOPS: 12957.07 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.99, Tstamp:1715256780.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 604	GFLOPS: 13237.08 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715256781.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 605	GFLOPS: 6928.47 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.60, Tstamp:1715256781.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 606	GFLOPS: 13725.11 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256781.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 607	GFLOPS: 13362.01 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715256781.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 608	GFLOPS: 13173.16 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715256782.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 609	GFLOPS: 13644.51 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.33, Tstamp:1715256782.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 610	GFLOPS: 13295.35 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715256782.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 611	GFLOPS: 22481.13 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.30, Tstamp:1715256783.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 612	GFLOPS: 13132.18 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715256783.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 613	GFLOPS: 12970.33 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715256783.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 614	GFLOPS: 13151.80 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715256784.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 615	GFLOPS: 20473.06 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.46, Tstamp:1715256784.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 616	GFLOPS: 12172.43 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715256784.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 617	GFLOPS: 11044.28 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715256785.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 618	GFLOPS: 6586.35 / 26725.48	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.53, Tstamp:1715256785.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,24)
      compute = ...

==================================================
No: 619	GFLOPS: 17894.02 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256785.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 620	GFLOPS: 13332.30 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715256785.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 621	GFLOPS: 17459.41 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.11, Tstamp:1715256786.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 622	GFLOPS: 17205.34 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.33, Tstamp:1715256786.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 623	GFLOPS: 13157.13 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715256786.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,24)
      compute = ...

==================================================
No: 624	GFLOPS: 13158.96 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715256786.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 625	GFLOPS: 7830.09 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.46, Tstamp:1715256787.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 626	GFLOPS: 13981.49 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.24, Tstamp:1715256787.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,8)
      compute = ...

==================================================
No: 627	GFLOPS: 12054.00 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715256787.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,24)
      compute = ...

==================================================
No: 628	GFLOPS: 13107.22 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715256788.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 629	GFLOPS: 11718.47 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715256788.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 630	GFLOPS: 12558.22 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715256788.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 631	GFLOPS: 11262.71 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715256788.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 632	GFLOPS: 12084.01 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715256789.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 633	GFLOPS: 12701.05 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715256789.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 634	GFLOPS: 11956.64 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715256789.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 635	GFLOPS: 12379.02 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.49, Tstamp:1715256790.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 636	GFLOPS: 12415.45 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.54, Tstamp:1715256790.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 637	GFLOPS: 13084.07 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715256790.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 638	GFLOPS: 2753.77 / 26725.48	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:1.06, Tstamp:1715256791.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 639	GFLOPS: 5056.59 / 26725.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.43, Tstamp:1715256791.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 640	GFLOPS: 2028.12 / 26725.48	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.46, Tstamp:1715256791.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 26.67 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.80 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1686	fail_ct: 362	Time elapsed: 2.54
GA Iter: 0	Max score: 0.7355	Min score: 0.3549	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7821	Min score: 0.4751	#Pop: 128	#M+: 1391	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 641	GFLOPS: 9953.44 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.52, Tstamp:1715256812.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 642	GFLOPS: 18330.86 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.32, Tstamp:1715256812.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 643	GFLOPS: 20705.73 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.74, Tstamp:1715256813.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 644	GFLOPS: 7877.64 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.39, Tstamp:1715256813.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 645	GFLOPS: 10487.15 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.63, Tstamp:1715256813.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 646	GFLOPS: 19633.73 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715256814.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 647	GFLOPS: 9696.59 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.20, Tstamp:1715256814.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 648	GFLOPS: 18780.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.01, Tstamp:1715256814.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 649	GFLOPS: 18314.02 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715256815.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 650	GFLOPS: 16515.43 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.37, Tstamp:1715256815.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 651	GFLOPS: 7373.51 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.85, Tstamp:1715256815.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 652	GFLOPS: 16268.41 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.78, Tstamp:1715256816.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 653	GFLOPS: 15210.03 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.92, Tstamp:1715256816.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 654	GFLOPS: 16372.76 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.98, Tstamp:1715256816.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 655	GFLOPS: 15508.72 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.82, Tstamp:1715256817.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 656	GFLOPS: 14655.76 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.33, Tstamp:1715256817.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 657	GFLOPS: 16412.81 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.92, Tstamp:1715256817.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 658	GFLOPS: 16969.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.73, Tstamp:1715256818.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 659	GFLOPS: 15775.26 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.70, Tstamp:1715256818.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 660	GFLOPS: 14769.97 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.57, Tstamp:1715256818.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 661	GFLOPS: 16515.16 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.59, Tstamp:1715256819.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 662	GFLOPS: 13180.66 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.69, Tstamp:1715256819.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 663	GFLOPS: 17627.27 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.74, Tstamp:1715256819.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 664	GFLOPS: 16551.86 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.62, Tstamp:1715256820.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 665	GFLOPS: 15974.43 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.79, Tstamp:1715256820.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 666	GFLOPS: 14605.35 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715256820.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 667	GFLOPS: 14994.23 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.89, Tstamp:1715256820.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 668	GFLOPS: 14751.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.75, Tstamp:1715256821.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 669	GFLOPS: 14807.57 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715256821.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 670	GFLOPS: 12894.04 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.50, Tstamp:1715256821.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 671	GFLOPS: 16535.35 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715256822.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 672	GFLOPS: 14925.79 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715256822.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 673	GFLOPS: 16688.60 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715256822.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 674	GFLOPS: 16892.65 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715256822.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 675	GFLOPS: 17260.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.35, Tstamp:1715256823.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 676	GFLOPS: 13775.64 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.48, Tstamp:1715256823.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,24)
      compute = ...

==================================================
No: 677	GFLOPS: 16555.48 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715256823.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 678	GFLOPS: 11172.24 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.13, Tstamp:1715256823.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 679	GFLOPS: 20724.19 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715256824.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 680	GFLOPS: 16743.88 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715256824.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 681	GFLOPS: 15024.99 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715256824.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 682	GFLOPS: 15061.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715256825.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 683	GFLOPS: 12701.55 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.18, Tstamp:1715256825.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 684	GFLOPS: 14072.10 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715256825.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 685	GFLOPS: 11306.22 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.26, Tstamp:1715256826.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 686	GFLOPS: 10187.52 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.13, Tstamp:1715256826.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 687	GFLOPS: 12379.20 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715256826.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 688	GFLOPS: 9890.15 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.27, Tstamp:1715256826.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 689	GFLOPS: 11274.81 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.81, Tstamp:1715256827.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 690	GFLOPS: 14221.01 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715256827.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 691	GFLOPS: 14410.51 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715256827.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 692	GFLOPS: 14318.46 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715256828.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 693	GFLOPS: 15205.22 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715256828.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 694	GFLOPS: 14565.14 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715256828.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 695	GFLOPS: 13698.07 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.24, Tstamp:1715256828.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 696	GFLOPS: 14073.90 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715256829.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 697	GFLOPS: 15126.59 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715256829.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 698	GFLOPS: 15125.09 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715256829.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 699	GFLOPS: 15050.16 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715256830.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 700	GFLOPS: 13221.68 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715256830.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 701	GFLOPS: 14189.05 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715256830.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 702	GFLOPS: 11754.69 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715256831.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 703	GFLOPS: 3790.98 / 26725.48	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.37, Tstamp:1715256831.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 704	GFLOPS: 1355.01 / 26725.48	results: MeasureResult(cost:[0.0027], error_no:0, all_cost:0.53, Tstamp:1715256831.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 26.59 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.86 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1654	fail_ct: 394	Time elapsed: 2.58
GA Iter: 0	Max score: 0.6906	Min score: 0.3460	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7505	Min score: 0.4641	#Pop: 128	#M+: 1384	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 10.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 705	GFLOPS: 10142.96 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.99, Tstamp:1715256853.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 706	GFLOPS: 14931.49 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.27, Tstamp:1715256853.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 707	GFLOPS: 19771.28 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.20, Tstamp:1715256853.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 708	GFLOPS: 21859.01 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:3.26, Tstamp:1715256854.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 709	GFLOPS: 16202.26 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715256854.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 710	GFLOPS: 12463.90 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.28, Tstamp:1715256854.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 711	GFLOPS: 12419.66 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.36, Tstamp:1715256854.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 712	GFLOPS: 15578.79 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.10, Tstamp:1715256855.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 713	GFLOPS: 12768.07 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.20, Tstamp:1715256855.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 714	GFLOPS: 16522.64 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.85, Tstamp:1715256856.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 715	GFLOPS: 16205.36 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.25, Tstamp:1715256856.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 716	GFLOPS: 15566.46 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.13, Tstamp:1715256856.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 717	GFLOPS: 15798.64 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.22, Tstamp:1715256856.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 718	GFLOPS: 16272.57 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715256857.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 719	GFLOPS: 15982.80 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.24, Tstamp:1715256857.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 720	GFLOPS: 14862.47 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.91, Tstamp:1715256857.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 721	GFLOPS: 13868.76 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.17, Tstamp:1715256858.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,24)
      compute = ...

==================================================
No: 722	GFLOPS: 14487.55 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.71, Tstamp:1715256858.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 723	GFLOPS: 15818.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.15, Tstamp:1715256858.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 724	GFLOPS: 14919.17 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.00, Tstamp:1715256859.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 725	GFLOPS: 18369.77 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.30, Tstamp:1715256859.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 726	GFLOPS: 13838.24 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.53, Tstamp:1715256859.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 727	GFLOPS: 12697.15 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.97, Tstamp:1715256860.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 728	GFLOPS: 14157.72 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.44, Tstamp:1715256860.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 729	GFLOPS: 14299.65 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.42, Tstamp:1715256860.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 730	GFLOPS: 14151.94 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.33, Tstamp:1715256861.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 731	GFLOPS: 13682.37 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715256861.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 732	GFLOPS: 17567.91 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715256861.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 733	GFLOPS: 13757.40 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.44, Tstamp:1715256861.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 734	GFLOPS: 13849.75 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715256862.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 735	GFLOPS: 13021.89 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715256862.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 736	GFLOPS: 13194.03 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.15, Tstamp:1715256862.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 737	GFLOPS: 9723.52 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.82, Tstamp:1715256863.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 738	GFLOPS: 14113.56 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.90, Tstamp:1715256863.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 739	GFLOPS: 14386.31 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715256863.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 740	GFLOPS: 14345.31 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715256864.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 741	GFLOPS: 14050.52 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715256864.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 742	GFLOPS: 14258.96 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715256864.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 743	GFLOPS: 13969.48 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715256865.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 744	GFLOPS: 14194.87 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715256865.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 745	GFLOPS: 16202.23 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715256865.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 746	GFLOPS: 14057.51 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256865.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 747	GFLOPS: 14247.94 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715256866.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 748	GFLOPS: 14169.62 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256866.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 749	GFLOPS: 9086.86 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.26, Tstamp:1715256866.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,24)
      compute = ...

==================================================
No: 750	GFLOPS: 14009.75 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715256867.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 751	GFLOPS: 14208.74 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715256867.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 752	GFLOPS: 14235.79 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715256867.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 753	GFLOPS: 16180.05 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715256868.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 754	GFLOPS: 16066.23 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715256868.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 755	GFLOPS: 16135.37 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715256868.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 756	GFLOPS: 16134.72 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256869.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 757	GFLOPS: 13233.26 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715256869.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 758	GFLOPS: 13278.61 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715256869.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 759	GFLOPS: 11426.66 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.07, Tstamp:1715256870.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,24)
      compute = ...

==================================================
No: 760	GFLOPS: 13405.56 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715256870.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 761	GFLOPS: 12822.59 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715256870.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 762	GFLOPS: 13316.68 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256871.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 763	GFLOPS: 13337.21 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715256871.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 764	GFLOPS: 13534.21 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715256871.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 765	GFLOPS: 13410.54 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715256872.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 766	GFLOPS: 2755.95 / 26725.48	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.37, Tstamp:1715256872.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 767	GFLOPS: 1305.15 / 26725.48	results: MeasureResult(cost:[0.0028], error_no:0, all_cost:0.86, Tstamp:1715256872.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 768	GFLOPS: 4170.31 / 26725.48	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.52, Tstamp:1715256872.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

Time elapsed for measurement: 27.44 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.88 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1658	fail_ct: 390	Time elapsed: 2.53
GA Iter: 0	Max score: 0.5874	Min score: 0.3431	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7549	Min score: 0.4553	#Pop: 128	#M+: 1379	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 769	GFLOPS: 5752.29 / 26725.48	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.82, Tstamp:1715256894.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 770	GFLOPS: 15404.44 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715256895.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 771	GFLOPS: 18800.94 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.18, Tstamp:1715256895.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 772	GFLOPS: 15946.72 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715256895.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 773	GFLOPS: 17925.51 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.54, Tstamp:1715256896.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 774	GFLOPS: 20024.22 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.84, Tstamp:1715256896.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 775	GFLOPS: 15773.98 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.33, Tstamp:1715256896.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 776	GFLOPS: 15830.85 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.81, Tstamp:1715256897.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 777	GFLOPS: 8729.20 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.82, Tstamp:1715256897.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 778	GFLOPS: 7657.59 / 26725.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.90, Tstamp:1715256897.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 779	GFLOPS: 14834.87 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.17, Tstamp:1715256897.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 780	GFLOPS: 15633.52 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.17, Tstamp:1715256898.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 781	GFLOPS: 17428.81 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.21, Tstamp:1715256898.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 782	GFLOPS: 26042.94 / 26725.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.13, Tstamp:1715256899.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 783	GFLOPS: 11954.64 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.73, Tstamp:1715256899.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 784	GFLOPS: 5030.48 / 26725.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.78, Tstamp:1715256899.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 785	GFLOPS: 16115.60 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.21, Tstamp:1715256899.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 786	GFLOPS: 8308.25 / 26725.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.39, Tstamp:1715256900.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 787	GFLOPS: 12596.82 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.22, Tstamp:1715256900.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 788	GFLOPS: 14697.27 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256901.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 789	GFLOPS: 15477.66 / 26725.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715256901.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 790	GFLOPS: 13560.26 / 26725.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715256901.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 791	GFLOPS: 26941.30 / 26941.30	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.02, Tstamp:1715256901.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 792	GFLOPS: 12098.40 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.13, Tstamp:1715256902.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 793	GFLOPS: 10618.80 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.16, Tstamp:1715256902.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 794	GFLOPS: 24320.27 / 26941.30	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.64, Tstamp:1715256902.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 795	GFLOPS: 13784.87 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.44, Tstamp:1715256903.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 796	GFLOPS: 13930.08 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715256903.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 797	GFLOPS: 13452.39 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715256903.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 798	GFLOPS: 13671.87 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.66, Tstamp:1715256904.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 799	GFLOPS: 13829.57 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715256904.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 800	GFLOPS: 8217.63 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.51, Tstamp:1715256904.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 801	GFLOPS: 12544.42 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.67, Tstamp:1715256905.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 802	GFLOPS: 12948.80 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715256905.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 803	GFLOPS: 13797.05 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.83, Tstamp:1715256905.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 804	GFLOPS: 13216.91 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715256905.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 805	GFLOPS: 13802.46 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.60, Tstamp:1715256906.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 806	GFLOPS: 11467.84 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.40, Tstamp:1715256906.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,24)
      compute = ...

==================================================
No: 807	GFLOPS: 13527.05 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715256906.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 808	GFLOPS: 13173.04 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715256907.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 809	GFLOPS: 12981.11 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.29, Tstamp:1715256907.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 810	GFLOPS: 13249.08 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715256907.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 811	GFLOPS: 13111.00 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.46, Tstamp:1715256908.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 812	GFLOPS: 9736.53 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.94, Tstamp:1715256908.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 813	GFLOPS: 11996.73 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715256908.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 814	GFLOPS: 13387.65 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715256908.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 815	GFLOPS: 13449.74 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715256909.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 816	GFLOPS: 12555.59 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.40, Tstamp:1715256909.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 817	GFLOPS: 15896.71 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.08, Tstamp:1715256909.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 818	GFLOPS: 13052.74 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.40, Tstamp:1715256910.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 819	GFLOPS: 11509.78 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.08, Tstamp:1715256910.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 820	GFLOPS: 12530.54 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715256910.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 821	GFLOPS: 16354.57 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.93, Tstamp:1715256910.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 822	GFLOPS: 13373.93 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715256911.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 823	GFLOPS: 11307.71 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715256911.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 824	GFLOPS: 13196.14 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715256912.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 825	GFLOPS: 12554.47 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715256912.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 826	GFLOPS: 12984.71 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715256912.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 827	GFLOPS: 11752.94 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.11, Tstamp:1715256912.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 828	GFLOPS: 12712.19 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715256913.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,24)
      compute = ...

==================================================
No: 829	GFLOPS: 12465.39 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.27, Tstamp:1715256913.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 830	GFLOPS: 8541.79 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.56, Tstamp:1715256913.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 831	GFLOPS: 8740.09 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.47, Tstamp:1715256913.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 832	GFLOPS: 1778.42 / 26941.30	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.73, Tstamp:1715256914.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 27.81 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.91 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1644	fail_ct: 404	Time elapsed: 2.51
GA Iter: 0	Max score: 0.5772	Min score: 0.3382	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8758	Min score: 0.4759	#Pop: 128	#M+: 1384	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 10.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 833	GFLOPS: 11366.74 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:4.07, Tstamp:1715256936.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 834	GFLOPS: 15591.16 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.31, Tstamp:1715256936.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 835	GFLOPS: 15963.17 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.51, Tstamp:1715256937.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 836	GFLOPS: 14863.28 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.56, Tstamp:1715256937.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 837	GFLOPS: 15691.88 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715256937.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 838	GFLOPS: 15948.24 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715256938.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 839	GFLOPS: 15665.89 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.64, Tstamp:1715256938.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 840	GFLOPS: 16109.72 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.96, Tstamp:1715256938.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 841	GFLOPS: 15422.43 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.80, Tstamp:1715256938.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 842	GFLOPS: 14468.49 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.67, Tstamp:1715256939.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 843	GFLOPS: 14153.22 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.32, Tstamp:1715256939.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 844	GFLOPS: 18481.02 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:3.10, Tstamp:1715256939.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 845	GFLOPS: 23392.76 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.91, Tstamp:1715256940.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 846	GFLOPS: 16281.46 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715256940.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 847	GFLOPS: 16179.16 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715256940.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 848	GFLOPS: 22249.91 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.90, Tstamp:1715256941.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 849	GFLOPS: 18743.21 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.85, Tstamp:1715256941.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 850	GFLOPS: 22119.85 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.43, Tstamp:1715256941.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 851	GFLOPS: 25729.70 / 26941.30	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.81, Tstamp:1715256942.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 852	GFLOPS: 24265.48 / 26941.30	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.67, Tstamp:1715256942.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 853	GFLOPS: 10426.19 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.37, Tstamp:1715256942.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 854	GFLOPS: 18930.52 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715256943.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 855	GFLOPS: 26570.05 / 26941.30	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.02, Tstamp:1715256943.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 856	GFLOPS: 16954.02 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715256943.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 857	GFLOPS: 13842.54 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715256944.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 858	GFLOPS: 13777.74 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715256944.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 859	GFLOPS: 22849.48 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.70, Tstamp:1715256944.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 860	GFLOPS: 17864.61 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715256945.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 861	GFLOPS: 18977.46 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.25, Tstamp:1715256945.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,24)
        compute = ...

==================================================
No: 862	GFLOPS: 17950.36 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256945.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 863	GFLOPS: 11076.51 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715256946.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 864	GFLOPS: 22834.18 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715256946.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 865	GFLOPS: 17900.23 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256946.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 866	GFLOPS: 12733.87 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715256946.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 867	GFLOPS: 17171.25 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715256947.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 868	GFLOPS: 18600.74 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.62, Tstamp:1715256947.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 869	GFLOPS: 8666.04 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.52, Tstamp:1715256947.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 870	GFLOPS: 7524.88 / 26941.30	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.72, Tstamp:1715256948.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 871	GFLOPS: 16010.02 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.86, Tstamp:1715256948.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 872	GFLOPS: 20056.18 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.91, Tstamp:1715256949.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 873	GFLOPS: 12730.21 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715256949.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 874	GFLOPS: 16814.97 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715256949.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 875	GFLOPS: 16153.17 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715256949.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 876	GFLOPS: 12554.70 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715256950.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 877	GFLOPS: 21829.89 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.73, Tstamp:1715256950.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 878	GFLOPS: 16446.36 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715256950.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 879	GFLOPS: 17930.74 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715256951.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 880	GFLOPS: 12270.71 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715256951.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 881	GFLOPS: 17872.18 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715256951.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 882	GFLOPS: 17549.83 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715256951.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 883	GFLOPS: 13457.48 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.97, Tstamp:1715256952.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 884	GFLOPS: 15898.32 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256952.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 885	GFLOPS: 18409.12 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.51, Tstamp:1715256952.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 886	GFLOPS: 16217.90 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715256953.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 887	GFLOPS: 12425.69 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715256953.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 888	GFLOPS: 14832.92 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715256953.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 889	GFLOPS: 19954.44 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715256953.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 890	GFLOPS: 17425.29 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715256954.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 891	GFLOPS: 16079.89 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715256954.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 892	GFLOPS: 15991.19 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.07, Tstamp:1715256954.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 893	GFLOPS: 14432.69 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.54, Tstamp:1715256955.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 894	GFLOPS: 1469.51 / 26941.30	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:0.45, Tstamp:1715256955.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 895	GFLOPS: 6581.27 / 26941.30	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.38, Tstamp:1715256955.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 896	GFLOPS: 12720.41 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715256955.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

Time elapsed for measurement: 28.05 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.92 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1682	fail_ct: 366	Time elapsed: 2.57
GA Iter: 0	Max score: 0.4870	Min score: 0.3307	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9503	Min score: 0.4793	#Pop: 128	#M+: 1385	#M-: 65
EvolutionarySearch		#s: 128	Time elapsed: 10.23
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 897	GFLOPS: 13197.10 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.04, Tstamp:1715256978.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 898	GFLOPS: 21808.34 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.73, Tstamp:1715256979.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 899	GFLOPS: 19160.91 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715256979.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 900	GFLOPS: 18916.01 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.16, Tstamp:1715256979.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 901	GFLOPS: 22891.51 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.30, Tstamp:1715256980.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 902	GFLOPS: 16738.88 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.55, Tstamp:1715256980.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 903	GFLOPS: 19243.61 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.48, Tstamp:1715256980.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 904	GFLOPS: 21339.92 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.71, Tstamp:1715256981.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 905	GFLOPS: 20157.79 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.71, Tstamp:1715256981.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 906	GFLOPS: 18622.40 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.16, Tstamp:1715256981.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 907	GFLOPS: 18271.71 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.36, Tstamp:1715256982.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 908	GFLOPS: 12301.08 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.13, Tstamp:1715256982.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 909	GFLOPS: 19388.59 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715256982.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 910	GFLOPS: 16736.95 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.36, Tstamp:1715256983.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 911	GFLOPS: 15789.47 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715256983.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 912	GFLOPS: 17834.48 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715256983.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 913	GFLOPS: 17319.01 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715256984.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 914	GFLOPS: 15516.09 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.85, Tstamp:1715256984.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 915	GFLOPS: 17379.46 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715256984.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 916	GFLOPS: 17914.91 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.78, Tstamp:1715256985.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 917	GFLOPS: 17784.52 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715256985.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 918	GFLOPS: 19683.38 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.24, Tstamp:1715256985.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 919	GFLOPS: 18961.77 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.57, Tstamp:1715256986.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 920	GFLOPS: 18140.99 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.31, Tstamp:1715256986.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 921	GFLOPS: 16415.79 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.36, Tstamp:1715256986.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 922	GFLOPS: 18849.71 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.80, Tstamp:1715256987.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 923	GFLOPS: 18763.67 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.50, Tstamp:1715256987.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 924	GFLOPS: 16761.47 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.59, Tstamp:1715256987.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 925	GFLOPS: 17677.86 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.28, Tstamp:1715256987.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 926	GFLOPS: 17333.37 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.90, Tstamp:1715256988.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 927	GFLOPS: 19339.77 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.32, Tstamp:1715256988.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 928	GFLOPS: 17458.94 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.66, Tstamp:1715256989.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 929	GFLOPS: 17470.32 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715256989.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 930	GFLOPS: 17141.83 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715256989.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 931	GFLOPS: 17605.35 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715256990.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 932	GFLOPS: 17180.78 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715256990.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 933	GFLOPS: 17544.20 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256990.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 934	GFLOPS: 17408.68 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715256991.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 935	GFLOPS: 17519.65 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715256991.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 936	GFLOPS: 15810.52 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715256991.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 937	GFLOPS: 17683.72 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715256991.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 938	GFLOPS: 16745.14 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.68, Tstamp:1715256992.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 939	GFLOPS: 16884.42 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715256992.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 940	GFLOPS: 17492.31 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715256992.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 941	GFLOPS: 12480.74 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715256993.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 942	GFLOPS: 12596.84 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715256993.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 943	GFLOPS: 13969.12 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.08, Tstamp:1715256993.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,24)
        compute = ...

==================================================
No: 944	GFLOPS: 15905.63 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256993.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 945	GFLOPS: 15924.23 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715256994.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 946	GFLOPS: 16523.02 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.22, Tstamp:1715256994.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,24)
        compute = ...

==================================================
No: 947	GFLOPS: 16437.38 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715256994.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 948	GFLOPS: 16596.92 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715256995.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 949	GFLOPS: 12845.21 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715256995.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 950	GFLOPS: 16143.94 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715256996.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 951	GFLOPS: 16434.25 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.48, Tstamp:1715256996.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 952	GFLOPS: 16972.55 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715256996.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 953	GFLOPS: 15750.68 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715256997.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 954	GFLOPS: 16331.36 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.54, Tstamp:1715256997.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 955	GFLOPS: 16516.08 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.56, Tstamp:1715256997.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 956	GFLOPS: 16150.57 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715256997.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 957	GFLOPS: 16093.53 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715256998.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 958	GFLOPS: 3986.50 / 26941.30	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.46, Tstamp:1715256998.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 959	GFLOPS: 4359.55 / 26941.30	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.48, Tstamp:1715256999.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 960	GFLOPS: 1516.84 / 26941.30	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:3.02, Tstamp:1715256999.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 29.40 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.30 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1679	fail_ct: 369	Time elapsed: 2.55
GA Iter: 0	Max score: 0.5649	Min score: 0.3390	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8193	Min score: 0.4725	#Pop: 128	#M+: 1374	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 10.17
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 40 programs to measure:
........................................****************************************
==================================================
No: 961	GFLOPS: 22676.18 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.85, Tstamp:1715257019.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 962	GFLOPS: 12163.30 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.00, Tstamp:1715257019.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 963	GFLOPS: 8489.95 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.09, Tstamp:1715257020.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 964	GFLOPS: 9172.53 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.41, Tstamp:1715257020.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 965	GFLOPS: 20926.08 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.80, Tstamp:1715257020.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 966	GFLOPS: 18559.60 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.57, Tstamp:1715257021.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 967	GFLOPS: 10968.48 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.14, Tstamp:1715257021.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 968	GFLOPS: 17884.49 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715257021.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 969	GFLOPS: 17861.20 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715257022.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 970	GFLOPS: 17632.93 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715257022.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 971	GFLOPS: 17631.51 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715257022.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 972	GFLOPS: 17725.08 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715257023.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 973	GFLOPS: 17636.18 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715257023.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 974	GFLOPS: 17899.51 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715257023.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 975	GFLOPS: 16977.69 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715257024.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 976	GFLOPS: 18053.19 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715257024.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 977	GFLOPS: 17846.14 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.56, Tstamp:1715257024.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 978	GFLOPS: 17291.61 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715257025.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 979	GFLOPS: 15971.80 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715257025.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 980	GFLOPS: 17446.01 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715257025.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 981	GFLOPS: 13972.77 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715257025.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,24)
        compute = ...

==================================================
No: 982	GFLOPS: 16970.58 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.48, Tstamp:1715257026.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 983	GFLOPS: 17884.66 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715257026.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 984	GFLOPS: 17740.04 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715257026.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 985	GFLOPS: 13279.99 / 26941.30	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.92, Tstamp:1715257027.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 986	GFLOPS: 17919.87 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715257027.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 987	GFLOPS: 17019.71 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.99, Tstamp:1715257027.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 988	GFLOPS: 17952.52 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715257028.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 989	GFLOPS: 18786.05 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715257028.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 990	GFLOPS: 15631.92 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715257028.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 991	GFLOPS: 16439.88 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715257028.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 992	GFLOPS: 16210.65 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715257029.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 993	GFLOPS: 16214.87 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715257029.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 994	GFLOPS: 18858.82 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.93, Tstamp:1715257029.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 995	GFLOPS: 16087.41 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715257030.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 996	GFLOPS: 15960.28 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.77, Tstamp:1715257030.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,24)
        compute = ...

==================================================
No: 997	GFLOPS: 8487.04 / 26941.30	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.43, Tstamp:1715257030.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 998	GFLOPS: 16297.70 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715257030.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 999	GFLOPS: 16150.09 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.86, Tstamp:1715257031.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 1000	GFLOPS: 16020.11 / 26941.30	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715257031.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

Time elapsed for measurement: 18.19 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
Lowered TIR:
@main = primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, compute_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_8: Pointer(float32), float32, [768, 3072], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [172, 16, 16], []),
             placeholder_2: Buffer(placeholder_10: Pointer(int32), int32, [172], []),
             placeholder_3: Buffer(placeholder_11: Pointer(int32), int32, [49], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, compute_1: compute} {
  for (m.outer: int32, 0, 128) "parallel" {
    allocate(compute_3: Pointer(global float32), float32, [288]), storage_scope = global;
    for (n.outer: int32, 0, 16) {
      for (nb_j.inner: int32, 0, 3) {
        let cse_var_1: int32 = (nb_j.inner*16)
         {
          compute_4: Buffer(compute_3, float32, [288], [])[cse_var_1] = 0f32
          compute_4[(cse_var_1 + 1)] = 0f32
          compute_4[(cse_var_1 + 2)] = 0f32
          compute_4[(cse_var_1 + 3)] = 0f32
          compute_4[(cse_var_1 + 4)] = 0f32
          compute_4[(cse_var_1 + 5)] = 0f32
          compute_4[(cse_var_1 + 6)] = 0f32
          compute_4[(cse_var_1 + 7)] = 0f32
          compute_4[(cse_var_1 + 8)] = 0f32
          compute_4[(cse_var_1 + 9)] = 0f32
          compute_4[(cse_var_1 + 10)] = 0f32
          compute_4[(cse_var_1 + 11)] = 0f32
          compute_4[(cse_var_1 + 12)] = 0f32
          compute_4[(cse_var_1 + 13)] = 0f32
          compute_4[(cse_var_1 + 14)] = 0f32
          compute_4[(cse_var_1 + 15)] = 0f32
          compute_4[(cse_var_1 + 48)] = 0f32
          compute_4[(cse_var_1 + 49)] = 0f32
          compute_4[(cse_var_1 + 50)] = 0f32
          compute_4[(cse_var_1 + 51)] = 0f32
          compute_4[(cse_var_1 + 52)] = 0f32
          compute_4[(cse_var_1 + 53)] = 0f32
          compute_4[(cse_var_1 + 54)] = 0f32
          compute_4[(cse_var_1 + 55)] = 0f32
          compute_4[(cse_var_1 + 56)] = 0f32
          compute_4[(cse_var_1 + 57)] = 0f32
          compute_4[(cse_var_1 + 58)] = 0f32
          compute_4[(cse_var_1 + 59)] = 0f32
          compute_4[(cse_var_1 + 60)] = 0f32
          compute_4[(cse_var_1 + 61)] = 0f32
          compute_4[(cse_var_1 + 62)] = 0f32
          compute_4[(cse_var_1 + 63)] = 0f32
          compute_4[(cse_var_1 + 96)] = 0f32
          compute_4[(cse_var_1 + 97)] = 0f32
          compute_4[(cse_var_1 + 98)] = 0f32
          compute_4[(cse_var_1 + 99)] = 0f32
          compute_4[(cse_var_1 + 100)] = 0f32
          compute_4[(cse_var_1 + 101)] = 0f32
          compute_4[(cse_var_1 + 102)] = 0f32
          compute_4[(cse_var_1 + 103)] = 0f32
          compute_4[(cse_var_1 + 104)] = 0f32
          compute_4[(cse_var_1 + 105)] = 0f32
          compute_4[(cse_var_1 + 106)] = 0f32
          compute_4[(cse_var_1 + 107)] = 0f32
          compute_4[(cse_var_1 + 108)] = 0f32
          compute_4[(cse_var_1 + 109)] = 0f32
          compute_4[(cse_var_1 + 110)] = 0f32
          compute_4[(cse_var_1 + 111)] = 0f32
          compute_4[(cse_var_1 + 144)] = 0f32
          compute_4[(cse_var_1 + 145)] = 0f32
          compute_4[(cse_var_1 + 146)] = 0f32
          compute_4[(cse_var_1 + 147)] = 0f32
          compute_4[(cse_var_1 + 148)] = 0f32
          compute_4[(cse_var_1 + 149)] = 0f32
          compute_4[(cse_var_1 + 150)] = 0f32
          compute_4[(cse_var_1 + 151)] = 0f32
          compute_4[(cse_var_1 + 152)] = 0f32
          compute_4[(cse_var_1 + 153)] = 0f32
          compute_4[(cse_var_1 + 154)] = 0f32
          compute_4[(cse_var_1 + 155)] = 0f32
          compute_4[(cse_var_1 + 156)] = 0f32
          compute_4[(cse_var_1 + 157)] = 0f32
          compute_4[(cse_var_1 + 158)] = 0f32
          compute_4[(cse_var_1 + 159)] = 0f32
          compute_4[(cse_var_1 + 192)] = 0f32
          compute_4[(cse_var_1 + 193)] = 0f32
          compute_4[(cse_var_1 + 194)] = 0f32
          compute_4[(cse_var_1 + 195)] = 0f32
          compute_4[(cse_var_1 + 196)] = 0f32
          compute_4[(cse_var_1 + 197)] = 0f32
          compute_4[(cse_var_1 + 198)] = 0f32
          compute_4[(cse_var_1 + 199)] = 0f32
          compute_4[(cse_var_1 + 200)] = 0f32
          compute_4[(cse_var_1 + 201)] = 0f32
          compute_4[(cse_var_1 + 202)] = 0f32
          compute_4[(cse_var_1 + 203)] = 0f32
          compute_4[(cse_var_1 + 204)] = 0f32
          compute_4[(cse_var_1 + 205)] = 0f32
          compute_4[(cse_var_1 + 206)] = 0f32
          compute_4[(cse_var_1 + 207)] = 0f32
          compute_4[(cse_var_1 + 240)] = 0f32
          compute_4[(cse_var_1 + 241)] = 0f32
          compute_4[(cse_var_1 + 242)] = 0f32
          compute_4[(cse_var_1 + 243)] = 0f32
          compute_4[(cse_var_1 + 244)] = 0f32
          compute_4[(cse_var_1 + 245)] = 0f32
          compute_4[(cse_var_1 + 246)] = 0f32
          compute_4[(cse_var_1 + 247)] = 0f32
          compute_4[(cse_var_1 + 248)] = 0f32
          compute_4[(cse_var_1 + 249)] = 0f32
          compute_4[(cse_var_1 + 250)] = 0f32
          compute_4[(cse_var_1 + 251)] = 0f32
          compute_4[(cse_var_1 + 252)] = 0f32
          compute_4[(cse_var_1 + 253)] = 0f32
          compute_4[(cse_var_1 + 254)] = 0f32
          compute_4[(cse_var_1 + 255)] = 0f32
          for (elem_idx: int32, 0, let cse_var_2: int32 = ((n.outer*3) + nb_j.inner) in (placeholder_12: Buffer(placeholder_11, int32, [49], [])[(cse_var_2 + 1)] - placeholder_12[cse_var_2])) {
            for (i.inner: int32, 0, 6) {
              let cse_var_21: int32 = (elem_idx*256)
              let cse_var_20: int32 = ((n.outer*3) + nb_j.inner)
              let cse_var_19: int32 = ((i.inner*48) + cse_var_1)
              let cse_var_18: int32 = ((m.outer*18432) + (i.inner*3072))
              let cse_var_17: int32 = (cse_var_19 + 9)
              let cse_var_16: int32 = (cse_var_19 + 8)
              let cse_var_15: int32 = (cse_var_19 + 7)
              let cse_var_14: int32 = (cse_var_19 + 6)
              let cse_var_13: int32 = (cse_var_19 + 5)
              let cse_var_12: int32 = (cse_var_19 + 4)
              let cse_var_11: int32 = (cse_var_19 + 3)
              let cse_var_10: int32 = (cse_var_19 + 2)
              let cse_var_9: int32 = (cse_var_19 + 15)
              let cse_var_8: int32 = (cse_var_19 + 14)
              let cse_var_7: int32 = (cse_var_19 + 13)
              let cse_var_6: int32 = (cse_var_19 + 12)
              let cse_var_5: int32 = (cse_var_19 + 11)
              let cse_var_4: int32 = (cse_var_19 + 10)
              let cse_var_3: int32 = (cse_var_19 + 1)
               {
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13: Buffer(placeholder_9, float32, [44032], [])[((placeholder_12[cse_var_20]*256) + cse_var_21)]*placeholder_14: Buffer(placeholder_8, float32, [2359296], [])[(cse_var_18 + (placeholder_15: Buffer(placeholder_10, int32, [172], [])[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 1)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 2)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 3)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 4)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 5)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 6)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 7)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 8)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 9)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 10)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 11)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 12)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 13)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 14)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 15)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 16)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 17)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 18)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 19)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 20)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 21)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 22)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 23)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 24)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 25)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 26)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 27)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 28)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 29)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 30)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 31)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 32)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 33)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 34)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 35)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 36)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 37)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 38)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 39)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 40)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 41)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 42)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 43)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 44)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 45)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 46)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 47)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 48)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 49)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 50)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 51)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 52)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 53)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 54)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 55)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 56)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 57)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 58)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 59)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 60)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 61)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 62)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 63)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 64)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 65)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 66)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 67)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 68)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 69)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 70)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 71)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 72)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 73)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 74)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 75)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 76)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 77)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 78)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 79)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 80)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 81)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 82)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 83)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 84)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 85)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 86)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 87)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 88)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 89)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 90)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 91)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 92)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 93)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 94)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 95)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 96)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 97)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 98)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 99)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 100)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 101)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 102)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 103)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 104)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 105)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 106)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 107)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 108)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 109)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 110)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 111)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 112)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 113)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 114)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 115)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 116)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 117)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 118)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 119)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 120)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 121)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 122)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 123)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 124)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 125)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 126)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 127)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 128)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 129)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 130)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 131)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 132)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 133)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 134)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 135)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 136)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 137)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 138)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 139)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 140)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 141)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 142)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 143)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 144)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 145)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 146)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 147)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 148)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 149)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 150)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 151)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 152)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 153)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 154)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 155)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 156)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 157)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 158)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 159)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 160)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 161)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 162)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 163)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 164)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 165)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 166)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 167)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 168)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 169)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 170)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 171)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 172)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 173)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 174)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 175)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 176)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 177)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 178)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 179)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 180)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 181)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 182)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 183)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 184)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 185)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 186)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 187)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 188)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 189)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 190)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 191)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 192)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 193)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 194)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 195)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 196)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 197)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 198)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 199)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 200)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 201)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 202)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 203)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 204)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 205)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 206)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 207)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 208)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 209)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 210)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 211)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 212)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 213)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 214)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 215)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 216)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 217)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 218)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 219)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 220)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 221)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 222)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 223)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 224)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 225)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 226)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 227)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 228)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 229)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 230)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 231)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 232)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 233)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 234)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 235)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 236)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 237)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 238)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 239)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 240)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 241)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 242)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 243)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 244)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 245)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 246)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 247)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 248)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 249)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 250)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 251)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 252)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 253)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 254)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 255)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
              }
            }
          }
        }
      }
      for (m.inner: int32, 0, 6) {
        compute_5: Buffer(compute_2, float32, [589824], [])[ramp((((m.outer*4608) + (m.inner*768)) + (n.outer*48)), 1, 48)] = compute_4[ramp((m.inner*48), 1, 48)]
      }
    }
  }
}

----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
Custom sketch rule "SparseDense" added.
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 1631	fail_ct: 417	Time elapsed: 2.51
GA Iter: 0	Max score: 0.9997	Min score: 0.9177	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9884	#Pop: 128	#M+: 1381	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 10.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
...............E.................................................***************************************************************
(768, 768)
(768, 768)
encoder.layer.10.output.dense.weight Execution time of this operator: 0.138 ms
encoder.layer.11.output.dense.weight: num_row = 768, num_col = 3072, nnz = 55187

==================================================
No: 1	GFLOPS: 7678.39 / 7678.39	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.70, Tstamp:1715257055.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,24)
      compute = ...

==================================================
No: 2	GFLOPS: 6737.79 / 7678.39	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.78, Tstamp:1715257055.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 3	GFLOPS: 12230.50 / 12230.50	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.92, Tstamp:1715257055.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 4	GFLOPS: 19844.16 / 19844.16	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.74, Tstamp:1715257055.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 5	GFLOPS: 0.00 / 19844.16	results: MeasureResult(error_type:CompileHostError, error_msg:Traceback (most recent call last):
  File "/home/qxj/.local/lib/python3.8/site-packages/tvm/auto_scheduler/measure.py", line 633, in _local_build_worker
    func = build_module.build(sch, args, target=task.target)
  File "/home/qxj/.local/lib/python3.8/sit
...
 execution of TVM.
For more information, please see: https://tvm.apache.org/docs/errors.html
---------------------------------------------------------------
  Check failed: (!use_count_.count(v)) is false: variable n.outer has been used before definition!
, all_cost:1.01, Tstamp:1715257055.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.0 (0,floordiv((floormod((n.outer*12), 16) + 203), 192))
      for i.1 (0,4)
        for nb_j.1 (0,(floordiv((floormod((n.outer*12), 16) + 11), 16) + 1))
          for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
            for i.2 (0,8)
              for j (0,16)
                for c (0,16)
                  compute = ...
    for m.1 (0,32)
      for n.1 (0,12)
        compute = ...

==================================================
No: 6	GFLOPS: 6138.59 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.36, Tstamp:1715257056.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

==================================================
No: 7	GFLOPS: 1163.44 / 19844.16	results: MeasureResult(cost:[0.0031], error_no:0, all_cost:1.67, Tstamp:1715257056.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 8	GFLOPS: 13342.84 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.09, Tstamp:1715257056.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 9	GFLOPS: 7100.73 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.56, Tstamp:1715257057.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,144)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 10	GFLOPS: 2390.50 / 19844.16	results: MeasureResult(cost:[0.0015], error_no:0, all_cost:1.47, Tstamp:1715257057.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,6)
      compute = ...

==================================================
No: 11	GFLOPS: 4497.78 / 19844.16	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.12, Tstamp:1715257057.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 12	GFLOPS: 12999.09 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.55, Tstamp:1715257058.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 13	GFLOPS: 10530.05 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715257058.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,192)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 14	GFLOPS: 3063.27 / 19844.16	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.96, Tstamp:1715257058.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for n.1 (0,6)
    compute = ...

==================================================
No: 15	GFLOPS: 4583.11 / 19844.16	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.12, Tstamp:1715257058.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 16
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,24)
      compute = ...

==================================================
No: 16	GFLOPS: 7348.49 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.76, Tstamp:1715257059.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 17	GFLOPS: 1067.46 / 19844.16	results: MeasureResult(cost:[0.0034], error_no:0, all_cost:0.78, Tstamp:1715257059.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 18	GFLOPS: 8443.62 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.08, Tstamp:1715257059.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 19	GFLOPS: 5075.47 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.55, Tstamp:1715257059.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 20	GFLOPS: 6030.49 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.78, Tstamp:1715257060.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 21	GFLOPS: 2608.88 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.85, Tstamp:1715257060.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 22	GFLOPS: 2754.21 / 19844.16	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.85, Tstamp:1715257060.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 23	GFLOPS: 9565.67 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.66, Tstamp:1715257061.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 24	GFLOPS: 6904.17 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.82, Tstamp:1715257061.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,8)
    compute = ...

==================================================
No: 25	GFLOPS: 5447.06 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.82, Tstamp:1715257061.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 26	GFLOPS: 2774.96 / 19844.16	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.91, Tstamp:1715257062.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 27	GFLOPS: 9240.72 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.58, Tstamp:1715257062.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 28	GFLOPS: 8939.39 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.58, Tstamp:1715257062.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 29	GFLOPS: 11453.52 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.03, Tstamp:1715257062.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 30	GFLOPS: 935.85 / 19844.16	results: MeasureResult(cost:[0.0039], error_no:0, all_cost:0.80, Tstamp:1715257063.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 31	GFLOPS: 10642.12 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257063.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 32	GFLOPS: 14761.24 / 19844.16	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715257063.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 33	GFLOPS: 2368.99 / 19844.16	results: MeasureResult(cost:[0.0015], error_no:0, all_cost:1.30, Tstamp:1715257063.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 34	GFLOPS: 2167.93 / 19844.16	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:1.31, Tstamp:1715257064.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 35	GFLOPS: 5261.23 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.84, Tstamp:1715257064.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 36	GFLOPS: 8858.34 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.30, Tstamp:1715257064.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,24)
      compute = ...

==================================================
No: 37	GFLOPS: 14647.70 / 19844.16	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.34, Tstamp:1715257065.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,24)
      compute = ...

==================================================
No: 38	GFLOPS: 6040.14 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.41, Tstamp:1715257065.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

==================================================
No: 39	GFLOPS: 4376.45 / 19844.16	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.07, Tstamp:1715257065.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 40	GFLOPS: 5221.08 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.41, Tstamp:1715257066.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 41	GFLOPS: 1490.12 / 19844.16	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.62, Tstamp:1715257066.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 42	GFLOPS: 11069.64 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715257066.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 43	GFLOPS: 1859.95 / 19844.16	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.31, Tstamp:1715257066.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 44	GFLOPS: 2509.82 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:1.31, Tstamp:1715257067.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 45	GFLOPS: 6465.38 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.84, Tstamp:1715257067.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 512
  for i.1 (0,256)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 46	GFLOPS: 3456.17 / 19844.16	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.52, Tstamp:1715257067.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 47	GFLOPS: 6853.53 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.48, Tstamp:1715257068.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 48	GFLOPS: 2312.31 / 19844.16	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:0.50, Tstamp:1715257068.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 49	GFLOPS: 798.60 / 19844.16	results: MeasureResult(cost:[0.0045], error_no:0, all_cost:2.38, Tstamp:1715257068.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 50	GFLOPS: 2660.99 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.51, Tstamp:1715257069.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 51	GFLOPS: 14714.48 / 19844.16	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715257069.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 52	GFLOPS: 2644.52 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.53, Tstamp:1715257069.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 53	GFLOPS: 9216.06 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715257070.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 54	GFLOPS: 2974.11 / 19844.16	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.51, Tstamp:1715257070.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 55	GFLOPS: 2213.82 / 19844.16	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:0.52, Tstamp:1715257070.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 16
  for i.1 (0,768)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 56	GFLOPS: 2878.52 / 19844.16	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:2.83, Tstamp:1715257071.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 57	GFLOPS: 1052.44 / 19844.16	results: MeasureResult(cost:[0.0034], error_no:0, all_cost:1.01, Tstamp:1715257071.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 58	GFLOPS: 8222.84 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.81, Tstamp:1715257071.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,8)
        compute = ...

==================================================
No: 59	GFLOPS: 11700.03 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715257071.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 60	GFLOPS: 5444.30 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.42, Tstamp:1715257072.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    for n.1 (0,48)
      compute = ...

==================================================
No: 61	GFLOPS: 1920.45 / 19844.16	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.81, Tstamp:1715257072.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 62	GFLOPS: 1845.75 / 19844.16	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.53, Tstamp:1715257072.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,384)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 63	GFLOPS: 2901.14 / 19844.16	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.47, Tstamp:1715257072.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 64	GFLOPS: 7016.46 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.32, Tstamp:1715257073.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

Time elapsed for measurement: 26.98 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.72 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1673	fail_ct: 375	Time elapsed: 2.47
GA Iter: 0	Max score: 0.9986	Min score: 0.9292	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9998	Min score: 0.9857	#Pop: 128	#M+: 1379	#M-: 69
EvolutionarySearch		#s: 128	Time elapsed: 10.07
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 65	GFLOPS: 8736.26 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.27, Tstamp:1715257096.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 66	GFLOPS: 11274.39 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.02, Tstamp:1715257096.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 67	GFLOPS: 1314.17 / 19844.16	results: MeasureResult(cost:[0.0028], error_no:0, all_cost:1.13, Tstamp:1715257096.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 68	GFLOPS: 4517.11 / 19844.16	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.27, Tstamp:1715257096.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 69	GFLOPS: 1734.30 / 19844.16	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:4.72, Tstamp:1715257097.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 70	GFLOPS: 2186.76 / 19844.16	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:1.99, Tstamp:1715257097.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 512
  for i.1 (0,96)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 71	GFLOPS: 6520.38 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.25, Tstamp:1715257097.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 72	GFLOPS: 1612.93 / 19844.16	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:0.81, Tstamp:1715257098.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 73	GFLOPS: 7421.34 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.03, Tstamp:1715257098.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,3)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,6)
    for n.1 (0,12)
      compute = ...

==================================================
No: 74	GFLOPS: 2607.22 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.94, Tstamp:1715257098.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 75	GFLOPS: 6524.24 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.81, Tstamp:1715257098.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 76	GFLOPS: 11033.49 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.00, Tstamp:1715257099.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 77	GFLOPS: 6535.30 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.06, Tstamp:1715257099.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 64
  for i.1 (0,256)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,48)
      compute = ...

==================================================
No: 78	GFLOPS: 13193.09 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.15, Tstamp:1715257099.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 79	GFLOPS: 1954.17 / 19844.16	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:1.39, Tstamp:1715257100.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 80	GFLOPS: 1454.85 / 19844.16	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:1.79, Tstamp:1715257100.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 81	GFLOPS: 5724.63 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.84, Tstamp:1715257100.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 82	GFLOPS: 12328.75 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257100.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 83	GFLOPS: 1714.22 / 19844.16	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:0.76, Tstamp:1715257101.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  vectorize n.1 (0,3)
    compute = ...

==================================================
No: 84	GFLOPS: 2541.17 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:1.33, Tstamp:1715257101.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 85	GFLOPS: 4954.89 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.95, Tstamp:1715257101.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    for n.1 (0,48)
      compute = ...

==================================================
No: 86	GFLOPS: 3462.95 / 19844.16	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.89, Tstamp:1715257102.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 87	GFLOPS: 6044.53 / 19844.16	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.66, Tstamp:1715257102.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 88	GFLOPS: 3258.73 / 19844.16	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.70, Tstamp:1715257102.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 89	GFLOPS: 7608.40 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.82, Tstamp:1715257103.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 90	GFLOPS: 3383.05 / 19844.16	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.91, Tstamp:1715257103.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 91	GFLOPS: 911.38 / 19844.16	results: MeasureResult(cost:[0.0040], error_no:0, all_cost:0.57, Tstamp:1715257103.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 92	GFLOPS: 2504.06 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.69, Tstamp:1715257103.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 93	GFLOPS: 9864.02 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.07, Tstamp:1715257104.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 94	GFLOPS: 10904.65 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715257104.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 95	GFLOPS: 8159.00 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.83, Tstamp:1715257104.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 96	GFLOPS: 3263.11 / 19844.16	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.51, Tstamp:1715257105.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 97	GFLOPS: 3536.29 / 19844.16	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.35, Tstamp:1715257105.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 98	GFLOPS: 2046.20 / 19844.16	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:1.06, Tstamp:1715257105.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 99	GFLOPS: 5286.47 / 19844.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.89, Tstamp:1715257106.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 100	GFLOPS: 4594.59 / 19844.16	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.30, Tstamp:1715257106.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    for n.1 (0,12)
      compute = ...

==================================================
No: 101	GFLOPS: 9101.69 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.47, Tstamp:1715257106.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,24)
      for c (0,16)
        compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 102	GFLOPS: 7118.72 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.51, Tstamp:1715257107.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 103	GFLOPS: 11556.08 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257107.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 104	GFLOPS: 13291.03 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257107.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 105	GFLOPS: 2607.50 / 19844.16	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.87, Tstamp:1715257107.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    for n.1 (0,6)
      compute = ...

==================================================
No: 106	GFLOPS: 3000.84 / 19844.16	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.42, Tstamp:1715257108.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 107	GFLOPS: 2817.39 / 19844.16	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.46, Tstamp:1715257108.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 108	GFLOPS: 1649.78 / 19844.16	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:0.50, Tstamp:1715257108.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 109	GFLOPS: 7197.77 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.61, Tstamp:1715257109.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,24)
      compute = ...

==================================================
No: 110	GFLOPS: 8109.16 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.54, Tstamp:1715257109.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 111	GFLOPS: 257.38 / 19844.16	results: MeasureResult(cost:[0.0141], error_no:0, all_cost:0.68, Tstamp:1715257109.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
for n.0 (0,48)
  compute auto_unroll: 512
  for i.1 (0,768)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 112	GFLOPS: 8975.18 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.51, Tstamp:1715257110.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 113	GFLOPS: 14335.84 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257110.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 114	GFLOPS: 13261.10 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715257110.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 115	GFLOPS: 825.13 / 19844.16	results: MeasureResult(cost:[0.0044], error_no:0, all_cost:0.40, Tstamp:1715257111.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 116	GFLOPS: 1458.14 / 19844.16	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:0.59, Tstamp:1715257111.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 117	GFLOPS: 9476.25 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.54, Tstamp:1715257111.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 118	GFLOPS: 6876.30 / 19844.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.45, Tstamp:1715257112.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 119	GFLOPS: 1206.53 / 19844.16	results: MeasureResult(cost:[0.0030], error_no:0, all_cost:1.22, Tstamp:1715257112.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 512
  for i.1 (0,384)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 120	GFLOPS: 11184.12 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715257112.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 121	GFLOPS: 4583.89 / 19844.16	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.32, Tstamp:1715257112.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 122	GFLOPS: 4093.27 / 19844.16	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.66, Tstamp:1715257113.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 123	GFLOPS: 8535.75 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.33, Tstamp:1715257113.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,64)
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 124	GFLOPS: 1906.15 / 19844.16	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.83, Tstamp:1715257113.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 125	GFLOPS: 2107.96 / 19844.16	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:3.21, Tstamp:1715257113.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    for n.1 (0,12)
      compute = ...

==================================================
No: 126	GFLOPS: 1410.23 / 19844.16	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:3.14, Tstamp:1715257114.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 127	GFLOPS: 12013.19 / 19844.16	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257114.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 128	GFLOPS: 1787.42 / 19844.16	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.56, Tstamp:1715257114.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 28.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.71 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1660	fail_ct: 388	Time elapsed: 2.57
GA Iter: 0	Max score: 0.9983	Min score: 0.5900	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9983	Min score: 0.7298	#Pop: 128	#M+: 1380	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 9.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 129	GFLOPS: 8714.63 / 19844.16	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.78, Tstamp:1715257136.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 130	GFLOPS: 19347.78 / 19844.16	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.71, Tstamp:1715257136.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 131	GFLOPS: 19912.08 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.39, Tstamp:1715257137.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 132	GFLOPS: 11800.24 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.45, Tstamp:1715257137.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 133	GFLOPS: 14200.88 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.10, Tstamp:1715257137.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 134	GFLOPS: 15668.95 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715257138.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 135	GFLOPS: 19267.38 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.21, Tstamp:1715257138.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 136	GFLOPS: 9718.10 / 19912.08	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.47, Tstamp:1715257138.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 137	GFLOPS: 18753.18 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.99, Tstamp:1715257139.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 138	GFLOPS: 14750.11 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.95, Tstamp:1715257139.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 139	GFLOPS: 15508.79 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.46, Tstamp:1715257139.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 140	GFLOPS: 19506.09 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.50, Tstamp:1715257140.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 141	GFLOPS: 19778.00 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.70, Tstamp:1715257140.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 142	GFLOPS: 13471.30 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715257140.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 143	GFLOPS: 14033.50 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257140.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 144	GFLOPS: 8501.65 / 19912.08	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.91, Tstamp:1715257141.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 145	GFLOPS: 15048.69 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.43, Tstamp:1715257141.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 146	GFLOPS: 18379.05 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.84, Tstamp:1715257141.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 147	GFLOPS: 12851.48 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.65, Tstamp:1715257142.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 148	GFLOPS: 14357.82 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257142.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 149	GFLOPS: 13151.21 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715257142.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 150	GFLOPS: 13205.60 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257142.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 151	GFLOPS: 8426.92 / 19912.08	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.49, Tstamp:1715257143.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 152	GFLOPS: 14310.80 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715257143.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 153	GFLOPS: 13375.12 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.90, Tstamp:1715257143.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 154	GFLOPS: 13314.34 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257144.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 155	GFLOPS: 11932.60 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257144.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 156	GFLOPS: 14480.83 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257144.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 157	GFLOPS: 13303.91 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257144.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 158	GFLOPS: 13318.21 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257145.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 159	GFLOPS: 17296.42 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.13, Tstamp:1715257145.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 160	GFLOPS: 13117.89 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715257146.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 161	GFLOPS: 6481.74 / 19912.08	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.43, Tstamp:1715257146.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 162	GFLOPS: 12073.90 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257146.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 163	GFLOPS: 11974.94 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715257146.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 164	GFLOPS: 18290.65 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.33, Tstamp:1715257147.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 165	GFLOPS: 18818.58 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715257147.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 166	GFLOPS: 14394.32 / 19912.08	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.34, Tstamp:1715257147.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 167	GFLOPS: 19730.59 / 19912.08	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.37, Tstamp:1715257148.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 168	GFLOPS: 21531.87 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.34, Tstamp:1715257148.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 169	GFLOPS: 21346.35 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.31, Tstamp:1715257149.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 170	GFLOPS: 15511.98 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715257149.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 171	GFLOPS: 11964.15 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257149.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 172	GFLOPS: 11993.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715257149.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 173	GFLOPS: 14404.47 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.90, Tstamp:1715257150.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 174	GFLOPS: 8356.81 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.45, Tstamp:1715257150.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 175	GFLOPS: 18439.91 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.21, Tstamp:1715257150.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 176	GFLOPS: 11887.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257151.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 177	GFLOPS: 13110.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715257151.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 178	GFLOPS: 9621.46 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.45, Tstamp:1715257151.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 179	GFLOPS: 10178.32 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.46, Tstamp:1715257152.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 180	GFLOPS: 14650.71 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.17, Tstamp:1715257152.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 181	GFLOPS: 13143.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257152.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 182	GFLOPS: 13119.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715257153.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 183	GFLOPS: 13383.58 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257153.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 184	GFLOPS: 9243.50 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.44, Tstamp:1715257153.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 185	GFLOPS: 13929.45 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.36, Tstamp:1715257154.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 186	GFLOPS: 18917.36 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715257154.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 187	GFLOPS: 14947.87 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715257154.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 188	GFLOPS: 12919.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257155.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 189	GFLOPS: 21151.25 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715257155.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 190	GFLOPS: 2282.92 / 21531.87	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:2.61, Tstamp:1715257155.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 191	GFLOPS: 11923.62 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.38, Tstamp:1715257156.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 192	GFLOPS: 8570.50 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.77, Tstamp:1715257156.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for i.1 (0,96)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

Time elapsed for measurement: 28.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.71 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1652	fail_ct: 396	Time elapsed: 2.53
GA Iter: 0	Max score: 0.8544	Min score: 0.5122	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9458	Min score: 0.6800	#Pop: 128	#M+: 1376	#M-: 65
EvolutionarySearch		#s: 128	Time elapsed: 10.13
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 193	GFLOPS: 6966.95 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.97, Tstamp:1715257180.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 194	GFLOPS: 13692.84 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.41, Tstamp:1715257180.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 195	GFLOPS: 11755.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.08, Tstamp:1715257181.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 196	GFLOPS: 12938.18 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.45, Tstamp:1715257181.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 197	GFLOPS: 15376.33 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.77, Tstamp:1715257181.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 198	GFLOPS: 13301.91 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.88, Tstamp:1715257181.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 199	GFLOPS: 17789.11 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715257182.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 200	GFLOPS: 16562.77 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.12, Tstamp:1715257182.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 201	GFLOPS: 17522.96 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.14, Tstamp:1715257182.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 202	GFLOPS: 16582.52 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.99, Tstamp:1715257183.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 203	GFLOPS: 13818.71 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.76, Tstamp:1715257183.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 204	GFLOPS: 18630.29 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.02, Tstamp:1715257183.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 205	GFLOPS: 11555.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.14, Tstamp:1715257184.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 206	GFLOPS: 13255.39 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.07, Tstamp:1715257184.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 207	GFLOPS: 20696.74 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.67, Tstamp:1715257184.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 208	GFLOPS: 19297.35 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.08, Tstamp:1715257185.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 209	GFLOPS: 18096.21 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.49, Tstamp:1715257185.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 210	GFLOPS: 12968.88 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.13, Tstamp:1715257185.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 211	GFLOPS: 18868.59 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.14, Tstamp:1715257186.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 212	GFLOPS: 17561.36 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.55, Tstamp:1715257186.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 213	GFLOPS: 20805.15 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.47, Tstamp:1715257186.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 214	GFLOPS: 12102.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257187.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 215	GFLOPS: 17235.69 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.62, Tstamp:1715257187.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 216	GFLOPS: 10421.96 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.89, Tstamp:1715257187.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 217	GFLOPS: 18919.05 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.71, Tstamp:1715257188.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 218	GFLOPS: 13534.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.68, Tstamp:1715257188.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 219	GFLOPS: 17976.91 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.48, Tstamp:1715257188.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 220	GFLOPS: 16490.09 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715257188.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 221	GFLOPS: 12377.03 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.45, Tstamp:1715257189.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 222	GFLOPS: 13078.24 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.62, Tstamp:1715257189.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 223	GFLOPS: 17767.97 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.48, Tstamp:1715257189.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 224	GFLOPS: 16016.59 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715257190.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 225	GFLOPS: 18263.99 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.48, Tstamp:1715257190.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 226	GFLOPS: 15487.69 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715257190.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 227	GFLOPS: 19523.33 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715257191.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 228	GFLOPS: 13281.06 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.53, Tstamp:1715257191.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 229	GFLOPS: 17751.86 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715257191.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 230	GFLOPS: 19104.05 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.11, Tstamp:1715257192.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 231	GFLOPS: 16048.31 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.23, Tstamp:1715257192.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 232	GFLOPS: 12310.63 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.35, Tstamp:1715257192.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 233	GFLOPS: 11896.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.66, Tstamp:1715257192.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 234	GFLOPS: 16160.27 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715257193.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 235	GFLOPS: 12545.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715257193.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 236	GFLOPS: 10988.28 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715257193.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,24)
    compute = ...

==================================================
No: 237	GFLOPS: 12540.71 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257194.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 238	GFLOPS: 17442.87 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.07, Tstamp:1715257194.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 239	GFLOPS: 12243.76 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257194.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 240	GFLOPS: 11856.33 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715257195.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 241	GFLOPS: 17837.13 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.28, Tstamp:1715257195.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 242	GFLOPS: 16301.12 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.32, Tstamp:1715257195.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 243	GFLOPS: 11271.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.35, Tstamp:1715257195.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 244	GFLOPS: 12160.65 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715257196.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 245	GFLOPS: 12005.01 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.49, Tstamp:1715257196.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 246	GFLOPS: 17965.28 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.55, Tstamp:1715257196.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 247	GFLOPS: 16103.63 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.33, Tstamp:1715257197.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 248	GFLOPS: 11443.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715257197.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 249	GFLOPS: 11557.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257197.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 250	GFLOPS: 12349.36 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257198.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 251	GFLOPS: 17107.71 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715257198.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 252	GFLOPS: 15284.02 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.26, Tstamp:1715257198.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 253	GFLOPS: 12703.76 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257198.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 254	GFLOPS: 5862.32 / 21531.87	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.00, Tstamp:1715257199.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 512
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 255	GFLOPS: 1930.61 / 21531.87	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:4.49, Tstamp:1715257199.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 256	GFLOPS: 4469.74 / 21531.87	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.64, Tstamp:1715257199.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

Time elapsed for measurement: 29.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.04 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1684	fail_ct: 364	Time elapsed: 2.58
GA Iter: 0	Max score: 0.7830	Min score: 0.5248	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9340	Min score: 0.6368	#Pop: 128	#M+: 1378	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 257	GFLOPS: 11203.05 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.81, Tstamp:1715257224.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 258	GFLOPS: 19810.48 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.88, Tstamp:1715257224.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 259	GFLOPS: 19684.80 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.43, Tstamp:1715257224.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 260	GFLOPS: 16394.88 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715257225.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 261	GFLOPS: 20669.47 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715257225.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 262	GFLOPS: 18124.35 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.80, Tstamp:1715257225.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 263	GFLOPS: 20303.98 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.00, Tstamp:1715257226.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 264	GFLOPS: 16152.60 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.69, Tstamp:1715257226.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 265	GFLOPS: 19700.16 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.13, Tstamp:1715257226.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 266	GFLOPS: 19631.96 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.43, Tstamp:1715257227.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 267	GFLOPS: 16737.37 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.87, Tstamp:1715257227.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 268	GFLOPS: 17689.24 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.24, Tstamp:1715257227.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 269	GFLOPS: 17007.22 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.95, Tstamp:1715257228.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 270	GFLOPS: 15921.39 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.13, Tstamp:1715257228.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 271	GFLOPS: 20156.57 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.82, Tstamp:1715257228.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 272	GFLOPS: 19013.79 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.89, Tstamp:1715257229.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 273	GFLOPS: 16105.67 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.30, Tstamp:1715257229.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 274	GFLOPS: 19540.38 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.86, Tstamp:1715257229.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 275	GFLOPS: 17100.84 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.98, Tstamp:1715257230.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 276	GFLOPS: 13052.16 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.02, Tstamp:1715257230.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 277	GFLOPS: 17623.88 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.18, Tstamp:1715257230.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 278	GFLOPS: 15108.03 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.47, Tstamp:1715257231.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 279	GFLOPS: 21522.90 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.76, Tstamp:1715257231.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 280	GFLOPS: 14911.39 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715257231.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 281	GFLOPS: 21079.30 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.40, Tstamp:1715257232.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 282	GFLOPS: 15626.88 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.43, Tstamp:1715257232.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 283	GFLOPS: 15731.67 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715257232.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 284	GFLOPS: 15635.43 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715257233.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 285	GFLOPS: 15814.25 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715257233.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 286	GFLOPS: 15590.26 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.74, Tstamp:1715257233.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 287	GFLOPS: 15350.59 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.60, Tstamp:1715257234.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 288	GFLOPS: 19926.25 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.73, Tstamp:1715257234.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 289	GFLOPS: 12701.76 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715257234.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 290	GFLOPS: 15097.54 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715257235.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 291	GFLOPS: 15067.97 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.03, Tstamp:1715257235.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 292	GFLOPS: 10615.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257235.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 16
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 293	GFLOPS: 14777.79 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715257236.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 294	GFLOPS: 14625.61 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715257236.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 295	GFLOPS: 13727.82 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.35, Tstamp:1715257236.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 296	GFLOPS: 14640.50 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715257236.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 297	GFLOPS: 17502.81 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.18, Tstamp:1715257237.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 298	GFLOPS: 17351.36 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.06, Tstamp:1715257237.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 299	GFLOPS: 7402.60 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.33, Tstamp:1715257237.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 300	GFLOPS: 14201.13 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257237.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 301	GFLOPS: 14304.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.38, Tstamp:1715257238.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 302	GFLOPS: 14329.00 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715257238.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 303	GFLOPS: 14977.03 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715257238.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 304	GFLOPS: 15735.56 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715257238.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 305	GFLOPS: 13976.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257239.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 306	GFLOPS: 17698.20 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.08, Tstamp:1715257239.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 307	GFLOPS: 14550.66 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715257239.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 308	GFLOPS: 16662.30 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715257240.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 309	GFLOPS: 14023.78 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257240.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 310	GFLOPS: 11408.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257240.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 311	GFLOPS: 11114.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257241.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 312	GFLOPS: 13931.82 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257241.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 313	GFLOPS: 14216.00 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257241.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 314	GFLOPS: 13449.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.22, Tstamp:1715257241.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 315	GFLOPS: 14222.39 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257242.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 316	GFLOPS: 12295.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715257242.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 317	GFLOPS: 13077.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715257242.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 318	GFLOPS: 914.74 / 21531.87	results: MeasureResult(cost:[0.0040], error_no:0, all_cost:4.50, Tstamp:1715257243.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 319	GFLOPS: 2284.31 / 21531.87	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:0.69, Tstamp:1715257243.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 16
  for i.1 (0,192)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 320	GFLOPS: 4970.91 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.35, Tstamp:1715257243.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

Time elapsed for measurement: 30.12 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.81 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1650	fail_ct: 398	Time elapsed: 2.56
GA Iter: 0	Max score: 0.8391	Min score: 0.5025	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9569	Min score: 0.6501	#Pop: 128	#M+: 1380	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.19
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 321	GFLOPS: 20789.03 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.95, Tstamp:1715257265.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 322	GFLOPS: 18111.82 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.58, Tstamp:1715257265.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 323	GFLOPS: 19831.94 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.64, Tstamp:1715257266.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 324	GFLOPS: 13280.47 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.16, Tstamp:1715257266.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 325	GFLOPS: 18269.28 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.85, Tstamp:1715257266.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 326	GFLOPS: 17822.71 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.93, Tstamp:1715257266.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 327	GFLOPS: 7346.67 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.06, Tstamp:1715257267.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,16)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 328	GFLOPS: 17554.87 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.21, Tstamp:1715257267.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 329	GFLOPS: 9776.02 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.95, Tstamp:1715257267.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 330	GFLOPS: 5565.54 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.38, Tstamp:1715257268.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,12)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 331	GFLOPS: 3766.78 / 21531.87	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:2.25, Tstamp:1715257268.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,8)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,96)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 332	GFLOPS: 17472.09 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.72, Tstamp:1715257268.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 333	GFLOPS: 5488.81 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.03, Tstamp:1715257269.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,12)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,64)
      for n.1 (0,16)
        compute = ...

==================================================
No: 334	GFLOPS: 5458.13 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.98, Tstamp:1715257269.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,12)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 335	GFLOPS: 7230.12 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.35, Tstamp:1715257269.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,16)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 336	GFLOPS: 17958.05 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.73, Tstamp:1715257270.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 337	GFLOPS: 6874.22 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.03, Tstamp:1715257270.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 338	GFLOPS: 17058.16 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.69, Tstamp:1715257270.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 339	GFLOPS: 13060.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.39, Tstamp:1715257271.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 340	GFLOPS: 16059.94 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.24, Tstamp:1715257271.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 341	GFLOPS: 15821.68 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.62, Tstamp:1715257271.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 342	GFLOPS: 10213.59 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.87, Tstamp:1715257271.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 343	GFLOPS: 14616.50 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.70, Tstamp:1715257272.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 344	GFLOPS: 14423.50 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715257272.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 345	GFLOPS: 16214.36 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715257272.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 346	GFLOPS: 14655.14 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.43, Tstamp:1715257273.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 347	GFLOPS: 16033.95 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.37, Tstamp:1715257273.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 348	GFLOPS: 14735.77 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715257273.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 349	GFLOPS: 17104.20 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.54, Tstamp:1715257273.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 350	GFLOPS: 15345.05 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715257274.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 351	GFLOPS: 17249.59 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.36, Tstamp:1715257274.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 352	GFLOPS: 14730.12 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715257274.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 353	GFLOPS: 6397.60 / 21531.87	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.38, Tstamp:1715257275.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,16)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 354	GFLOPS: 3855.67 / 21531.87	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.55, Tstamp:1715257275.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,16)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 355	GFLOPS: 10456.08 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.45, Tstamp:1715257275.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 356	GFLOPS: 10310.38 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.62, Tstamp:1715257276.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 357	GFLOPS: 16678.16 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715257276.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 358	GFLOPS: 15948.12 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.24, Tstamp:1715257276.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 359	GFLOPS: 2810.86 / 21531.87	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:1.62, Tstamp:1715257276.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,6)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,128)
      for n.1 (0,16)
        compute = ...

==================================================
No: 360	GFLOPS: 12354.94 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257277.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 361	GFLOPS: 15951.18 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.32, Tstamp:1715257277.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 362	GFLOPS: 13776.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.34, Tstamp:1715257277.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 363	GFLOPS: 14277.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.59, Tstamp:1715257278.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 364	GFLOPS: 12183.47 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.16, Tstamp:1715257278.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 365	GFLOPS: 11799.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.53, Tstamp:1715257278.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 366	GFLOPS: 15634.54 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715257278.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 367	GFLOPS: 10325.32 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.99, Tstamp:1715257278.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,48)
        compute = ...

==================================================
No: 368	GFLOPS: 11595.16 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.22, Tstamp:1715257279.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 369	GFLOPS: 11161.53 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.60, Tstamp:1715257279.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 370	GFLOPS: 13358.66 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.24, Tstamp:1715257279.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 371	GFLOPS: 13278.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.26, Tstamp:1715257280.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 372	GFLOPS: 13233.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.50, Tstamp:1715257280.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 373	GFLOPS: 13200.64 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.50, Tstamp:1715257280.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 374	GFLOPS: 12471.63 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.41, Tstamp:1715257281.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 375	GFLOPS: 12968.39 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.27, Tstamp:1715257281.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 376	GFLOPS: 13059.47 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.27, Tstamp:1715257281.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 377	GFLOPS: 1646.12 / 21531.87	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:1.26, Tstamp:1715257282.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,4)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,32)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,192)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 378	GFLOPS: 9550.25 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.20, Tstamp:1715257282.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 379	GFLOPS: 12155.78 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257282.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 380	GFLOPS: 8072.65 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.54, Tstamp:1715257283.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 381	GFLOPS: 11712.94 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.17, Tstamp:1715257283.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 382	GFLOPS: 1335.70 / 21531.87	results: MeasureResult(cost:[0.0027], error_no:0, all_cost:0.34, Tstamp:1715257283.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 383	GFLOPS: 1564.37 / 21531.87	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:0.48, Tstamp:1715257284.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 384	GFLOPS: 12079.84 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257284.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

Time elapsed for measurement: 26.83 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.96 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1676	fail_ct: 372	Time elapsed: 2.53
GA Iter: 0	Max score: 0.6681	Min score: 0.4948	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9419	Min score: 0.6300	#Pop: 128	#M+: 1371	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 10.12
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 385	GFLOPS: 10977.59 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.65, Tstamp:1715257308.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 386	GFLOPS: 13532.59 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.78, Tstamp:1715257309.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 387	GFLOPS: 18896.01 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.68, Tstamp:1715257309.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 388	GFLOPS: 17046.85 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.18, Tstamp:1715257309.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 389	GFLOPS: 18093.56 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.69, Tstamp:1715257309.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 390	GFLOPS: 14944.61 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.34, Tstamp:1715257310.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 391	GFLOPS: 18205.68 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.21, Tstamp:1715257310.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 392	GFLOPS: 7796.91 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.05, Tstamp:1715257310.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 393	GFLOPS: 18223.15 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715257311.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 394	GFLOPS: 15136.16 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.35, Tstamp:1715257311.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 395	GFLOPS: 15633.22 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.01, Tstamp:1715257311.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 396	GFLOPS: 12416.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257311.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 397	GFLOPS: 15300.53 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.82, Tstamp:1715257312.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 398	GFLOPS: 10701.57 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.45, Tstamp:1715257312.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 399	GFLOPS: 15480.41 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715257313.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 400	GFLOPS: 14627.98 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.49, Tstamp:1715257313.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 401	GFLOPS: 14799.54 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.89, Tstamp:1715257313.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 402	GFLOPS: 15047.98 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.28, Tstamp:1715257313.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 403	GFLOPS: 14785.18 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.57, Tstamp:1715257314.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 404	GFLOPS: 12500.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715257314.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 405	GFLOPS: 15789.56 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.22, Tstamp:1715257314.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 406	GFLOPS: 16441.27 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715257315.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 407	GFLOPS: 10330.62 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.92, Tstamp:1715257315.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 408	GFLOPS: 11341.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715257315.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 409	GFLOPS: 14347.19 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.14, Tstamp:1715257315.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 410	GFLOPS: 13904.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.17, Tstamp:1715257316.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 411	GFLOPS: 15337.03 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.37, Tstamp:1715257316.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 412	GFLOPS: 13626.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.56, Tstamp:1715257317.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 413	GFLOPS: 13568.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257317.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 414	GFLOPS: 13699.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.50, Tstamp:1715257317.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 415	GFLOPS: 17790.30 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715257318.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 416	GFLOPS: 14083.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.86, Tstamp:1715257318.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 417	GFLOPS: 12745.57 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.88, Tstamp:1715257318.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 418	GFLOPS: 13518.53 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257319.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 419	GFLOPS: 15080.55 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.07, Tstamp:1715257319.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,24)
        compute = ...

==================================================
No: 420	GFLOPS: 11957.35 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257319.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 421	GFLOPS: 12419.03 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257319.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 422	GFLOPS: 10798.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.57, Tstamp:1715257320.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 423	GFLOPS: 14938.92 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715257320.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 424	GFLOPS: 11937.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257320.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 425	GFLOPS: 11439.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.90, Tstamp:1715257321.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 426	GFLOPS: 11931.45 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257321.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 427	GFLOPS: 15036.87 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.02, Tstamp:1715257321.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 428	GFLOPS: 11720.20 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.88, Tstamp:1715257322.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 429	GFLOPS: 11396.06 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.81, Tstamp:1715257322.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 430	GFLOPS: 15432.82 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715257322.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 431	GFLOPS: 14405.16 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.38, Tstamp:1715257322.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 432	GFLOPS: 12034.41 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.21, Tstamp:1715257323.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 433	GFLOPS: 15536.07 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.86, Tstamp:1715257323.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 434	GFLOPS: 13595.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.54, Tstamp:1715257323.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 435	GFLOPS: 14307.59 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257324.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 436	GFLOPS: 14649.96 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715257324.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 437	GFLOPS: 14341.76 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257324.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 438	GFLOPS: 13543.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.38, Tstamp:1715257325.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 439	GFLOPS: 13918.78 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.37, Tstamp:1715257325.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 440	GFLOPS: 14590.84 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715257325.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 441	GFLOPS: 15410.88 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715257325.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 442	GFLOPS: 14196.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715257326.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 443	GFLOPS: 13207.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257326.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 444	GFLOPS: 14966.30 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.91, Tstamp:1715257326.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 445	GFLOPS: 15868.73 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715257327.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 446	GFLOPS: 1547.12 / 21531.87	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:3.11, Tstamp:1715257327.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 447	GFLOPS: 4533.53 / 21531.87	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:4.47, Tstamp:1715257327.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 448	GFLOPS: 1461.91 / 21531.87	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:0.52, Tstamp:1715257328.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 30.07 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.79 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1685	fail_ct: 363	Time elapsed: 2.54
GA Iter: 0	Max score: 0.7703	Min score: 0.4984	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8812	Min score: 0.6306	#Pop: 128	#M+: 1383	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 10.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 449	GFLOPS: 18892.35 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.33, Tstamp:1715257350.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 450	GFLOPS: 16213.55 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:3.79, Tstamp:1715257350.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 451	GFLOPS: 14042.25 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.88, Tstamp:1715257350.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 452	GFLOPS: 19607.35 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.38, Tstamp:1715257351.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 453	GFLOPS: 18057.96 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.98, Tstamp:1715257351.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 454	GFLOPS: 21499.04 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.30, Tstamp:1715257351.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 455	GFLOPS: 7079.79 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.69, Tstamp:1715257352.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 456	GFLOPS: 10960.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.03, Tstamp:1715257352.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 457	GFLOPS: 10025.50 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.02, Tstamp:1715257352.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 458	GFLOPS: 15111.74 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.47, Tstamp:1715257352.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 459	GFLOPS: 15034.02 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.38, Tstamp:1715257353.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 460	GFLOPS: 17783.01 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.23, Tstamp:1715257353.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 461	GFLOPS: 10382.69 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.34, Tstamp:1715257353.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,192)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 462	GFLOPS: 14148.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.76, Tstamp:1715257354.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 463	GFLOPS: 8330.53 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.33, Tstamp:1715257354.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 464	GFLOPS: 13384.04 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.18, Tstamp:1715257354.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,24)
        compute = ...

==================================================
No: 465	GFLOPS: 15068.25 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.31, Tstamp:1715257355.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 466	GFLOPS: 15261.44 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.74, Tstamp:1715257355.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 467	GFLOPS: 15541.37 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.03, Tstamp:1715257356.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 468	GFLOPS: 11990.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.87, Tstamp:1715257356.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 469	GFLOPS: 12989.41 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.94, Tstamp:1715257356.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 470	GFLOPS: 16562.07 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715257356.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 471	GFLOPS: 15236.78 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715257357.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 472	GFLOPS: 10473.70 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.64, Tstamp:1715257357.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,24)
        compute = ...

==================================================
No: 473	GFLOPS: 10426.18 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715257357.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 474	GFLOPS: 9925.30 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.89, Tstamp:1715257358.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 475	GFLOPS: 14036.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.96, Tstamp:1715257358.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 476	GFLOPS: 14744.70 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715257358.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 477	GFLOPS: 14157.52 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715257358.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 478	GFLOPS: 17325.67 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715257359.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 479	GFLOPS: 12914.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.46, Tstamp:1715257359.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 480	GFLOPS: 13905.04 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257359.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 481	GFLOPS: 12399.89 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257360.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 482	GFLOPS: 14708.29 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.80, Tstamp:1715257360.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 483	GFLOPS: 14709.73 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715257360.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 484	GFLOPS: 14056.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715257361.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 485	GFLOPS: 9925.25 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.38, Tstamp:1715257361.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 486	GFLOPS: 7850.83 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.61, Tstamp:1715257361.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 487	GFLOPS: 16405.03 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715257361.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 488	GFLOPS: 14284.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.37, Tstamp:1715257362.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 489	GFLOPS: 13312.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.72, Tstamp:1715257362.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 490	GFLOPS: 10302.65 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.76, Tstamp:1715257362.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 491	GFLOPS: 13959.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.95, Tstamp:1715257363.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 492	GFLOPS: 13519.54 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.04, Tstamp:1715257363.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 493	GFLOPS: 7535.16 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.42, Tstamp:1715257363.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 494	GFLOPS: 14425.74 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257363.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 495	GFLOPS: 13294.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.43, Tstamp:1715257364.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 496	GFLOPS: 9560.04 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.71, Tstamp:1715257364.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 497	GFLOPS: 13607.95 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.48, Tstamp:1715257364.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 498	GFLOPS: 14594.01 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715257365.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 499	GFLOPS: 12949.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.31, Tstamp:1715257365.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 500	GFLOPS: 14141.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715257365.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 501	GFLOPS: 14496.19 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715257366.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 502	GFLOPS: 14498.16 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715257366.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 503	GFLOPS: 12739.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.25, Tstamp:1715257366.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 504	GFLOPS: 10568.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.37, Tstamp:1715257367.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 505	GFLOPS: 14208.45 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257367.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 506	GFLOPS: 14132.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257367.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 507	GFLOPS: 12933.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715257367.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 508	GFLOPS: 14681.11 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.39, Tstamp:1715257368.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 509	GFLOPS: 14828.17 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715257368.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 510	GFLOPS: 1125.63 / 21531.87	results: MeasureResult(cost:[0.0032], error_no:0, all_cost:0.54, Tstamp:1715257368.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 511	GFLOPS: 1725.53 / 21531.87	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:1.21, Tstamp:1715257369.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 512	GFLOPS: 9561.58 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.71, Tstamp:1715257369.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

Time elapsed for measurement: 27.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.07 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1673	fail_ct: 375	Time elapsed: 2.56
GA Iter: 0	Max score: 0.7530	Min score: 0.4835	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8732	Min score: 0.6206	#Pop: 128	#M+: 1389	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 10.33
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 513	GFLOPS: 17609.13 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.99, Tstamp:1715257391.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 514	GFLOPS: 8977.99 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.56, Tstamp:1715257391.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 515	GFLOPS: 16900.84 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.58, Tstamp:1715257391.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 516	GFLOPS: 10101.08 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.19, Tstamp:1715257392.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 517	GFLOPS: 7545.01 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.49, Tstamp:1715257392.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 518	GFLOPS: 16748.54 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.56, Tstamp:1715257392.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 519	GFLOPS: 12885.29 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715257392.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 520	GFLOPS: 12862.86 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.79, Tstamp:1715257393.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 521	GFLOPS: 14785.86 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.43, Tstamp:1715257393.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 522	GFLOPS: 12569.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.31, Tstamp:1715257394.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 523	GFLOPS: 8936.07 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.63, Tstamp:1715257394.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 524	GFLOPS: 10417.24 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.99, Tstamp:1715257394.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 525	GFLOPS: 12448.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.99, Tstamp:1715257394.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 526	GFLOPS: 13673.20 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.50, Tstamp:1715257395.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 527	GFLOPS: 14420.25 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715257395.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 528	GFLOPS: 13447.81 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.57, Tstamp:1715257396.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 529	GFLOPS: 12362.04 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.27, Tstamp:1715257396.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 530	GFLOPS: 12761.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.87, Tstamp:1715257396.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 531	GFLOPS: 11400.35 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.87, Tstamp:1715257396.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,16)
      compute = ...

==================================================
No: 532	GFLOPS: 14434.50 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257397.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 533	GFLOPS: 12585.51 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257397.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 534	GFLOPS: 13347.17 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715257397.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 535	GFLOPS: 7715.95 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.58, Tstamp:1715257398.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 536	GFLOPS: 14689.74 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715257398.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 537	GFLOPS: 13486.00 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.12, Tstamp:1715257398.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 538	GFLOPS: 13050.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.76, Tstamp:1715257399.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 539	GFLOPS: 13522.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.12, Tstamp:1715257399.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 540	GFLOPS: 14474.93 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715257399.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 541	GFLOPS: 13001.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257399.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 542	GFLOPS: 12905.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715257400.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 543	GFLOPS: 14601.41 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715257400.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 544	GFLOPS: 13293.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.83, Tstamp:1715257400.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 545	GFLOPS: 13627.00 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257401.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 546	GFLOPS: 13411.37 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.98, Tstamp:1715257401.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 547	GFLOPS: 10773.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257401.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 548	GFLOPS: 12971.15 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715257402.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 549	GFLOPS: 10389.58 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257402.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 550	GFLOPS: 9651.91 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.59, Tstamp:1715257402.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 551	GFLOPS: 13640.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715257403.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 552	GFLOPS: 13873.69 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257403.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 553	GFLOPS: 8306.90 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.20, Tstamp:1715257403.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 554	GFLOPS: 13462.52 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715257404.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 555	GFLOPS: 13523.95 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257404.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 556	GFLOPS: 10455.78 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257404.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 557	GFLOPS: 8665.69 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.49, Tstamp:1715257405.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 558	GFLOPS: 7231.46 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.44, Tstamp:1715257405.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 559	GFLOPS: 13575.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257405.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 560	GFLOPS: 11737.05 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715257405.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 561	GFLOPS: 7622.76 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.28, Tstamp:1715257406.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 562	GFLOPS: 14607.97 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715257406.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 563	GFLOPS: 14569.94 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.21, Tstamp:1715257406.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 564	GFLOPS: 13650.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715257407.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 565	GFLOPS: 14744.77 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715257407.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 566	GFLOPS: 13258.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257407.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 567	GFLOPS: 14316.88 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257408.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 568	GFLOPS: 13909.17 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257408.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 569	GFLOPS: 13245.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.54, Tstamp:1715257408.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 570	GFLOPS: 9774.37 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.27, Tstamp:1715257409.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,24)
      for c (0,16)
        compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 571	GFLOPS: 13040.51 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257409.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 572	GFLOPS: 13078.89 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715257409.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 573	GFLOPS: 10321.62 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.59, Tstamp:1715257410.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 574	GFLOPS: 1480.16 / 21531.87	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.97, Tstamp:1715257410.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,3)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 575	GFLOPS: 5504.69 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.48, Tstamp:1715257410.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 576	GFLOPS: 4283.57 / 21531.87	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.76, Tstamp:1715257411.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 64
  for i.1 (0,128)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    for n.1 (0,48)
      compute = ...

Time elapsed for measurement: 27.74 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.90 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1655	fail_ct: 393	Time elapsed: 2.59
GA Iter: 0	Max score: 0.7336	Min score: 0.4823	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9144	Min score: 0.6164	#Pop: 128	#M+: 1371	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 10.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 577	GFLOPS: 13754.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.98, Tstamp:1715257433.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 578	GFLOPS: 12238.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.94, Tstamp:1715257433.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 579	GFLOPS: 18335.50 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.74, Tstamp:1715257433.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 580	GFLOPS: 15093.25 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.88, Tstamp:1715257434.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 581	GFLOPS: 17980.62 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.68, Tstamp:1715257434.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 582	GFLOPS: 8078.47 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.96, Tstamp:1715257434.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 583	GFLOPS: 11360.53 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.46, Tstamp:1715257435.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 584	GFLOPS: 11330.63 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.92, Tstamp:1715257435.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 585	GFLOPS: 8251.94 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.64, Tstamp:1715257435.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 586	GFLOPS: 9066.35 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.78, Tstamp:1715257435.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 587	GFLOPS: 14386.68 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.59, Tstamp:1715257436.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 588	GFLOPS: 14521.69 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715257436.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 589	GFLOPS: 14467.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.96, Tstamp:1715257436.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 590	GFLOPS: 12897.24 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.74, Tstamp:1715257437.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 591	GFLOPS: 14140.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257437.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 592	GFLOPS: 14844.93 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.72, Tstamp:1715257437.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 593	GFLOPS: 10955.39 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.56, Tstamp:1715257438.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 594	GFLOPS: 10724.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.97, Tstamp:1715257438.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 595	GFLOPS: 13639.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.00, Tstamp:1715257438.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 596	GFLOPS: 10608.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715257439.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,48)
      for c (0,16)
        compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 597	GFLOPS: 14670.68 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715257439.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 598	GFLOPS: 13264.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715257439.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 599	GFLOPS: 9190.64 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.78, Tstamp:1715257440.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 600	GFLOPS: 13228.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715257440.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 601	GFLOPS: 14144.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257440.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 602	GFLOPS: 14777.33 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715257441.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 603	GFLOPS: 12901.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.77, Tstamp:1715257441.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 604	GFLOPS: 13253.19 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257441.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 605	GFLOPS: 13686.99 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257441.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 606	GFLOPS: 12937.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715257442.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 607	GFLOPS: 12726.50 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257442.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 608	GFLOPS: 13091.91 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715257442.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 609	GFLOPS: 13077.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715257443.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 610	GFLOPS: 12193.33 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715257443.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 611	GFLOPS: 13043.12 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257443.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 612	GFLOPS: 13156.68 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257444.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 613	GFLOPS: 13448.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257444.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 614	GFLOPS: 14203.94 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.31, Tstamp:1715257444.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 615	GFLOPS: 14473.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257444.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 616	GFLOPS: 9982.71 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.34, Tstamp:1715257445.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 617	GFLOPS: 13533.38 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.54, Tstamp:1715257445.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 618	GFLOPS: 14295.28 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715257445.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 619	GFLOPS: 14376.84 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257446.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 620	GFLOPS: 14194.41 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.35, Tstamp:1715257446.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 621	GFLOPS: 13044.69 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257446.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 622	GFLOPS: 13130.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257446.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 623	GFLOPS: 12369.08 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.91, Tstamp:1715257447.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 624	GFLOPS: 13287.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257447.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 625	GFLOPS: 13168.03 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257447.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 626	GFLOPS: 12964.70 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715257448.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 627	GFLOPS: 13043.75 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257448.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 628	GFLOPS: 13226.06 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257448.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 629	GFLOPS: 13704.63 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715257449.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 630	GFLOPS: 15195.63 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715257449.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 631	GFLOPS: 12869.01 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257449.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 632	GFLOPS: 13439.94 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257450.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 633	GFLOPS: 12321.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257450.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 634	GFLOPS: 13247.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257450.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 635	GFLOPS: 13205.23 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257451.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 636	GFLOPS: 11236.36 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257451.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 637	GFLOPS: 13322.34 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257451.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 638	GFLOPS: 4943.54 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.60, Tstamp:1715257452.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    for n.1 (0,48)
      compute = ...

==================================================
No: 639	GFLOPS: 6936.08 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.45, Tstamp:1715257452.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 640	GFLOPS: 810.51 / 21531.87	results: MeasureResult(cost:[0.0045], error_no:0, all_cost:0.46, Tstamp:1715257452.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 27.68 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.99 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1651	fail_ct: 397	Time elapsed: 2.50
GA Iter: 0	Max score: 0.6376	Min score: 0.4904	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8898	Min score: 0.6046	#Pop: 128	#M+: 1384	#M-: 84
EvolutionarySearch		#s: 128	Time elapsed: 10.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 641	GFLOPS: 7323.21 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.91, Tstamp:1715257473.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,96)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 642	GFLOPS: 12298.95 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.83, Tstamp:1715257474.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,96)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 643	GFLOPS: 10521.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.97, Tstamp:1715257474.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 644	GFLOPS: 12451.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.65, Tstamp:1715257474.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 645	GFLOPS: 12559.79 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.25, Tstamp:1715257474.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 646	GFLOPS: 12952.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.33, Tstamp:1715257475.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 647	GFLOPS: 8799.28 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.49, Tstamp:1715257475.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 648	GFLOPS: 14547.96 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715257476.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 649	GFLOPS: 8952.77 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.08, Tstamp:1715257476.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 650	GFLOPS: 10731.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.10, Tstamp:1715257476.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 651	GFLOPS: 13180.68 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.13, Tstamp:1715257476.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 652	GFLOPS: 14092.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715257477.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 653	GFLOPS: 14131.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.91, Tstamp:1715257477.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 654	GFLOPS: 14433.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.59, Tstamp:1715257477.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 655	GFLOPS: 14166.81 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257478.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 656	GFLOPS: 10493.35 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715257478.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 657	GFLOPS: 16783.19 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715257478.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 658	GFLOPS: 14321.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.90, Tstamp:1715257479.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 659	GFLOPS: 10748.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.01, Tstamp:1715257479.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 660	GFLOPS: 14310.29 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715257479.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 661	GFLOPS: 13701.06 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257479.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 662	GFLOPS: 12241.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.81, Tstamp:1715257480.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 663	GFLOPS: 10284.65 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.54, Tstamp:1715257480.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 664	GFLOPS: 14096.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257480.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 665	GFLOPS: 11346.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.80, Tstamp:1715257481.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 666	GFLOPS: 13679.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.83, Tstamp:1715257481.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 667	GFLOPS: 12814.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.04, Tstamp:1715257481.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 668	GFLOPS: 12631.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257481.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 669	GFLOPS: 10134.04 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.56, Tstamp:1715257482.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 670	GFLOPS: 13144.00 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715257482.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 671	GFLOPS: 13110.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715257482.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 672	GFLOPS: 12379.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.99, Tstamp:1715257482.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 673	GFLOPS: 10411.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.83, Tstamp:1715257483.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 674	GFLOPS: 13192.27 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715257483.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 675	GFLOPS: 13485.99 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715257484.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 676	GFLOPS: 13198.12 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257484.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 677	GFLOPS: 13517.93 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715257484.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 678	GFLOPS: 15153.08 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715257484.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,6)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 679	GFLOPS: 12804.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715257485.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 680	GFLOPS: 12346.32 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715257485.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 681	GFLOPS: 14165.65 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257486.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 682	GFLOPS: 13970.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257486.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 683	GFLOPS: 13869.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715257486.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 684	GFLOPS: 13314.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257486.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 685	GFLOPS: 13240.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.00, Tstamp:1715257487.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 686	GFLOPS: 13147.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715257487.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 687	GFLOPS: 12743.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715257487.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 688	GFLOPS: 12794.84 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715257487.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 689	GFLOPS: 13969.69 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715257488.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 690	GFLOPS: 12726.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.14, Tstamp:1715257488.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 691	GFLOPS: 12567.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.55, Tstamp:1715257489.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,24)
        compute = ...

==================================================
No: 692	GFLOPS: 13418.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257489.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 693	GFLOPS: 12718.82 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257489.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 694	GFLOPS: 12909.36 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715257489.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 695	GFLOPS: 13794.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715257490.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 696	GFLOPS: 14324.35 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257490.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 697	GFLOPS: 13054.66 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715257490.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 698	GFLOPS: 13233.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715257491.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 699	GFLOPS: 14355.33 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.25, Tstamp:1715257491.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,16)
        compute = ...

==================================================
No: 700	GFLOPS: 13109.28 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257491.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 701	GFLOPS: 12865.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257492.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 702	GFLOPS: 3276.33 / 21531.87	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.60, Tstamp:1715257492.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 703	GFLOPS: 5572.76 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.50, Tstamp:1715257492.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 704	GFLOPS: 11310.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.26, Tstamp:1715257492.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 26.76 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.84 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1665	fail_ct: 383	Time elapsed: 2.55
GA Iter: 0	Max score: 0.6341	Min score: 0.4918	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8967	Min score: 0.5993	#Pop: 128	#M+: 1384	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 705	GFLOPS: 12783.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.89, Tstamp:1715257515.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 706	GFLOPS: 9484.92 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.61, Tstamp:1715257515.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 707	GFLOPS: 16719.46 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715257516.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 708	GFLOPS: 14217.76 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.31, Tstamp:1715257516.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 709	GFLOPS: 12861.22 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.01, Tstamp:1715257516.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,3)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 710	GFLOPS: 13373.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.42, Tstamp:1715257517.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,48)
      compute = ...

==================================================
No: 711	GFLOPS: 15208.38 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.54, Tstamp:1715257517.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 712	GFLOPS: 11612.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257517.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,3)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 713	GFLOPS: 14707.81 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.99, Tstamp:1715257518.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 714	GFLOPS: 14285.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257518.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 715	GFLOPS: 13648.86 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.76, Tstamp:1715257518.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 716	GFLOPS: 14332.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.00, Tstamp:1715257519.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 717	GFLOPS: 13862.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.08, Tstamp:1715257519.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 718	GFLOPS: 13556.52 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.98, Tstamp:1715257519.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 719	GFLOPS: 14402.76 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257520.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 720	GFLOPS: 12735.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.81, Tstamp:1715257520.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 721	GFLOPS: 14567.75 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.86, Tstamp:1715257520.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 722	GFLOPS: 11295.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257520.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 723	GFLOPS: 12918.01 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.86, Tstamp:1715257521.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 724	GFLOPS: 13482.66 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.02, Tstamp:1715257521.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 725	GFLOPS: 13801.16 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.84, Tstamp:1715257521.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 726	GFLOPS: 13957.74 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.86, Tstamp:1715257522.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 727	GFLOPS: 11970.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.99, Tstamp:1715257522.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 728	GFLOPS: 14018.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715257522.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 729	GFLOPS: 11983.18 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257523.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,2)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 730	GFLOPS: 13826.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.18, Tstamp:1715257523.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 731	GFLOPS: 13311.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257523.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
    for m.1 (0,3)
      compute = ...

==================================================
No: 732	GFLOPS: 14020.23 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.88, Tstamp:1715257524.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 733	GFLOPS: 14681.50 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715257524.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 734	GFLOPS: 13634.33 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.83, Tstamp:1715257524.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 735	GFLOPS: 13938.32 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257525.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 736	GFLOPS: 14351.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715257525.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 737	GFLOPS: 14577.17 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715257526.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 738	GFLOPS: 13040.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257526.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 739	GFLOPS: 13593.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715257526.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 740	GFLOPS: 13213.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257526.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 741	GFLOPS: 10028.26 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.75, Tstamp:1715257527.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 742	GFLOPS: 12567.36 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715257527.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 743	GFLOPS: 12217.38 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257527.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 744	GFLOPS: 12922.53 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257528.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 745	GFLOPS: 14283.91 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257528.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 746	GFLOPS: 13614.70 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257528.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 747	GFLOPS: 13378.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.86, Tstamp:1715257529.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 748	GFLOPS: 12637.29 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715257529.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 749	GFLOPS: 14320.23 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715257529.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 750	GFLOPS: 13110.94 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715257530.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 751	GFLOPS: 12970.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257530.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 752	GFLOPS: 12974.69 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257530.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 753	GFLOPS: 11370.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.64, Tstamp:1715257531.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 754	GFLOPS: 13051.23 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715257531.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 755	GFLOPS: 13090.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257531.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 756	GFLOPS: 12281.86 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715257532.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 757	GFLOPS: 13107.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257532.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 758	GFLOPS: 13122.88 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257532.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 759	GFLOPS: 13217.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715257532.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 760	GFLOPS: 13841.62 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257533.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 761	GFLOPS: 12869.28 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715257533.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 762	GFLOPS: 12981.33 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257533.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 763	GFLOPS: 13227.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.94, Tstamp:1715257534.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 764	GFLOPS: 13433.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715257534.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 765	GFLOPS: 13763.39 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715257534.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 766	GFLOPS: 773.68 / 21531.87	results: MeasureResult(cost:[0.0047], error_no:0, all_cost:0.62, Tstamp:1715257534.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,192)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 767	GFLOPS: 1330.10 / 21531.87	results: MeasureResult(cost:[0.0027], error_no:0, all_cost:0.53, Tstamp:1715257535.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 768	GFLOPS: 1820.73 / 21531.87	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:2.46, Tstamp:1715257535.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,6)
      compute = ...

Time elapsed for measurement: 28.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.91 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1678	fail_ct: 370	Time elapsed: 2.54
GA Iter: 0	Max score: 0.6166	Min score: 0.4781	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8527	Min score: 0.5852	#Pop: 128	#M+: 1387	#M-: 66
EvolutionarySearch		#s: 128	Time elapsed: 10.23
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 769	GFLOPS: 4462.29 / 21531.87	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:3.01, Tstamp:1715257556.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 770	GFLOPS: 5736.22 / 21531.87	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.49, Tstamp:1715257556.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 771	GFLOPS: 12435.20 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.17, Tstamp:1715257557.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 772	GFLOPS: 13468.84 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.67, Tstamp:1715257557.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 773	GFLOPS: 13457.71 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.01, Tstamp:1715257557.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 774	GFLOPS: 14577.33 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.04, Tstamp:1715257558.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 775	GFLOPS: 13778.29 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.00, Tstamp:1715257558.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 776	GFLOPS: 14250.01 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257558.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 777	GFLOPS: 14559.30 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.99, Tstamp:1715257559.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 778	GFLOPS: 15157.12 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.55, Tstamp:1715257559.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,48)
        compute = ...

==================================================
No: 779	GFLOPS: 14404.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715257559.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 780	GFLOPS: 12061.45 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.13, Tstamp:1715257560.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      compute = ...

==================================================
No: 781	GFLOPS: 13911.01 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.34, Tstamp:1715257560.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 782	GFLOPS: 13515.41 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257560.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 783	GFLOPS: 14326.41 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715257561.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 784	GFLOPS: 13561.19 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715257561.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 785	GFLOPS: 14579.18 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.77, Tstamp:1715257561.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 786	GFLOPS: 13816.18 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.09, Tstamp:1715257562.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 787	GFLOPS: 14079.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.33, Tstamp:1715257562.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 788	GFLOPS: 14155.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257562.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 789	GFLOPS: 14628.13 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715257563.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 790	GFLOPS: 8751.27 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.70, Tstamp:1715257563.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 791	GFLOPS: 12539.71 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.09, Tstamp:1715257563.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 792	GFLOPS: 14162.53 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.14, Tstamp:1715257564.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 793	GFLOPS: 10792.58 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.91, Tstamp:1715257564.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
    for m.1 (0,3)
      compute = ...

==================================================
No: 794	GFLOPS: 13870.19 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.95, Tstamp:1715257564.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 795	GFLOPS: 14014.47 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257565.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 796	GFLOPS: 14016.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.96, Tstamp:1715257565.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 797	GFLOPS: 14290.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715257565.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 798	GFLOPS: 13315.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715257566.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 799	GFLOPS: 13102.95 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257566.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 800	GFLOPS: 12691.15 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.83, Tstamp:1715257566.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 801	GFLOPS: 13137.27 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257566.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 802	GFLOPS: 13223.69 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715257567.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 803	GFLOPS: 12991.86 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257567.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 804	GFLOPS: 13151.54 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715257567.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 805	GFLOPS: 12968.05 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257568.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 806	GFLOPS: 13469.63 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257568.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 807	GFLOPS: 12873.65 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715257568.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 808	GFLOPS: 13264.45 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257568.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 809	GFLOPS: 13299.34 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257569.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 810	GFLOPS: 13134.81 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257569.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 811	GFLOPS: 13088.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715257569.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 812	GFLOPS: 6428.66 / 21531.87	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.36, Tstamp:1715257570.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 813	GFLOPS: 7306.60 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.82, Tstamp:1715257570.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
    for m.1 (0,16)
      compute = ...

==================================================
No: 814	GFLOPS: 12184.64 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715257570.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 815	GFLOPS: 13424.77 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715257571.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 816	GFLOPS: 13034.10 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257571.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 817	GFLOPS: 13120.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.15, Tstamp:1715257571.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 818	GFLOPS: 13065.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257572.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 819	GFLOPS: 12965.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715257572.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 820	GFLOPS: 12828.35 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257572.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 821	GFLOPS: 12942.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715257572.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 822	GFLOPS: 12966.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715257573.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 823	GFLOPS: 12897.36 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715257573.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 824	GFLOPS: 12946.99 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.55, Tstamp:1715257573.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 825	GFLOPS: 9546.96 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.43, Tstamp:1715257574.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 826	GFLOPS: 12956.51 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257574.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 827	GFLOPS: 13097.28 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257574.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 828	GFLOPS: 13543.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257575.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 829	GFLOPS: 12831.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.80, Tstamp:1715257575.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 830	GFLOPS: 4088.93 / 21531.87	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.84, Tstamp:1715257575.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 831	GFLOPS: 8786.22 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.58, Tstamp:1715257576.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,24)
      compute = ...

==================================================
No: 832	GFLOPS: 5538.45 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.39, Tstamp:1715257576.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 27.27 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.96 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1657	fail_ct: 391	Time elapsed: 2.55
GA Iter: 0	Max score: 0.6134	Min score: 0.4782	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6436	Min score: 0.5625	#Pop: 128	#M+: 1366	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 833	GFLOPS: 7367.91 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.11, Tstamp:1715257597.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 834	GFLOPS: 14349.86 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.35, Tstamp:1715257597.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 835	GFLOPS: 13804.75 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.03, Tstamp:1715257598.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 836	GFLOPS: 13577.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.68, Tstamp:1715257598.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 837	GFLOPS: 14230.39 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.06, Tstamp:1715257598.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 838	GFLOPS: 14152.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.77, Tstamp:1715257598.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 839	GFLOPS: 13497.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715257599.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 840	GFLOPS: 12636.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.97, Tstamp:1715257599.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 841	GFLOPS: 13542.44 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.69, Tstamp:1715257599.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 842	GFLOPS: 12982.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.00, Tstamp:1715257600.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 843	GFLOPS: 12778.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715257600.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 844	GFLOPS: 13207.24 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.95, Tstamp:1715257600.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 845	GFLOPS: 13167.11 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257601.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 846	GFLOPS: 6623.12 / 21531.87	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.85, Tstamp:1715257601.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 847	GFLOPS: 8563.48 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.01, Tstamp:1715257601.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 848	GFLOPS: 12242.88 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.94, Tstamp:1715257601.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 849	GFLOPS: 13365.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.03, Tstamp:1715257602.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 850	GFLOPS: 13519.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.24, Tstamp:1715257602.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 851	GFLOPS: 10606.54 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257602.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 852	GFLOPS: 13728.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.54, Tstamp:1715257603.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 853	GFLOPS: 14736.87 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.19, Tstamp:1715257603.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 854	GFLOPS: 13013.89 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715257603.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 855	GFLOPS: 13191.71 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.14, Tstamp:1715257604.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 856	GFLOPS: 12690.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257604.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 857	GFLOPS: 12127.20 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715257604.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 858	GFLOPS: 13388.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715257605.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 859	GFLOPS: 13263.78 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257605.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 860	GFLOPS: 13047.64 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257605.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 861	GFLOPS: 13326.66 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715257605.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 862	GFLOPS: 13258.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257606.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 863	GFLOPS: 12304.38 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257606.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 864	GFLOPS: 13212.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.91, Tstamp:1715257606.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 865	GFLOPS: 13201.79 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257607.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 866	GFLOPS: 12820.82 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257607.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 867	GFLOPS: 12777.34 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257607.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 868	GFLOPS: 13363.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257607.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 869	GFLOPS: 13185.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.99, Tstamp:1715257608.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 870	GFLOPS: 13065.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715257608.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 871	GFLOPS: 13344.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715257608.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 872	GFLOPS: 12194.86 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715257608.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 873	GFLOPS: 12739.12 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257609.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 874	GFLOPS: 12983.00 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257609.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 875	GFLOPS: 13091.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.54, Tstamp:1715257609.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 876	GFLOPS: 13286.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257610.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 877	GFLOPS: 13145.62 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257610.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 878	GFLOPS: 12761.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.81, Tstamp:1715257610.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 879	GFLOPS: 11156.18 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715257611.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 880	GFLOPS: 13234.27 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715257611.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 881	GFLOPS: 12268.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.45, Tstamp:1715257611.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 882	GFLOPS: 12800.83 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257612.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 883	GFLOPS: 12549.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.25, Tstamp:1715257612.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 884	GFLOPS: 13139.65 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715257612.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 885	GFLOPS: 13205.74 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715257613.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 886	GFLOPS: 13041.89 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257613.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 887	GFLOPS: 12103.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257613.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 888	GFLOPS: 13222.81 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.76, Tstamp:1715257613.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 889	GFLOPS: 13557.77 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.25, Tstamp:1715257614.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 890	GFLOPS: 11818.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257614.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 891	GFLOPS: 13188.13 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.85, Tstamp:1715257614.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 892	GFLOPS: 13051.62 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715257615.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 893	GFLOPS: 12153.57 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257615.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 894	GFLOPS: 9794.24 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.77, Tstamp:1715257615.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 895	GFLOPS: 4419.44 / 21531.87	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.99, Tstamp:1715257616.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 896	GFLOPS: 9197.42 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.54, Tstamp:1715257616.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

Time elapsed for measurement: 26.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.05 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1638	fail_ct: 410	Time elapsed: 2.57
GA Iter: 0	Max score: 0.7174	Min score: 0.4604	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7174	Min score: 0.5508	#Pop: 128	#M+: 1393	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 10.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 897	GFLOPS: 13787.90 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.20, Tstamp:1715257640.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 898	GFLOPS: 14420.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715257641.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 899	GFLOPS: 16601.23 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.29, Tstamp:1715257641.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 900	GFLOPS: 8503.88 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.91, Tstamp:1715257641.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,32)
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 901	GFLOPS: 10307.80 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.10, Tstamp:1715257642.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 902	GFLOPS: 10814.82 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.98, Tstamp:1715257642.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,24)
      compute = ...

==================================================
No: 903	GFLOPS: 13375.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.26, Tstamp:1715257642.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 904	GFLOPS: 13178.96 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.38, Tstamp:1715257642.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 905	GFLOPS: 13158.81 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.54, Tstamp:1715257643.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 906	GFLOPS: 11321.22 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.83, Tstamp:1715257643.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 907	GFLOPS: 12974.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.11, Tstamp:1715257643.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 908	GFLOPS: 13009.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.18, Tstamp:1715257644.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 909	GFLOPS: 12734.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.94, Tstamp:1715257644.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 910	GFLOPS: 13185.44 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.26, Tstamp:1715257644.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 911	GFLOPS: 12706.41 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.33, Tstamp:1715257645.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 912	GFLOPS: 13141.92 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.16, Tstamp:1715257645.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 913	GFLOPS: 12407.20 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.17, Tstamp:1715257645.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 914	GFLOPS: 13275.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.26, Tstamp:1715257646.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 915	GFLOPS: 12422.48 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.34, Tstamp:1715257646.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 916	GFLOPS: 13172.23 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715257646.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 917	GFLOPS: 10424.89 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715257646.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,24)
        compute = ...

==================================================
No: 918	GFLOPS: 13256.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.88, Tstamp:1715257647.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 919	GFLOPS: 11563.78 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.78, Tstamp:1715257647.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 920	GFLOPS: 13095.97 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.21, Tstamp:1715257647.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 921	GFLOPS: 12395.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715257648.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 922	GFLOPS: 13021.16 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.30, Tstamp:1715257648.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 923	GFLOPS: 12706.13 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257648.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 924	GFLOPS: 13399.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.82, Tstamp:1715257649.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 925	GFLOPS: 13183.14 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.06, Tstamp:1715257649.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 926	GFLOPS: 11941.61 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.33, Tstamp:1715257649.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 927	GFLOPS: 11856.84 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.72, Tstamp:1715257649.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 928	GFLOPS: 10883.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.64, Tstamp:1715257650.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 929	GFLOPS: 11786.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257650.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 930	GFLOPS: 12062.62 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257650.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 931	GFLOPS: 13682.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715257651.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 932	GFLOPS: 12121.88 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257651.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 933	GFLOPS: 12928.80 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257651.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 934	GFLOPS: 12973.44 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715257651.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 935	GFLOPS: 12942.89 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.12, Tstamp:1715257652.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 936	GFLOPS: 13002.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.05, Tstamp:1715257652.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 937	GFLOPS: 13038.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715257652.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 938	GFLOPS: 11950.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715257653.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 939	GFLOPS: 12614.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257653.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 940	GFLOPS: 12411.17 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715257653.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 941	GFLOPS: 11836.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.40, Tstamp:1715257654.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 942	GFLOPS: 12737.87 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715257654.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 943	GFLOPS: 12783.99 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257654.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 944	GFLOPS: 13246.57 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257655.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 945	GFLOPS: 12618.56 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.57, Tstamp:1715257655.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 946	GFLOPS: 12149.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.68, Tstamp:1715257655.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 947	GFLOPS: 12533.91 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.08, Tstamp:1715257656.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 948	GFLOPS: 12409.65 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.74, Tstamp:1715257656.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 949	GFLOPS: 13861.55 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715257656.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 950	GFLOPS: 12378.54 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715257657.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 951	GFLOPS: 12626.21 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.78, Tstamp:1715257657.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 952	GFLOPS: 12305.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257657.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 953	GFLOPS: 12825.62 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257658.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 954	GFLOPS: 12396.25 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257658.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 955	GFLOPS: 12794.30 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.74, Tstamp:1715257658.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 956	GFLOPS: 11903.12 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257658.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 957	GFLOPS: 12151.67 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715257659.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 958	GFLOPS: 1422.54 / 21531.87	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:4.50, Tstamp:1715257659.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 959	GFLOPS: 5378.52 / 21531.87	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.53, Tstamp:1715257659.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,48)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 960	GFLOPS: 1270.49 / 21531.87	results: MeasureResult(cost:[0.0029], error_no:0, all_cost:0.40, Tstamp:1715257660.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 29.80 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.20 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1684	fail_ct: 364	Time elapsed: 2.58
GA Iter: 0	Max score: 0.6071	Min score: 0.4725	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7346	Min score: 0.5425	#Pop: 128	#M+: 1387	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 40 programs to measure:
........................................****************************************
==================================================
No: 961	GFLOPS: 9096.06 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.41, Tstamp:1715257680.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 962	GFLOPS: 14650.42 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.80, Tstamp:1715257680.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 963	GFLOPS: 9983.03 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.40, Tstamp:1715257680.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 964	GFLOPS: 13311.09 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257681.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 965	GFLOPS: 13819.05 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.77, Tstamp:1715257681.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 966	GFLOPS: 17665.93 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.50, Tstamp:1715257681.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 967	GFLOPS: 13363.73 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715257681.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 968	GFLOPS: 14285.70 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.71, Tstamp:1715257682.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 969	GFLOPS: 10311.39 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.76, Tstamp:1715257682.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 970	GFLOPS: 13179.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.95, Tstamp:1715257682.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 971	GFLOPS: 14373.15 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.86, Tstamp:1715257683.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 972	GFLOPS: 13196.82 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.67, Tstamp:1715257683.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 973	GFLOPS: 13090.15 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.28, Tstamp:1715257683.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 974	GFLOPS: 13100.03 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.69, Tstamp:1715257683.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 975	GFLOPS: 13545.98 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715257684.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 976	GFLOPS: 13181.28 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715257684.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 977	GFLOPS: 13144.49 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715257685.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 978	GFLOPS: 13429.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257685.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 979	GFLOPS: 12075.79 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715257685.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 980	GFLOPS: 13210.91 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715257685.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 981	GFLOPS: 13181.14 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.93, Tstamp:1715257686.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 982	GFLOPS: 10367.72 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.46, Tstamp:1715257686.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 983	GFLOPS: 13238.02 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.22, Tstamp:1715257686.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 984	GFLOPS: 13036.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715257687.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 985	GFLOPS: 11914.46 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.70, Tstamp:1715257687.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 986	GFLOPS: 14700.38 / 21531.87	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.04, Tstamp:1715257687.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 987	GFLOPS: 12758.42 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.66, Tstamp:1715257688.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 988	GFLOPS: 13414.07 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715257688.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 989	GFLOPS: 13327.40 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.16, Tstamp:1715257688.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 990	GFLOPS: 12548.45 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257688.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 991	GFLOPS: 12767.31 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.62, Tstamp:1715257689.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 992	GFLOPS: 12455.96 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.46, Tstamp:1715257689.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 993	GFLOPS: 12058.26 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715257689.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 994	GFLOPS: 12904.60 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.03, Tstamp:1715257690.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 995	GFLOPS: 10651.12 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257690.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 996	GFLOPS: 10922.99 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.42, Tstamp:1715257690.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 997	GFLOPS: 10298.69 / 21531.87	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.24, Tstamp:1715257691.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 998	GFLOPS: 10508.85 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.58, Tstamp:1715257691.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,6)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 999	GFLOPS: 12589.01 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715257691.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 1000	GFLOPS: 12187.04 / 21531.87	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715257692.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

Time elapsed for measurement: 17.90 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
Lowered TIR:
@main = primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, compute_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_8: Pointer(float32), float32, [768, 3072], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [216, 16, 16], []),
             placeholder_2: Buffer(placeholder_10: Pointer(int32), int32, [216], []),
             placeholder_3: Buffer(placeholder_11: Pointer(int32), int32, [49], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, compute_1: compute} {
  for (m.outer.n.outer.fused: int32, 0, 1024) "parallel" {
    allocate(compute_3: Pointer(global float32), float32, [576]), storage_scope = global {
      for (i.outer.inner: int32, 0, 2) {
        for (nb_j.inner: int32, 0, 3) {
          let cse_var_1: int32 = ((i.outer.inner*288) + (nb_j.inner*16))
           {
            compute_4: Buffer(compute_3, float32, [576], [])[cse_var_1] = 0f32
            compute_4[(cse_var_1 + 1)] = 0f32
            compute_4[(cse_var_1 + 2)] = 0f32
            compute_4[(cse_var_1 + 3)] = 0f32
            compute_4[(cse_var_1 + 4)] = 0f32
            compute_4[(cse_var_1 + 5)] = 0f32
            compute_4[(cse_var_1 + 6)] = 0f32
            compute_4[(cse_var_1 + 7)] = 0f32
            compute_4[(cse_var_1 + 8)] = 0f32
            compute_4[(cse_var_1 + 9)] = 0f32
            compute_4[(cse_var_1 + 10)] = 0f32
            compute_4[(cse_var_1 + 11)] = 0f32
            compute_4[(cse_var_1 + 12)] = 0f32
            compute_4[(cse_var_1 + 13)] = 0f32
            compute_4[(cse_var_1 + 14)] = 0f32
            compute_4[(cse_var_1 + 15)] = 0f32
            compute_4[(cse_var_1 + 48)] = 0f32
            compute_4[(cse_var_1 + 49)] = 0f32
            compute_4[(cse_var_1 + 50)] = 0f32
            compute_4[(cse_var_1 + 51)] = 0f32
            compute_4[(cse_var_1 + 52)] = 0f32
            compute_4[(cse_var_1 + 53)] = 0f32
            compute_4[(cse_var_1 + 54)] = 0f32
            compute_4[(cse_var_1 + 55)] = 0f32
            compute_4[(cse_var_1 + 56)] = 0f32
            compute_4[(cse_var_1 + 57)] = 0f32
            compute_4[(cse_var_1 + 58)] = 0f32
            compute_4[(cse_var_1 + 59)] = 0f32
            compute_4[(cse_var_1 + 60)] = 0f32
            compute_4[(cse_var_1 + 61)] = 0f32
            compute_4[(cse_var_1 + 62)] = 0f32
            compute_4[(cse_var_1 + 63)] = 0f32
            compute_4[(cse_var_1 + 96)] = 0f32
            compute_4[(cse_var_1 + 97)] = 0f32
            compute_4[(cse_var_1 + 98)] = 0f32
            compute_4[(cse_var_1 + 99)] = 0f32
            compute_4[(cse_var_1 + 100)] = 0f32
            compute_4[(cse_var_1 + 101)] = 0f32
            compute_4[(cse_var_1 + 102)] = 0f32
            compute_4[(cse_var_1 + 103)] = 0f32
            compute_4[(cse_var_1 + 104)] = 0f32
            compute_4[(cse_var_1 + 105)] = 0f32
            compute_4[(cse_var_1 + 106)] = 0f32
            compute_4[(cse_var_1 + 107)] = 0f32
            compute_4[(cse_var_1 + 108)] = 0f32
            compute_4[(cse_var_1 + 109)] = 0f32
            compute_4[(cse_var_1 + 110)] = 0f32
            compute_4[(cse_var_1 + 111)] = 0f32
            compute_4[(cse_var_1 + 144)] = 0f32
            compute_4[(cse_var_1 + 145)] = 0f32
            compute_4[(cse_var_1 + 146)] = 0f32
            compute_4[(cse_var_1 + 147)] = 0f32
            compute_4[(cse_var_1 + 148)] = 0f32
            compute_4[(cse_var_1 + 149)] = 0f32
            compute_4[(cse_var_1 + 150)] = 0f32
            compute_4[(cse_var_1 + 151)] = 0f32
            compute_4[(cse_var_1 + 152)] = 0f32
            compute_4[(cse_var_1 + 153)] = 0f32
            compute_4[(cse_var_1 + 154)] = 0f32
            compute_4[(cse_var_1 + 155)] = 0f32
            compute_4[(cse_var_1 + 156)] = 0f32
            compute_4[(cse_var_1 + 157)] = 0f32
            compute_4[(cse_var_1 + 158)] = 0f32
            compute_4[(cse_var_1 + 159)] = 0f32
            compute_4[(cse_var_1 + 192)] = 0f32
            compute_4[(cse_var_1 + 193)] = 0f32
            compute_4[(cse_var_1 + 194)] = 0f32
            compute_4[(cse_var_1 + 195)] = 0f32
            compute_4[(cse_var_1 + 196)] = 0f32
            compute_4[(cse_var_1 + 197)] = 0f32
            compute_4[(cse_var_1 + 198)] = 0f32
            compute_4[(cse_var_1 + 199)] = 0f32
            compute_4[(cse_var_1 + 200)] = 0f32
            compute_4[(cse_var_1 + 201)] = 0f32
            compute_4[(cse_var_1 + 202)] = 0f32
            compute_4[(cse_var_1 + 203)] = 0f32
            compute_4[(cse_var_1 + 204)] = 0f32
            compute_4[(cse_var_1 + 205)] = 0f32
            compute_4[(cse_var_1 + 206)] = 0f32
            compute_4[(cse_var_1 + 207)] = 0f32
            compute_4[(cse_var_1 + 240)] = 0f32
            compute_4[(cse_var_1 + 241)] = 0f32
            compute_4[(cse_var_1 + 242)] = 0f32
            compute_4[(cse_var_1 + 243)] = 0f32
            compute_4[(cse_var_1 + 244)] = 0f32
            compute_4[(cse_var_1 + 245)] = 0f32
            compute_4[(cse_var_1 + 246)] = 0f32
            compute_4[(cse_var_1 + 247)] = 0f32
            compute_4[(cse_var_1 + 248)] = 0f32
            compute_4[(cse_var_1 + 249)] = 0f32
            compute_4[(cse_var_1 + 250)] = 0f32
            compute_4[(cse_var_1 + 251)] = 0f32
            compute_4[(cse_var_1 + 252)] = 0f32
            compute_4[(cse_var_1 + 253)] = 0f32
            compute_4[(cse_var_1 + 254)] = 0f32
            compute_4[(cse_var_1 + 255)] = 0f32
            for (elem_idx: int32, 0, let cse_var_2: int32 = ((floormod(m.outer.n.outer.fused, 16)*3) + nb_j.inner) in (placeholder_12: Buffer(placeholder_11, int32, [49], [])[(cse_var_2 + 1)] - placeholder_12[cse_var_2])) {
              for (i.inner: int32, 0, 6) {
                let cse_var_21: int32 = (elem_idx*256)
                let cse_var_20: int32 = ((floormod(m.outer.n.outer.fused, 16)*3) + nb_j.inner)
                let cse_var_19: int32 = (((i.outer.inner*288) + (i.inner*48)) + (nb_j.inner*16))
                let cse_var_18: int32 = (((floordiv(m.outer.n.outer.fused, 16)*36864) + (i.outer.inner*18432)) + (i.inner*3072))
                let cse_var_17: int32 = (cse_var_19 + 9)
                let cse_var_16: int32 = (cse_var_19 + 8)
                let cse_var_15: int32 = (cse_var_19 + 7)
                let cse_var_14: int32 = (cse_var_19 + 6)
                let cse_var_13: int32 = (cse_var_19 + 5)
                let cse_var_12: int32 = (cse_var_19 + 4)
                let cse_var_11: int32 = (cse_var_19 + 3)
                let cse_var_10: int32 = (cse_var_19 + 2)
                let cse_var_9: int32 = (cse_var_19 + 15)
                let cse_var_8: int32 = (cse_var_19 + 14)
                let cse_var_7: int32 = (cse_var_19 + 13)
                let cse_var_6: int32 = (cse_var_19 + 12)
                let cse_var_5: int32 = (cse_var_19 + 11)
                let cse_var_4: int32 = (cse_var_19 + 10)
                let cse_var_3: int32 = (cse_var_19 + 1)
                 {
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13: Buffer(placeholder_9, float32, [55296], [])[((placeholder_12[cse_var_20]*256) + cse_var_21)]*placeholder_14: Buffer(placeholder_8, float32, [2359296], [])[(cse_var_18 + (placeholder_15: Buffer(placeholder_10, int32, [216], [])[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 1)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 2)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 3)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 4)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 5)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 6)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 7)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 8)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 9)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 10)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 11)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 12)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 13)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 14)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 15)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 16)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 17)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 18)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 19)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 20)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 21)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 22)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 23)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 24)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 25)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 26)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 27)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 28)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 29)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 30)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 31)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 32)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 33)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 34)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 35)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 36)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 37)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 38)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 39)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 40)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 41)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 42)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 43)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 44)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 45)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 46)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 47)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 48)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 49)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 50)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 51)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 52)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 53)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 54)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 55)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 56)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 57)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 58)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 59)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 60)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 61)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 62)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 63)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 64)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 65)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 66)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 67)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 68)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 69)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 70)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 71)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 72)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 73)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 74)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 75)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 76)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 77)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 78)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 79)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 80)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 81)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 82)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 83)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 84)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 85)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 86)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 87)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 88)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 89)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 90)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 91)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 92)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 93)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 94)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 95)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 96)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 97)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 98)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 99)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 100)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 101)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 102)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 103)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 104)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 105)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 106)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 107)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 108)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 109)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 110)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 111)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 112)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 113)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 114)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 115)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 116)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 117)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 118)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 119)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 120)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 121)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 122)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 123)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 124)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 125)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 126)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 127)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 128)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 129)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 130)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 131)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 132)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 133)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 134)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 135)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 136)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 137)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 138)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 139)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 140)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 141)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 142)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 143)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 144)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 145)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 146)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 147)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 148)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 149)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 150)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 151)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 152)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 153)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 154)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 155)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 156)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 157)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 158)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 159)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 160)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 161)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 162)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 163)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 164)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 165)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 166)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 167)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 168)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 169)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 170)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 171)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 172)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 173)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 174)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 175)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 176)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 177)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 178)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 179)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 180)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 181)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 182)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 183)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 184)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 185)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 186)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 187)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 188)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 189)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 190)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 191)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 192)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 193)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 194)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 195)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 196)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 197)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 198)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 199)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 200)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 201)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 202)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 203)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 204)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 205)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 206)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 207)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 208)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 209)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 210)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 211)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 212)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 213)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 214)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 215)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 216)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 217)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 218)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 219)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 220)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 221)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 222)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 223)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 224)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 225)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 226)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 227)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 228)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 229)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 230)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 231)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 232)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 233)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 234)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 235)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 236)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 237)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 238)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 239)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 240)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 241)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 242)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 243)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 244)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 245)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 246)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 247)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 248)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 249)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 250)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 251)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 252)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 253)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 254)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 255)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                }
              }
            }
          }
        }
      }
      for (m.inner: int32, 0, 12) {
        compute_5: Buffer(compute_2, float32, [589824], [])[ramp((((floordiv(m.outer.n.outer.fused, 16)*9216) + (m.inner*768)) + (floormod(m.outer.n.outer.fused, 16)*48)), 1, 48)] = compute_4[ramp((m.inner*48), 1, 48)]
      }
    }
  }
}

----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
Custom sketch rule "SparseDense" added.
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 1681	fail_ct: 367	Time elapsed: 2.46
GA Iter: 0	Max score: 0.9982	Min score: 0.9239	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9863	#Pop: 128	#M+: 1383	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
(768, 768)
(768, 768)
encoder.layer.11.output.dense.weight Execution time of this operator: 0.170 ms
encoder.layer.8.output.dense.weight: num_row = 768, num_col = 3072, nnz = 25553

==================================================
No: 1	GFLOPS: 20996.64 / 20996.64	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.07, Tstamp:1715257716.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 2	GFLOPS: 9226.36 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.31, Tstamp:1715257716.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,48)
      compute = ...

==================================================
No: 3	GFLOPS: 11767.44 / 20996.64	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.14, Tstamp:1715257716.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 4	GFLOPS: 1658.37 / 20996.64	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:1.88, Tstamp:1715257717.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 5	GFLOPS: 2631.57 / 20996.64	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:2.00, Tstamp:1715257717.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 6	GFLOPS: 1602.16 / 20996.64	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:1.90, Tstamp:1715257717.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    for n.1 (0,3)
      compute = ...

==================================================
No: 7	GFLOPS: 9432.35 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715257717.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 8	GFLOPS: 1824.80 / 20996.64	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:1.08, Tstamp:1715257718.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 9	GFLOPS: 7486.03 / 20996.64	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.93, Tstamp:1715257718.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 10	GFLOPS: 17362.45 / 20996.64	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.34, Tstamp:1715257718.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,24)
      for c (0,16)
        compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 11	GFLOPS: 8723.87 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.94, Tstamp:1715257719.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 12	GFLOPS: 12680.82 / 20996.64	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.83, Tstamp:1715257719.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 13	GFLOPS: 3100.51 / 20996.64	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.05, Tstamp:1715257719.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 14	GFLOPS: 11057.64 / 20996.64	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.36, Tstamp:1715257720.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 64
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,16)
      compute = ...

==================================================
No: 15	GFLOPS: 3486.96 / 20996.64	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.03, Tstamp:1715257720.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 16	GFLOPS: 8446.43 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.11, Tstamp:1715257720.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 17	GFLOPS: 3464.88 / 20996.64	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.99, Tstamp:1715257721.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 18	GFLOPS: 1387.42 / 20996.64	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:1.20, Tstamp:1715257721.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,384)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 19	GFLOPS: 4727.69 / 20996.64	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:3.55, Tstamp:1715257721.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 20	GFLOPS: 14825.62 / 20996.64	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715257722.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for c (0,16)
      compute = ...
  compute = ...

==================================================
No: 21	GFLOPS: 5722.00 / 20996.64	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:3.23, Tstamp:1715257722.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 22	GFLOPS: 1409.51 / 20996.64	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:0.88, Tstamp:1715257722.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,192)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    for n.1 (0,3)
      compute = ...

==================================================
No: 23	GFLOPS: 4047.95 / 20996.64	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.20, Tstamp:1715257722.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 24	GFLOPS: 2764.39 / 20996.64	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.84, Tstamp:1715257723.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 25	GFLOPS: 18548.91 / 20996.64	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715257723.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 26	GFLOPS: 8123.22 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.55, Tstamp:1715257723.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,48)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 27	GFLOPS: 8581.25 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.58, Tstamp:1715257724.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 28	GFLOPS: 3021.25 / 20996.64	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.75, Tstamp:1715257724.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 64
  for i.1 (0,384)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 29	GFLOPS: 1364.10 / 20996.64	results: MeasureResult(cost:[0.0027], error_no:0, all_cost:2.62, Tstamp:1715257724.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 30	GFLOPS: 7982.63 / 20996.64	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.80, Tstamp:1715257724.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 31	GFLOPS: 1365.91 / 20996.64	results: MeasureResult(cost:[0.0027], error_no:0, all_cost:0.59, Tstamp:1715257725.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 32	GFLOPS: 3573.90 / 20996.64	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.10, Tstamp:1715257725.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 33	GFLOPS: 8204.33 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.76, Tstamp:1715257725.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 34	GFLOPS: 3010.46 / 20996.64	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.47, Tstamp:1715257725.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 35	GFLOPS: 6445.68 / 20996.64	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.67, Tstamp:1715257726.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 36	GFLOPS: 13049.20 / 20996.64	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.49, Tstamp:1715257726.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 37	GFLOPS: 3705.36 / 20996.64	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.58, Tstamp:1715257726.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 38	GFLOPS: 15372.62 / 20996.64	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715257727.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 39	GFLOPS: 4317.92 / 20996.64	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.48, Tstamp:1715257727.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 40	GFLOPS: 2371.78 / 20996.64	results: MeasureResult(cost:[0.0015], error_no:0, all_cost:3.08, Tstamp:1715257727.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 41	GFLOPS: 6320.29 / 20996.64	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.66, Tstamp:1715257727.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,6)
      compute = ...

==================================================
No: 42	GFLOPS: 5194.84 / 20996.64	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.41, Tstamp:1715257728.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 43	GFLOPS: 10284.84 / 20996.64	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.22, Tstamp:1715257728.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 44	GFLOPS: 25029.81 / 25029.81	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715257728.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 45	GFLOPS: 8480.62 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.10, Tstamp:1715257729.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 46	GFLOPS: 1846.16 / 25029.81	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:2.45, Tstamp:1715257729.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    for n.1 (0,3)
      compute = ...

==================================================
No: 47	GFLOPS: 3935.07 / 25029.81	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.86, Tstamp:1715257729.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 48	GFLOPS: 3676.98 / 25029.81	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.59, Tstamp:1715257730.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 49	GFLOPS: 17888.33 / 25029.81	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715257730.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 50	GFLOPS: 8697.71 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.39, Tstamp:1715257730.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,24)
      compute = ...

==================================================
No: 51	GFLOPS: 8442.27 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.41, Tstamp:1715257730.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 52	GFLOPS: 5826.88 / 25029.81	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.30, Tstamp:1715257731.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 53	GFLOPS: 3331.07 / 25029.81	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.51, Tstamp:1715257731.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 54	GFLOPS: 3619.73 / 25029.81	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.42, Tstamp:1715257731.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 55	GFLOPS: 2026.92 / 25029.81	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:1.17, Tstamp:1715257732.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 56	GFLOPS: 4084.75 / 25029.81	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.99, Tstamp:1715257732.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 57	GFLOPS: 15000.78 / 25029.81	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715257732.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 58	GFLOPS: 8219.39 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.34, Tstamp:1715257732.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 59	GFLOPS: 10910.87 / 25029.81	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715257733.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,24)
      compute = ...

==================================================
No: 60	GFLOPS: 8646.59 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.44, Tstamp:1715257733.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 61	GFLOPS: 2558.89 / 25029.81	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:1.65, Tstamp:1715257733.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 62	GFLOPS: 3203.66 / 25029.81	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.83, Tstamp:1715257733.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 63	GFLOPS: 1534.06 / 25029.81	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.46, Tstamp:1715257734.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 64	GFLOPS: 14134.47 / 25029.81	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715257734.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 27.39 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.76 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1667	fail_ct: 381	Time elapsed: 2.48
GA Iter: 0	Max score: 0.9999	Min score: 0.9201	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9866	#Pop: 128	#M+: 1386	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.26
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 65	GFLOPS: 1761.13 / 25029.81	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:0.74, Tstamp:1715257757.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 66	GFLOPS: 11613.67 / 25029.81	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.81, Tstamp:1715257757.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 67	GFLOPS: 2212.99 / 25029.81	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:0.67, Tstamp:1715257758.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 68	GFLOPS: 13682.08 / 25029.81	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.95, Tstamp:1715257758.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 69	GFLOPS: 3421.16 / 25029.81	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.70, Tstamp:1715257758.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,4)
      compute = ...

==================================================
No: 70	GFLOPS: 3313.06 / 25029.81	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.81, Tstamp:1715257758.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 71	GFLOPS: 1896.97 / 25029.81	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:1.09, Tstamp:1715257759.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 72	GFLOPS: 15968.85 / 25029.81	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715257759.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 73	GFLOPS: 19099.69 / 25029.81	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715257759.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 74	GFLOPS: 8158.69 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.97, Tstamp:1715257760.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 75	GFLOPS: 861.94 / 25029.81	results: MeasureResult(cost:[0.0042], error_no:0, all_cost:1.64, Tstamp:1715257760.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 76	GFLOPS: 1712.03 / 25029.81	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:1.48, Tstamp:1715257760.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 77	GFLOPS: 14250.43 / 25029.81	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715257761.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 64
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 78	GFLOPS: 4248.48 / 25029.81	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.51, Tstamp:1715257761.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 79	GFLOPS: 3960.88 / 25029.81	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.83, Tstamp:1715257761.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,128)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 80	GFLOPS: 6588.84 / 25029.81	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.96, Tstamp:1715257762.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 81	GFLOPS: 14887.54 / 25029.81	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.23, Tstamp:1715257762.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 82	GFLOPS: 10050.19 / 25029.81	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.63, Tstamp:1715257762.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 83	GFLOPS: 15613.78 / 25029.81	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715257762.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 84	GFLOPS: 30516.78 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715257763.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 85	GFLOPS: 5114.08 / 30516.78	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.65, Tstamp:1715257763.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 86	GFLOPS: 2632.35 / 30516.78	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.86, Tstamp:1715257764.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,2)
      compute = ...

==================================================
No: 87	GFLOPS: 2728.27 / 30516.78	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.61, Tstamp:1715257764.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 88	GFLOPS: 3446.64 / 30516.78	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.01, Tstamp:1715257764.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 89	GFLOPS: 10061.98 / 30516.78	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.69, Tstamp:1715257765.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 90	GFLOPS: 3568.23 / 30516.78	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.75, Tstamp:1715257765.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 91	GFLOPS: 2768.46 / 30516.78	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.74, Tstamp:1715257765.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 92	GFLOPS: 5102.75 / 30516.78	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.53, Tstamp:1715257765.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 93	GFLOPS: 28144.93 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715257766.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 94	GFLOPS: 3880.60 / 30516.78	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.80, Tstamp:1715257766.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 95	GFLOPS: 6005.74 / 30516.78	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.46, Tstamp:1715257766.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 96	GFLOPS: 2085.12 / 30516.78	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.48, Tstamp:1715257766.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 97	GFLOPS: 13853.23 / 30516.78	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715257767.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 98	GFLOPS: 11996.86 / 30516.78	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.84, Tstamp:1715257767.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 99	GFLOPS: 6092.13 / 30516.78	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.43, Tstamp:1715257767.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 100	GFLOPS: 1377.81 / 30516.78	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:0.61, Tstamp:1715257767.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 101	GFLOPS: 15404.55 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.15, Tstamp:1715257768.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,144)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 102	GFLOPS: 28504.71 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715257768.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 103	GFLOPS: 5057.62 / 30516.78	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.68, Tstamp:1715257768.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 104	GFLOPS: 5629.84 / 30516.78	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.07, Tstamp:1715257769.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,4)
      compute = ...

==================================================
No: 105	GFLOPS: 2053.06 / 30516.78	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.49, Tstamp:1715257769.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 106	GFLOPS: 3842.90 / 30516.78	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.45, Tstamp:1715257769.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 107	GFLOPS: 11871.70 / 30516.78	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257770.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for i.1 (0,96)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 108	GFLOPS: 2069.89 / 30516.78	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.44, Tstamp:1715257770.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 109	GFLOPS: 6614.67 / 30516.78	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.50, Tstamp:1715257770.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 110	GFLOPS: 1554.51 / 30516.78	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:1.04, Tstamp:1715257770.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 111	GFLOPS: 1551.85 / 30516.78	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:0.38, Tstamp:1715257771.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 112	GFLOPS: 2651.59 / 30516.78	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.50, Tstamp:1715257771.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,768)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 113	GFLOPS: 9298.52 / 30516.78	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.43, Tstamp:1715257771.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 114	GFLOPS: 23177.76 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715257771.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 115	GFLOPS: 9757.27 / 30516.78	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.51, Tstamp:1715257772.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 116	GFLOPS: 28619.48 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.38, Tstamp:1715257772.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 117	GFLOPS: 15016.89 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.37, Tstamp:1715257772.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 118	GFLOPS: 4221.26 / 30516.78	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.11, Tstamp:1715257773.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,192)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,4)
        compute = ...

==================================================
No: 119	GFLOPS: 1648.68 / 30516.78	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:0.96, Tstamp:1715257773.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 120	GFLOPS: 29545.89 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.01, Tstamp:1715257773.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 121	GFLOPS: 11239.72 / 30516.78	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.44, Tstamp:1715257774.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,24)
      compute = ...

==================================================
No: 122	GFLOPS: 14707.78 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715257774.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 123	GFLOPS: 3213.89 / 30516.78	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:3.87, Tstamp:1715257774.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 124	GFLOPS: 4112.87 / 30516.78	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.69, Tstamp:1715257774.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 125	GFLOPS: 7574.94 / 30516.78	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.01, Tstamp:1715257775.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 126	GFLOPS: 6434.03 / 30516.78	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:3.48, Tstamp:1715257775.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 127	GFLOPS: 1373.58 / 30516.78	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:0.54, Tstamp:1715257775.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 128	GFLOPS: 4403.61 / 30516.78	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.32, Tstamp:1715257776.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 27.92 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.73 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1679	fail_ct: 369	Time elapsed: 2.55
GA Iter: 0	Max score: 0.9708	Min score: 0.5603	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9708	Min score: 0.8617	#Pop: 128	#M+: 1376	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 10.00
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 129	GFLOPS: 15254.13 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.15, Tstamp:1715257796.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 130	GFLOPS: 28644.89 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.42, Tstamp:1715257797.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 131	GFLOPS: 20554.38 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715257797.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 132	GFLOPS: 20262.54 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.08, Tstamp:1715257797.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 133	GFLOPS: 22192.18 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715257798.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 134	GFLOPS: 24370.26 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715257798.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 135	GFLOPS: 20593.99 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.94, Tstamp:1715257798.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 136	GFLOPS: 19091.24 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.00, Tstamp:1715257799.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 137	GFLOPS: 19193.10 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.34, Tstamp:1715257799.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 138	GFLOPS: 23947.81 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.19, Tstamp:1715257799.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 139	GFLOPS: 18297.35 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.95, Tstamp:1715257800.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 140	GFLOPS: 22266.12 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.92, Tstamp:1715257800.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 141	GFLOPS: 18630.92 / 30516.78	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.03, Tstamp:1715257800.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 142	GFLOPS: 28102.48 / 30516.78	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715257801.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 143	GFLOPS: 30783.05 / 30783.05	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.10, Tstamp:1715257801.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 144	GFLOPS: 20689.08 / 30783.05	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715257801.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 145	GFLOPS: 31681.06 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.06, Tstamp:1715257802.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 146	GFLOPS: 23269.36 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.57, Tstamp:1715257802.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 147	GFLOPS: 20715.28 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715257802.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 148	GFLOPS: 20168.28 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715257803.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 149	GFLOPS: 23354.33 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.66, Tstamp:1715257803.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 150	GFLOPS: 28394.98 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715257803.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 151	GFLOPS: 27849.15 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715257804.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 152	GFLOPS: 20485.86 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715257804.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 153	GFLOPS: 27138.93 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.25, Tstamp:1715257804.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 154	GFLOPS: 18950.13 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715257804.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 155	GFLOPS: 16984.28 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715257805.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 156	GFLOPS: 20481.13 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715257805.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 157	GFLOPS: 23357.71 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715257805.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 158	GFLOPS: 14411.82 / 31681.06	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.20, Tstamp:1715257806.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 159	GFLOPS: 18582.99 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715257806.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 160	GFLOPS: 27477.46 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715257806.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 161	GFLOPS: 24015.54 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715257807.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 162	GFLOPS: 20569.61 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.65, Tstamp:1715257807.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 163	GFLOPS: 26424.35 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715257807.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 164	GFLOPS: 21509.87 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715257808.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 165	GFLOPS: 20324.90 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715257808.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 166	GFLOPS: 22943.66 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715257808.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 167	GFLOPS: 20160.57 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715257809.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 168	GFLOPS: 28379.21 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715257809.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 169	GFLOPS: 25470.98 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715257809.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 170	GFLOPS: 21714.08 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715257810.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 171	GFLOPS: 21035.69 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715257810.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 172	GFLOPS: 22298.78 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.35, Tstamp:1715257810.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 173	GFLOPS: 22052.64 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715257811.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 174	GFLOPS: 12873.57 / 31681.06	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.08, Tstamp:1715257811.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 175	GFLOPS: 20426.69 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715257811.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 176	GFLOPS: 28204.41 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715257812.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 177	GFLOPS: 28683.77 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715257812.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 178	GFLOPS: 26125.41 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715257812.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 179	GFLOPS: 28465.51 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715257812.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 180	GFLOPS: 26153.38 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715257813.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 181	GFLOPS: 20945.99 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715257813.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 182	GFLOPS: 19039.45 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715257814.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 183	GFLOPS: 20975.14 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715257814.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 184	GFLOPS: 19108.89 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715257814.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 185	GFLOPS: 20883.24 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715257814.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 186	GFLOPS: 25914.64 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715257815.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 187	GFLOPS: 26085.81 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715257815.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 188	GFLOPS: 25745.56 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715257815.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 189	GFLOPS: 25730.24 / 31681.06	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715257816.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 190	GFLOPS: 10639.01 / 31681.06	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715257816.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 191	GFLOPS: 10181.47 / 31681.06	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.94, Tstamp:1715257817.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  vectorize n.1 (0,12)
    compute = ...

==================================================
No: 192	GFLOPS: 19258.60 / 31681.06	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.53, Tstamp:1715257817.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 27.79 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.75 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1666	fail_ct: 382	Time elapsed: 2.55
GA Iter: 0	Max score: 0.9633	Min score: 0.5051	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9691	Min score: 0.7752	#Pop: 128	#M+: 1381	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 10.10
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 193	GFLOPS: 38639.14 / 38639.14	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.85, Tstamp:1715257838.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 194	GFLOPS: 28938.11 / 38639.14	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.09, Tstamp:1715257838.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 195	GFLOPS: 33729.40 / 38639.14	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.85, Tstamp:1715257839.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 196	GFLOPS: 35537.55 / 38639.14	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.07, Tstamp:1715257839.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 197	GFLOPS: 39364.69 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.92, Tstamp:1715257839.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 198	GFLOPS: 37316.76 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.08, Tstamp:1715257840.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 199	GFLOPS: 37262.38 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.28, Tstamp:1715257840.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 200	GFLOPS: 34808.23 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.00, Tstamp:1715257840.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 201	GFLOPS: 29018.27 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.60, Tstamp:1715257841.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 202	GFLOPS: 37044.02 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.45, Tstamp:1715257841.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 203	GFLOPS: 29564.34 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.98, Tstamp:1715257841.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 204	GFLOPS: 33981.63 / 39364.69	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.80, Tstamp:1715257842.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 205	GFLOPS: 40827.98 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.80, Tstamp:1715257842.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 206	GFLOPS: 28102.06 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715257842.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 207	GFLOPS: 35215.37 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.62, Tstamp:1715257843.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 208	GFLOPS: 29861.07 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715257843.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 209	GFLOPS: 37434.76 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.97, Tstamp:1715257843.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 210	GFLOPS: 27939.92 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715257844.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 211	GFLOPS: 28025.35 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715257844.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 212	GFLOPS: 28687.45 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.17, Tstamp:1715257844.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 213	GFLOPS: 28415.02 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715257845.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 214	GFLOPS: 26122.75 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715257845.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 215	GFLOPS: 28072.55 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715257845.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 216	GFLOPS: 26359.43 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715257846.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 217	GFLOPS: 27967.18 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715257846.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 218	GFLOPS: 28465.14 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715257846.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 219	GFLOPS: 39333.60 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.58, Tstamp:1715257847.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 220	GFLOPS: 27394.97 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715257847.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 221	GFLOPS: 27761.88 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715257847.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 222	GFLOPS: 28800.69 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715257848.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 223	GFLOPS: 28495.38 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715257848.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 224	GFLOPS: 27859.30 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257849.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 225	GFLOPS: 34000.48 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.52, Tstamp:1715257849.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 226	GFLOPS: 27649.95 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715257849.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 227	GFLOPS: 25459.11 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715257850.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 228	GFLOPS: 28140.34 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715257850.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 229	GFLOPS: 28916.15 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715257850.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 230	GFLOPS: 27198.83 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.36, Tstamp:1715257851.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 231	GFLOPS: 28387.14 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715257851.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 232	GFLOPS: 28889.84 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715257851.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 233	GFLOPS: 28552.35 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715257852.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 234	GFLOPS: 26098.09 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257852.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 235	GFLOPS: 28684.33 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715257852.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 236	GFLOPS: 26268.53 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715257853.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 237	GFLOPS: 25567.56 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715257853.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 238	GFLOPS: 28403.39 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715257854.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 239	GFLOPS: 26592.12 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715257854.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 240	GFLOPS: 25574.22 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.39, Tstamp:1715257854.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 241	GFLOPS: 16316.32 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715257855.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 242	GFLOPS: 26714.65 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715257855.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 243	GFLOPS: 25897.88 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715257855.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 244	GFLOPS: 26039.70 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715257856.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 245	GFLOPS: 25636.06 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715257856.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 246	GFLOPS: 25447.01 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.39, Tstamp:1715257856.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 247	GFLOPS: 29895.92 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715257856.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 248	GFLOPS: 26225.42 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715257857.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 249	GFLOPS: 20270.46 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.36, Tstamp:1715257857.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 250	GFLOPS: 26506.06 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715257857.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 251	GFLOPS: 26586.59 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715257858.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 252	GFLOPS: 26650.88 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.39, Tstamp:1715257858.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 253	GFLOPS: 25748.82 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715257858.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 254	GFLOPS: 8735.04 / 40827.98	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.43, Tstamp:1715257859.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 255	GFLOPS: 3832.10 / 40827.98	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.48, Tstamp:1715257859.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 256	GFLOPS: 9142.65 / 40827.98	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715257859.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 29.01 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.86 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1667	fail_ct: 381	Time elapsed: 2.54
GA Iter: 0	Max score: 0.8532	Min score: 0.3844	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9317	Min score: 0.6188	#Pop: 128	#M+: 1383	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 9.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 257	GFLOPS: 19093.26 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.50, Tstamp:1715257880.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 258	GFLOPS: 32268.13 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.84, Tstamp:1715257881.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 259	GFLOPS: 25569.29 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.44, Tstamp:1715257881.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 260	GFLOPS: 29274.70 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.17, Tstamp:1715257881.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 261	GFLOPS: 20586.04 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.60, Tstamp:1715257881.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 262	GFLOPS: 17214.05 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.39, Tstamp:1715257882.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 263	GFLOPS: 14484.08 / 40827.98	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.56, Tstamp:1715257882.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 264	GFLOPS: 34125.43 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.16, Tstamp:1715257882.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 265	GFLOPS: 34650.10 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.62, Tstamp:1715257883.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 266	GFLOPS: 20709.93 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.71, Tstamp:1715257883.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 267	GFLOPS: 16982.33 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.42, Tstamp:1715257884.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 268	GFLOPS: 34073.60 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.04, Tstamp:1715257884.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 269	GFLOPS: 26160.13 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.30, Tstamp:1715257884.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 270	GFLOPS: 29081.68 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715257885.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 271	GFLOPS: 15656.35 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.38, Tstamp:1715257885.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 272	GFLOPS: 28920.76 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.89, Tstamp:1715257886.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 273	GFLOPS: 28695.64 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.80, Tstamp:1715257886.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 274	GFLOPS: 27145.96 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715257886.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 275	GFLOPS: 28142.05 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715257887.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 276	GFLOPS: 24704.68 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.91, Tstamp:1715257887.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 277	GFLOPS: 25531.24 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.95, Tstamp:1715257887.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 278	GFLOPS: 24459.52 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.79, Tstamp:1715257888.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 279	GFLOPS: 25808.30 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715257888.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 280	GFLOPS: 28923.85 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715257888.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 281	GFLOPS: 26824.70 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.37, Tstamp:1715257888.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 282	GFLOPS: 34319.66 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.67, Tstamp:1715257889.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 283	GFLOPS: 22953.53 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.25, Tstamp:1715257889.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 284	GFLOPS: 25916.47 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.00, Tstamp:1715257890.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 285	GFLOPS: 28991.63 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257890.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 286	GFLOPS: 28164.54 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715257890.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 287	GFLOPS: 28597.81 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715257891.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 288	GFLOPS: 26442.01 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715257891.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 289	GFLOPS: 28502.34 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715257891.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 290	GFLOPS: 26265.22 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715257892.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 291	GFLOPS: 25121.18 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715257892.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 292	GFLOPS: 26194.74 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715257892.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 293	GFLOPS: 26382.60 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715257893.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 294	GFLOPS: 26266.57 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715257893.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 295	GFLOPS: 24991.68 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715257893.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 296	GFLOPS: 31381.60 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.50, Tstamp:1715257894.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 297	GFLOPS: 26422.79 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715257894.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 298	GFLOPS: 26372.60 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715257894.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 299	GFLOPS: 25154.50 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715257895.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 300	GFLOPS: 28557.01 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.46, Tstamp:1715257895.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 301	GFLOPS: 26426.58 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715257895.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 302	GFLOPS: 25062.22 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715257896.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 303	GFLOPS: 26255.97 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715257896.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 304	GFLOPS: 27386.23 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715257897.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 305	GFLOPS: 28269.89 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715257897.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 306	GFLOPS: 25922.30 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715257897.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 307	GFLOPS: 25426.59 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715257898.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 308	GFLOPS: 29440.59 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715257898.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 309	GFLOPS: 23126.36 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715257898.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 310	GFLOPS: 25725.30 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715257899.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 311	GFLOPS: 26166.14 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715257899.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 312	GFLOPS: 35700.97 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.52, Tstamp:1715257900.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 313	GFLOPS: 27564.27 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.35, Tstamp:1715257900.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 314	GFLOPS: 26993.85 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.36, Tstamp:1715257900.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 315	GFLOPS: 21786.06 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715257900.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 316	GFLOPS: 25793.14 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715257901.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 317	GFLOPS: 23646.61 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715257901.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 318	GFLOPS: 1924.93 / 40827.98	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.90, Tstamp:1715257901.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 319	GFLOPS: 3407.68 / 40827.98	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.42, Tstamp:1715257901.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 320	GFLOPS: 5453.72 / 40827.98	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.32, Tstamp:1715257902.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 28.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.78 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1652	fail_ct: 396	Time elapsed: 2.52
GA Iter: 0	Max score: 0.7532	Min score: 0.3995	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8200	Min score: 0.5927	#Pop: 128	#M+: 1393	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 9.98
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 321	GFLOPS: 15810.41 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.31, Tstamp:1715257924.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 322	GFLOPS: 9138.40 / 40827.98	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.57, Tstamp:1715257924.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 323	GFLOPS: 33497.03 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.63, Tstamp:1715257924.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 324	GFLOPS: 28962.96 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.40, Tstamp:1715257925.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 325	GFLOPS: 16004.51 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.16, Tstamp:1715257925.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 326	GFLOPS: 32226.10 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.16, Tstamp:1715257925.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 327	GFLOPS: 32204.35 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.01, Tstamp:1715257926.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 328	GFLOPS: 32169.74 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.32, Tstamp:1715257926.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 329	GFLOPS: 24345.73 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.30, Tstamp:1715257926.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 330	GFLOPS: 27253.66 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715257927.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 331	GFLOPS: 18432.24 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715257927.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 332	GFLOPS: 16379.26 / 40827.98	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.55, Tstamp:1715257927.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 333	GFLOPS: 26390.60 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.50, Tstamp:1715257928.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 334	GFLOPS: 25781.14 / 40827.98	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.33, Tstamp:1715257928.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 335	GFLOPS: 41330.48 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.19, Tstamp:1715257928.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 336	GFLOPS: 26043.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.31, Tstamp:1715257929.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 337	GFLOPS: 25965.96 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.31, Tstamp:1715257929.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 338	GFLOPS: 26260.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715257929.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 339	GFLOPS: 28586.91 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715257930.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 340	GFLOPS: 24728.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715257930.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 341	GFLOPS: 26379.68 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715257930.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 342	GFLOPS: 34576.66 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.98, Tstamp:1715257931.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 343	GFLOPS: 26185.26 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.12, Tstamp:1715257931.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 344	GFLOPS: 27033.93 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715257932.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 345	GFLOPS: 29182.40 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715257932.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 346	GFLOPS: 26165.00 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.25, Tstamp:1715257932.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 347	GFLOPS: 28040.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715257932.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 348	GFLOPS: 26342.11 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715257933.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 349	GFLOPS: 28106.65 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715257933.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 350	GFLOPS: 28394.48 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715257934.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 351	GFLOPS: 26382.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715257934.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 352	GFLOPS: 28041.02 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.39, Tstamp:1715257934.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 353	GFLOPS: 26735.52 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715257935.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 354	GFLOPS: 27124.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715257935.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 355	GFLOPS: 26096.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715257935.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 356	GFLOPS: 27802.99 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.30, Tstamp:1715257936.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 357	GFLOPS: 24697.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715257936.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 358	GFLOPS: 25964.79 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715257936.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 359	GFLOPS: 26234.30 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715257937.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 360	GFLOPS: 26247.31 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715257937.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 361	GFLOPS: 26942.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715257938.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 362	GFLOPS: 25994.52 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257938.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 363	GFLOPS: 27079.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.80, Tstamp:1715257938.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 364	GFLOPS: 25607.30 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715257939.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 365	GFLOPS: 26470.20 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715257939.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 366	GFLOPS: 26389.76 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715257939.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 367	GFLOPS: 26217.21 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715257940.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 368	GFLOPS: 24945.79 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715257940.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 369	GFLOPS: 26724.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715257941.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 370	GFLOPS: 23787.61 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715257941.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 371	GFLOPS: 25005.44 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715257941.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 372	GFLOPS: 26089.12 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715257942.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 373	GFLOPS: 26772.11 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715257942.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 374	GFLOPS: 25754.57 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715257942.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 375	GFLOPS: 25953.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715257942.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 376	GFLOPS: 25964.01 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715257943.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 377	GFLOPS: 29120.80 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715257943.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 378	GFLOPS: 25193.43 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715257943.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 379	GFLOPS: 26199.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715257944.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 380	GFLOPS: 25635.10 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715257944.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 381	GFLOPS: 26191.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715257944.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 382	GFLOPS: 20394.57 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.78, Tstamp:1715257945.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,24)
      compute = ...

==================================================
No: 383	GFLOPS: 3149.23 / 41330.48	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:2.78, Tstamp:1715257945.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 384	GFLOPS: 4175.68 / 41330.48	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.52, Tstamp:1715257945.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 16
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 30.36 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.89 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1683	fail_ct: 365	Time elapsed: 2.54
GA Iter: 0	Max score: 0.6696	Min score: 0.3872	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9082	Min score: 0.6129	#Pop: 128	#M+: 1380	#M-: 71
EvolutionarySearch		#s: 128	Time elapsed: 10.25
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 385	GFLOPS: 16470.61 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.78, Tstamp:1715257968.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 386	GFLOPS: 33370.69 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.60, Tstamp:1715257968.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 387	GFLOPS: 26254.63 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.49, Tstamp:1715257968.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 388	GFLOPS: 21929.88 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:3.69, Tstamp:1715257968.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 389	GFLOPS: 33524.31 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.48, Tstamp:1715257969.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 390	GFLOPS: 28254.90 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.20, Tstamp:1715257969.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 391	GFLOPS: 34027.12 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.26, Tstamp:1715257969.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 392	GFLOPS: 29394.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.43, Tstamp:1715257970.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 393	GFLOPS: 28429.44 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.52, Tstamp:1715257970.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 394	GFLOPS: 36641.19 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.08, Tstamp:1715257970.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 395	GFLOPS: 27878.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.90, Tstamp:1715257971.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 396	GFLOPS: 30482.25 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.28, Tstamp:1715257971.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 397	GFLOPS: 28373.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715257971.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 398	GFLOPS: 30462.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.53, Tstamp:1715257972.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 399	GFLOPS: 25964.40 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.16, Tstamp:1715257972.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 400	GFLOPS: 34361.45 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.48, Tstamp:1715257972.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 401	GFLOPS: 39654.49 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.90, Tstamp:1715257973.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 402	GFLOPS: 29110.25 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.36, Tstamp:1715257973.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 403	GFLOPS: 28224.61 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.56, Tstamp:1715257973.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 404	GFLOPS: 26821.10 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.83, Tstamp:1715257974.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 405	GFLOPS: 22980.43 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.44, Tstamp:1715257974.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 406	GFLOPS: 39029.07 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.99, Tstamp:1715257974.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 407	GFLOPS: 30716.72 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.56, Tstamp:1715257975.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 408	GFLOPS: 28988.97 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715257975.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 409	GFLOPS: 31723.18 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.27, Tstamp:1715257975.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 410	GFLOPS: 27988.87 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.37, Tstamp:1715257976.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 411	GFLOPS: 31675.20 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.19, Tstamp:1715257976.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 412	GFLOPS: 30307.76 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715257976.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 413	GFLOPS: 30631.53 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.76, Tstamp:1715257977.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 414	GFLOPS: 29780.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.08, Tstamp:1715257977.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 415	GFLOPS: 25548.77 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715257977.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 416	GFLOPS: 28868.89 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715257978.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 417	GFLOPS: 26067.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715257978.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 418	GFLOPS: 25648.68 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715257979.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 419	GFLOPS: 25486.88 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715257979.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 420	GFLOPS: 19720.56 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.57, Tstamp:1715257979.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,16)
        compute = ...

==================================================
No: 421	GFLOPS: 26443.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257979.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 422	GFLOPS: 18741.35 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715257980.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 423	GFLOPS: 28056.73 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715257980.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 424	GFLOPS: 25892.97 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715257980.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 425	GFLOPS: 23380.56 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715257981.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 426	GFLOPS: 28064.60 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715257981.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 427	GFLOPS: 13471.97 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715257981.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 428	GFLOPS: 25525.32 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257982.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 429	GFLOPS: 27965.72 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715257982.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 430	GFLOPS: 26129.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715257982.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 431	GFLOPS: 26752.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.23, Tstamp:1715257983.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 432	GFLOPS: 28858.23 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715257983.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 433	GFLOPS: 27607.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715257983.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 434	GFLOPS: 28096.33 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257984.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 435	GFLOPS: 28218.98 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715257984.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 436	GFLOPS: 27304.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715257984.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 437	GFLOPS: 28236.66 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715257985.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 438	GFLOPS: 27323.78 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715257985.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 439	GFLOPS: 17742.63 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.18, Tstamp:1715257985.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 440	GFLOPS: 32354.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.37, Tstamp:1715257986.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 441	GFLOPS: 27164.60 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715257986.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 442	GFLOPS: 27600.40 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715257987.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 443	GFLOPS: 26941.29 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715257987.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 444	GFLOPS: 26354.01 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715257987.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 445	GFLOPS: 27428.88 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715257988.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 446	GFLOPS: 9543.16 / 41330.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.45, Tstamp:1715257988.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 447	GFLOPS: 3048.91 / 41330.48	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.14, Tstamp:1715257988.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 448	GFLOPS: 6727.50 / 41330.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.40, Tstamp:1715257989.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

Time elapsed for measurement: 29.52 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.84 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1645	fail_ct: 403	Time elapsed: 2.54
GA Iter: 0	Max score: 0.7820	Min score: 0.3921	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9131	Min score: 0.6095	#Pop: 128	#M+: 1386	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 449	GFLOPS: 9334.14 / 41330.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.85, Tstamp:1715258011.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 450	GFLOPS: 34159.54 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.44, Tstamp:1715258011.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 451	GFLOPS: 16528.75 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:3.39, Tstamp:1715258012.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 452	GFLOPS: 36248.99 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.78, Tstamp:1715258012.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 453	GFLOPS: 37775.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.56, Tstamp:1715258013.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 454	GFLOPS: 39179.11 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.54, Tstamp:1715258013.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 455	GFLOPS: 16968.62 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.45, Tstamp:1715258013.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 456	GFLOPS: 33826.04 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.00, Tstamp:1715258013.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 457	GFLOPS: 34869.10 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.59, Tstamp:1715258014.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 458	GFLOPS: 32361.05 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.38, Tstamp:1715258014.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 459	GFLOPS: 17467.04 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.93, Tstamp:1715258014.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 460	GFLOPS: 29057.20 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.22, Tstamp:1715258015.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 461	GFLOPS: 34953.90 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.16, Tstamp:1715258015.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 462	GFLOPS: 30225.12 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.90, Tstamp:1715258015.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 463	GFLOPS: 34221.21 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.17, Tstamp:1715258016.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 464	GFLOPS: 32341.78 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.67, Tstamp:1715258016.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 465	GFLOPS: 20607.16 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.86, Tstamp:1715258016.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 466	GFLOPS: 28320.09 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715258017.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 467	GFLOPS: 26417.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715258017.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 468	GFLOPS: 26534.95 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.72, Tstamp:1715258018.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 469	GFLOPS: 30339.28 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.72, Tstamp:1715258018.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 470	GFLOPS: 15588.53 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715258018.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 471	GFLOPS: 15874.66 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.15, Tstamp:1715258019.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 472	GFLOPS: 29159.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.34, Tstamp:1715258019.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 473	GFLOPS: 29326.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.47, Tstamp:1715258019.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 474	GFLOPS: 28015.04 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715258020.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 475	GFLOPS: 28082.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.69, Tstamp:1715258020.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 476	GFLOPS: 27415.56 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.39, Tstamp:1715258020.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 477	GFLOPS: 28720.53 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.91, Tstamp:1715258021.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 478	GFLOPS: 28456.34 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715258021.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 479	GFLOPS: 27879.61 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715258021.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 480	GFLOPS: 28513.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715258022.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 481	GFLOPS: 29017.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715258022.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 482	GFLOPS: 28599.52 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715258022.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 483	GFLOPS: 27907.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715258023.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 484	GFLOPS: 24919.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715258023.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 485	GFLOPS: 26550.71 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715258024.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 486	GFLOPS: 25855.26 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715258024.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 487	GFLOPS: 28104.38 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715258024.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 488	GFLOPS: 26639.71 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715258025.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 489	GFLOPS: 24804.81 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715258025.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 490	GFLOPS: 28453.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715258026.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 491	GFLOPS: 25448.73 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715258026.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 492	GFLOPS: 26217.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715258026.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 493	GFLOPS: 28131.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715258027.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 494	GFLOPS: 21285.41 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715258027.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 495	GFLOPS: 28616.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715258027.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 496	GFLOPS: 28959.90 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715258028.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 497	GFLOPS: 29036.49 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715258028.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 498	GFLOPS: 30049.88 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715258029.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 499	GFLOPS: 26604.76 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715258029.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 500	GFLOPS: 24739.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.26, Tstamp:1715258029.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 501	GFLOPS: 26024.57 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.66, Tstamp:1715258030.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 502	GFLOPS: 28267.73 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715258030.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 503	GFLOPS: 28396.52 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715258030.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 504	GFLOPS: 22056.43 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715258031.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 505	GFLOPS: 26392.11 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715258031.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 506	GFLOPS: 18074.07 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715258031.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 507	GFLOPS: 26230.38 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715258032.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 508	GFLOPS: 26607.81 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715258032.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 509	GFLOPS: 26229.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715258032.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 510	GFLOPS: 20271.41 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.23, Tstamp:1715258033.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 511	GFLOPS: 1534.50 / 41330.48	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.54, Tstamp:1715258033.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 512	GFLOPS: 4872.66 / 41330.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.64, Tstamp:1715258033.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

Time elapsed for measurement: 31.20 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.89 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1671	fail_ct: 377	Time elapsed: 2.49
GA Iter: 0	Max score: 0.6467	Min score: 0.3964	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8008	Min score: 0.6017	#Pop: 128	#M+: 1379	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 9.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 513	GFLOPS: 14982.24 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.68, Tstamp:1715258054.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 514	GFLOPS: 28618.40 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.45, Tstamp:1715258055.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 515	GFLOPS: 26991.89 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.83, Tstamp:1715258055.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 516	GFLOPS: 20202.39 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.75, Tstamp:1715258055.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 517	GFLOPS: 28555.34 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715258055.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 518	GFLOPS: 27102.49 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.88, Tstamp:1715258056.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 519	GFLOPS: 28089.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715258056.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 520	GFLOPS: 29258.02 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715258057.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 521	GFLOPS: 28471.55 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715258057.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 522	GFLOPS: 28111.52 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258057.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 523	GFLOPS: 28428.92 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.14, Tstamp:1715258058.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 524	GFLOPS: 27622.06 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.94, Tstamp:1715258058.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 525	GFLOPS: 31902.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.61, Tstamp:1715258058.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 526	GFLOPS: 27852.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715258059.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 527	GFLOPS: 28512.30 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715258059.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 528	GFLOPS: 28727.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715258059.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 529	GFLOPS: 28563.23 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.17, Tstamp:1715258060.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 530	GFLOPS: 30076.36 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.80, Tstamp:1715258060.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 531	GFLOPS: 16979.77 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.36, Tstamp:1715258060.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 532	GFLOPS: 26507.45 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715258061.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 533	GFLOPS: 25397.28 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715258061.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 534	GFLOPS: 28141.00 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715258061.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 535	GFLOPS: 25861.67 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715258062.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 536	GFLOPS: 28246.68 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715258062.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 537	GFLOPS: 25927.04 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715258062.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 538	GFLOPS: 26986.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.17, Tstamp:1715258063.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 539	GFLOPS: 25846.87 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715258063.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 540	GFLOPS: 28953.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715258064.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 541	GFLOPS: 26076.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.58, Tstamp:1715258064.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 542	GFLOPS: 26831.73 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.56, Tstamp:1715258064.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 543	GFLOPS: 12379.53 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.51, Tstamp:1715258064.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 544	GFLOPS: 19413.62 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715258065.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 545	GFLOPS: 28369.23 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715258065.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 546	GFLOPS: 24826.84 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715258065.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 547	GFLOPS: 12671.89 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715258066.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 548	GFLOPS: 25976.91 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715258066.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 549	GFLOPS: 29045.35 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715258066.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 550	GFLOPS: 23022.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.36, Tstamp:1715258066.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 551	GFLOPS: 25697.84 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715258067.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 552	GFLOPS: 28561.11 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715258067.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 553	GFLOPS: 26312.67 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715258068.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 554	GFLOPS: 26311.68 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715258068.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 555	GFLOPS: 26245.81 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715258068.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 556	GFLOPS: 26234.66 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715258069.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 557	GFLOPS: 25671.31 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715258069.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 558	GFLOPS: 26558.81 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715258069.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 559	GFLOPS: 25942.25 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715258070.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 560	GFLOPS: 26255.50 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715258070.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 561	GFLOPS: 25588.61 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715258071.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 562	GFLOPS: 26450.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715258071.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 563	GFLOPS: 25773.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715258071.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 564	GFLOPS: 26152.32 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715258072.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 565	GFLOPS: 26161.38 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715258072.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 566	GFLOPS: 25472.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715258072.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 567	GFLOPS: 26037.24 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715258072.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 568	GFLOPS: 25867.10 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715258073.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 569	GFLOPS: 14793.60 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715258073.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 570	GFLOPS: 28715.22 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715258073.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 571	GFLOPS: 26348.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715258074.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 572	GFLOPS: 26204.08 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715258074.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 573	GFLOPS: 26206.54 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715258075.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 574	GFLOPS: 3518.43 / 41330.48	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.50, Tstamp:1715258075.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 575	GFLOPS: 4072.27 / 41330.48	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.49, Tstamp:1715258075.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 576	GFLOPS: 5263.78 / 41330.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.33, Tstamp:1715258076.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 28.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.02 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1680	fail_ct: 368	Time elapsed: 2.53
GA Iter: 0	Max score: 0.6272	Min score: 0.3994	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8599	Min score: 0.5798	#Pop: 128	#M+: 1378	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 10.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 577	GFLOPS: 16410.06 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.88, Tstamp:1715258097.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 578	GFLOPS: 25926.87 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.66, Tstamp:1715258097.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 579	GFLOPS: 28243.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.09, Tstamp:1715258098.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 580	GFLOPS: 27832.44 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.55, Tstamp:1715258098.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 581	GFLOPS: 28701.19 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715258099.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 582	GFLOPS: 28968.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.38, Tstamp:1715258099.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 583	GFLOPS: 28274.60 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715258099.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 584	GFLOPS: 28106.05 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715258100.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 585	GFLOPS: 27996.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258100.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 586	GFLOPS: 26396.02 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.13, Tstamp:1715258100.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 587	GFLOPS: 26373.47 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258101.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 588	GFLOPS: 29975.08 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.32, Tstamp:1715258101.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 589	GFLOPS: 23445.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.51, Tstamp:1715258102.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 590	GFLOPS: 26133.37 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.37, Tstamp:1715258102.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 591	GFLOPS: 24006.41 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.19, Tstamp:1715258102.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 592	GFLOPS: 26276.42 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715258103.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 593	GFLOPS: 26446.85 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715258103.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 594	GFLOPS: 26440.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258103.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 595	GFLOPS: 26628.06 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715258104.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 596	GFLOPS: 26352.16 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715258104.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 597	GFLOPS: 26419.46 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715258104.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 598	GFLOPS: 26119.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715258105.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 599	GFLOPS: 26057.48 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715258105.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 600	GFLOPS: 26491.79 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715258106.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 601	GFLOPS: 25959.56 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715258106.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 602	GFLOPS: 26262.10 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715258106.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 603	GFLOPS: 26357.60 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715258106.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 604	GFLOPS: 25650.02 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715258107.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 605	GFLOPS: 26108.80 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715258107.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 606	GFLOPS: 25882.57 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715258107.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 607	GFLOPS: 25911.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715258108.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 608	GFLOPS: 26028.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715258108.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 609	GFLOPS: 25934.77 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715258108.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 610	GFLOPS: 25739.74 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715258109.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 611	GFLOPS: 26480.56 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715258109.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 612	GFLOPS: 24211.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258109.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 613	GFLOPS: 24873.09 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715258110.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 614	GFLOPS: 13544.26 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715258110.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 615	GFLOPS: 25588.21 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715258111.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 616	GFLOPS: 25289.01 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715258111.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 617	GFLOPS: 26237.28 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715258111.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 618	GFLOPS: 21394.55 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715258111.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 619	GFLOPS: 25876.06 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715258112.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 620	GFLOPS: 25330.05 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715258112.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 621	GFLOPS: 26076.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715258112.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 622	GFLOPS: 24811.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715258113.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 623	GFLOPS: 26073.36 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715258113.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 624	GFLOPS: 28140.47 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.39, Tstamp:1715258113.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 625	GFLOPS: 25805.38 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715258114.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 626	GFLOPS: 26014.46 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715258114.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 627	GFLOPS: 26316.03 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715258114.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 628	GFLOPS: 26027.89 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258115.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 629	GFLOPS: 26544.64 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715258115.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 630	GFLOPS: 23874.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715258115.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 631	GFLOPS: 23996.74 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.34, Tstamp:1715258116.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 632	GFLOPS: 23930.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715258116.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 633	GFLOPS: 25426.39 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715258116.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 634	GFLOPS: 24924.55 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715258116.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 635	GFLOPS: 23441.98 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258117.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 636	GFLOPS: 25650.80 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715258117.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 637	GFLOPS: 26159.39 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715258118.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 638	GFLOPS: 15198.41 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715258118.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 639	GFLOPS: 2981.69 / 41330.48	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.29, Tstamp:1715258118.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 640	GFLOPS: 1329.04 / 41330.48	results: MeasureResult(cost:[0.0027], error_no:0, all_cost:0.37, Tstamp:1715258118.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 28.91 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.95 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1659	fail_ct: 389	Time elapsed: 2.55
GA Iter: 0	Max score: 0.6573	Min score: 0.3859	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7875	Min score: 0.5777	#Pop: 128	#M+: 1386	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 641	GFLOPS: 25792.57 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.65, Tstamp:1715258140.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 642	GFLOPS: 26698.47 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.55, Tstamp:1715258140.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 643	GFLOPS: 15099.71 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.66, Tstamp:1715258141.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 644	GFLOPS: 27563.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.42, Tstamp:1715258141.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 645	GFLOPS: 29874.43 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.60, Tstamp:1715258141.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 646	GFLOPS: 25866.23 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715258142.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 647	GFLOPS: 28642.87 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715258142.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 648	GFLOPS: 28638.72 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715258142.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 649	GFLOPS: 28575.71 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715258143.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 650	GFLOPS: 28291.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715258143.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 651	GFLOPS: 28160.07 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715258143.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 652	GFLOPS: 28818.87 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.03, Tstamp:1715258144.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 653	GFLOPS: 18134.09 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.47, Tstamp:1715258144.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 654	GFLOPS: 25682.26 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.01, Tstamp:1715258144.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 655	GFLOPS: 27836.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.59, Tstamp:1715258145.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 656	GFLOPS: 26394.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715258145.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 657	GFLOPS: 26586.32 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.88, Tstamp:1715258145.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 658	GFLOPS: 26534.04 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715258146.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 659	GFLOPS: 26174.61 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715258146.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 660	GFLOPS: 28642.93 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715258146.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 661	GFLOPS: 25273.71 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715258147.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 662	GFLOPS: 25212.90 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.56, Tstamp:1715258147.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 663	GFLOPS: 26028.73 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715258147.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 664	GFLOPS: 26121.72 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715258148.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 665	GFLOPS: 25749.54 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715258148.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 666	GFLOPS: 26595.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.60, Tstamp:1715258148.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 667	GFLOPS: 25440.88 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715258149.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 668	GFLOPS: 26560.25 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715258149.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 669	GFLOPS: 25573.01 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715258149.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 670	GFLOPS: 21465.51 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715258150.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 671	GFLOPS: 25570.77 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715258150.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 672	GFLOPS: 25711.09 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715258150.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 673	GFLOPS: 26052.41 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715258151.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 674	GFLOPS: 25855.77 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715258151.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 675	GFLOPS: 25398.16 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715258151.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 676	GFLOPS: 23572.98 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.04, Tstamp:1715258151.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 677	GFLOPS: 25547.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715258152.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 678	GFLOPS: 21265.30 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715258152.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 679	GFLOPS: 23863.67 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715258152.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 680	GFLOPS: 26162.14 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715258153.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 681	GFLOPS: 25188.13 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715258153.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 682	GFLOPS: 25753.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715258153.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 683	GFLOPS: 23262.24 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715258153.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 684	GFLOPS: 21174.13 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.56, Tstamp:1715258154.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 685	GFLOPS: 23406.51 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715258154.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 686	GFLOPS: 23162.23 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715258154.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 687	GFLOPS: 25584.61 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715258155.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 688	GFLOPS: 25959.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715258155.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 689	GFLOPS: 25976.47 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715258155.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 690	GFLOPS: 26607.55 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715258156.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 691	GFLOPS: 24766.26 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715258156.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 692	GFLOPS: 15912.62 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.28, Tstamp:1715258156.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 693	GFLOPS: 24996.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715258157.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 694	GFLOPS: 25870.80 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715258157.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 695	GFLOPS: 23142.11 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715258157.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 696	GFLOPS: 25739.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715258158.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 697	GFLOPS: 26322.28 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715258158.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 698	GFLOPS: 22473.74 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715258158.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 699	GFLOPS: 23782.12 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715258159.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 700	GFLOPS: 23911.81 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.86, Tstamp:1715258159.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,48)
        compute = ...

==================================================
No: 701	GFLOPS: 24856.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715258159.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 702	GFLOPS: 15192.99 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715258160.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 703	GFLOPS: 20062.18 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715258160.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 704	GFLOPS: 2533.88 / 41330.48	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.36, Tstamp:1715258160.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 28.28 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.94 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1677	fail_ct: 371	Time elapsed: 2.51
GA Iter: 0	Max score: 0.6099	Min score: 0.3914	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8681	Min score: 0.5552	#Pop: 128	#M+: 1381	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 705	GFLOPS: 10409.60 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.44, Tstamp:1715258182.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 706	GFLOPS: 28391.30 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715258182.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 707	GFLOPS: 23112.28 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.04, Tstamp:1715258182.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 708	GFLOPS: 23597.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.87, Tstamp:1715258183.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 709	GFLOPS: 22763.23 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.75, Tstamp:1715258183.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 710	GFLOPS: 14473.74 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.87, Tstamp:1715258183.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 711	GFLOPS: 11456.43 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.80, Tstamp:1715258184.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 712	GFLOPS: 11421.74 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.07, Tstamp:1715258184.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 713	GFLOPS: 11690.81 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.88, Tstamp:1715258184.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 714	GFLOPS: 13871.02 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.57, Tstamp:1715258185.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 715	GFLOPS: 11828.68 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.42, Tstamp:1715258185.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 716	GFLOPS: 26610.90 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715258185.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 717	GFLOPS: 26573.24 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.47, Tstamp:1715258186.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 718	GFLOPS: 25653.76 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.14, Tstamp:1715258186.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 719	GFLOPS: 27291.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.57, Tstamp:1715258186.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 720	GFLOPS: 24265.95 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.37, Tstamp:1715258187.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 721	GFLOPS: 26498.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715258187.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 722	GFLOPS: 24971.05 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.55, Tstamp:1715258187.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 723	GFLOPS: 25470.56 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715258188.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 724	GFLOPS: 26362.48 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.35, Tstamp:1715258188.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 725	GFLOPS: 25888.31 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715258189.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 726	GFLOPS: 16966.92 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.66, Tstamp:1715258189.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 727	GFLOPS: 25623.43 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715258189.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 728	GFLOPS: 25478.30 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715258190.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 729	GFLOPS: 26412.30 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715258190.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 730	GFLOPS: 14133.94 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.77, Tstamp:1715258190.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 731	GFLOPS: 25036.14 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.50, Tstamp:1715258191.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 732	GFLOPS: 26617.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.14, Tstamp:1715258191.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 733	GFLOPS: 26501.29 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715258191.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 734	GFLOPS: 25041.55 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715258192.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 735	GFLOPS: 25011.83 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.31, Tstamp:1715258192.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 736	GFLOPS: 22287.83 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.46, Tstamp:1715258192.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 737	GFLOPS: 22818.28 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715258193.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 738	GFLOPS: 25914.18 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715258193.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 739	GFLOPS: 26846.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.51, Tstamp:1715258193.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 740	GFLOPS: 19345.07 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715258194.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 741	GFLOPS: 20246.67 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.55, Tstamp:1715258194.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 742	GFLOPS: 26508.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.72, Tstamp:1715258194.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 743	GFLOPS: 25106.97 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715258195.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 744	GFLOPS: 24419.22 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715258195.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 745	GFLOPS: 17562.19 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715258195.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 746	GFLOPS: 26598.60 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715258196.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 747	GFLOPS: 22503.91 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715258196.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 748	GFLOPS: 23558.64 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.40, Tstamp:1715258196.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 749	GFLOPS: 24718.78 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715258197.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 750	GFLOPS: 13780.10 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.42, Tstamp:1715258197.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 751	GFLOPS: 24092.24 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715258197.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 752	GFLOPS: 23727.43 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715258198.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 753	GFLOPS: 16918.47 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715258198.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 754	GFLOPS: 23897.44 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715258198.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 755	GFLOPS: 24990.89 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.25, Tstamp:1715258199.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 756	GFLOPS: 26361.74 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.61, Tstamp:1715258199.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 757	GFLOPS: 13051.18 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715258199.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 758	GFLOPS: 23351.56 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715258200.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 759	GFLOPS: 22648.69 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.35, Tstamp:1715258200.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 760	GFLOPS: 24095.21 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258200.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 761	GFLOPS: 23957.47 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715258201.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 762	GFLOPS: 24465.57 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715258201.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 763	GFLOPS: 22506.12 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715258201.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 764	GFLOPS: 23725.69 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.56, Tstamp:1715258202.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 765	GFLOPS: 22061.78 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715258202.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 766	GFLOPS: 2804.08 / 41330.48	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.69, Tstamp:1715258203.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 767	GFLOPS: 3269.95 / 41330.48	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.54, Tstamp:1715258203.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  for i.1 (0,384)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 768	GFLOPS: 18916.96 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715258203.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 29.30 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.16 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1642	fail_ct: 406	Time elapsed: 2.56
GA Iter: 0	Max score: 0.6904	Min score: 0.4008	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6904	Min score: 0.5278	#Pop: 128	#M+: 1367	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.15
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 769	GFLOPS: 13964.35 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.24, Tstamp:1715258228.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 770	GFLOPS: 18429.93 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.40, Tstamp:1715258228.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 771	GFLOPS: 28805.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.12, Tstamp:1715258228.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 772	GFLOPS: 31260.12 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.27, Tstamp:1715258229.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 773	GFLOPS: 15224.09 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715258229.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 774	GFLOPS: 31949.63 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715258229.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 775	GFLOPS: 25406.97 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715258230.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 776	GFLOPS: 25276.62 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715258230.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 777	GFLOPS: 24269.94 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.74, Tstamp:1715258230.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 778	GFLOPS: 26116.46 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.73, Tstamp:1715258231.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 779	GFLOPS: 26047.04 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.42, Tstamp:1715258231.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 780	GFLOPS: 24520.21 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715258231.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 781	GFLOPS: 21385.19 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715258232.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 782	GFLOPS: 20862.51 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715258232.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 783	GFLOPS: 21874.31 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715258232.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 784	GFLOPS: 24386.79 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715258233.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 785	GFLOPS: 23883.21 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715258233.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 786	GFLOPS: 26167.13 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715258234.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 787	GFLOPS: 23358.78 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.14, Tstamp:1715258234.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 788	GFLOPS: 24758.19 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.62, Tstamp:1715258234.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 789	GFLOPS: 26232.92 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.22, Tstamp:1715258234.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 790	GFLOPS: 15285.75 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.99, Tstamp:1715258235.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 791	GFLOPS: 22805.45 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.97, Tstamp:1715258235.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 792	GFLOPS: 24802.68 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715258236.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 793	GFLOPS: 23701.56 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715258236.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 794	GFLOPS: 24487.00 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.16, Tstamp:1715258236.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 795	GFLOPS: 24033.58 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715258237.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 796	GFLOPS: 22724.85 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715258237.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 797	GFLOPS: 24633.82 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715258237.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 798	GFLOPS: 17967.61 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.46, Tstamp:1715258237.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 799	GFLOPS: 23884.91 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.91, Tstamp:1715258238.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 800	GFLOPS: 19710.16 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715258238.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 801	GFLOPS: 23471.96 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.57, Tstamp:1715258238.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 802	GFLOPS: 25932.99 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715258239.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 803	GFLOPS: 26128.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715258239.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 804	GFLOPS: 21557.36 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715258239.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 805	GFLOPS: 17569.72 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715258239.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 806	GFLOPS: 27340.86 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.33, Tstamp:1715258240.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 807	GFLOPS: 22645.03 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.88, Tstamp:1715258240.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 808	GFLOPS: 22341.52 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715258240.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 809	GFLOPS: 23406.75 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715258241.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 810	GFLOPS: 18143.91 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715258241.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 811	GFLOPS: 20307.11 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715258241.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 812	GFLOPS: 26369.75 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715258241.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 813	GFLOPS: 19505.39 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715258242.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 814	GFLOPS: 14929.15 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715258242.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 815	GFLOPS: 26890.45 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715258242.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 816	GFLOPS: 22512.10 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715258243.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 817	GFLOPS: 26324.68 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715258243.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 818	GFLOPS: 23151.32 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715258243.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 819	GFLOPS: 23651.90 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715258244.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 820	GFLOPS: 23386.73 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715258244.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 821	GFLOPS: 23280.55 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715258244.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 822	GFLOPS: 22920.41 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715258245.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 823	GFLOPS: 27781.84 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715258245.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 824	GFLOPS: 22915.75 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715258246.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 825	GFLOPS: 24612.22 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715258246.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 826	GFLOPS: 22228.90 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715258246.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 827	GFLOPS: 31475.01 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715258246.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 828	GFLOPS: 21230.35 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715258247.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 829	GFLOPS: 24925.93 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715258247.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 830	GFLOPS: 6199.65 / 41330.48	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.56, Tstamp:1715258247.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 831	GFLOPS: 1650.87 / 41330.48	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:4.10, Tstamp:1715258248.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 832	GFLOPS: 5333.42 / 41330.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.45, Tstamp:1715258248.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 30.72 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.02 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1670	fail_ct: 378	Time elapsed: 2.56
GA Iter: 0	Max score: 0.6456	Min score: 0.3813	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7299	Min score: 0.5068	#Pop: 128	#M+: 1383	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.12
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 833	GFLOPS: 8573.40 / 41330.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.64, Tstamp:1715258269.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 834	GFLOPS: 14047.73 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.13, Tstamp:1715258270.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 835	GFLOPS: 29534.46 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.08, Tstamp:1715258270.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 836	GFLOPS: 21530.71 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715258270.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 837	GFLOPS: 25575.99 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.00, Tstamp:1715258271.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 838	GFLOPS: 25108.17 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715258271.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 839	GFLOPS: 26234.03 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.69, Tstamp:1715258271.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 840	GFLOPS: 26089.08 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715258272.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 841	GFLOPS: 14436.32 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.23, Tstamp:1715258272.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 842	GFLOPS: 26007.14 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.04, Tstamp:1715258272.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 843	GFLOPS: 22644.12 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.03, Tstamp:1715258273.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 844	GFLOPS: 23148.17 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715258273.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 845	GFLOPS: 24373.51 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.14, Tstamp:1715258274.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 846	GFLOPS: 21804.31 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715258274.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 847	GFLOPS: 13158.46 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.04, Tstamp:1715258274.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 848	GFLOPS: 24552.70 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715258275.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 849	GFLOPS: 25333.03 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715258275.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 850	GFLOPS: 23924.62 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.18, Tstamp:1715258275.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 851	GFLOPS: 25811.50 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715258276.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 852	GFLOPS: 22008.24 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715258276.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 853	GFLOPS: 21350.86 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715258276.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 854	GFLOPS: 25105.04 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.80, Tstamp:1715258277.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 855	GFLOPS: 23342.47 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715258277.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 856	GFLOPS: 23613.70 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715258277.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 857	GFLOPS: 15672.59 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715258278.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 858	GFLOPS: 14238.35 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.63, Tstamp:1715258278.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,48)
      for c (0,16)
        compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 859	GFLOPS: 14639.67 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.04, Tstamp:1715258278.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 860	GFLOPS: 24179.12 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715258278.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 861	GFLOPS: 21430.61 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715258279.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 862	GFLOPS: 19482.34 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715258279.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 863	GFLOPS: 17220.91 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.26, Tstamp:1715258279.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 864	GFLOPS: 22387.96 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715258280.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 865	GFLOPS: 21405.24 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715258280.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 866	GFLOPS: 23102.19 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.86, Tstamp:1715258280.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 867	GFLOPS: 22433.62 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715258281.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 868	GFLOPS: 23118.60 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715258281.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 869	GFLOPS: 21708.08 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715258282.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 870	GFLOPS: 24411.52 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715258282.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 871	GFLOPS: 25940.27 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715258282.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 872	GFLOPS: 21247.96 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715258282.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 873	GFLOPS: 13552.02 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.61, Tstamp:1715258283.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,64)
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 874	GFLOPS: 21643.22 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715258283.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 875	GFLOPS: 20499.59 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715258284.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 876	GFLOPS: 15629.64 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715258284.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 877	GFLOPS: 19945.09 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715258284.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 878	GFLOPS: 24116.27 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715258284.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 879	GFLOPS: 23232.38 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.74, Tstamp:1715258285.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 880	GFLOPS: 23091.34 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258285.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 881	GFLOPS: 21923.08 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715258286.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 882	GFLOPS: 21930.67 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715258286.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 883	GFLOPS: 25780.93 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715258286.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 884	GFLOPS: 21563.46 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715258287.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 885	GFLOPS: 22101.31 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715258287.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 886	GFLOPS: 20627.52 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715258287.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 887	GFLOPS: 20806.57 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715258288.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 888	GFLOPS: 19673.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715258288.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 889	GFLOPS: 18988.34 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715258288.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 890	GFLOPS: 22469.89 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.43, Tstamp:1715258288.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 891	GFLOPS: 21797.08 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715258289.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 892	GFLOPS: 21575.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.39, Tstamp:1715258289.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 893	GFLOPS: 20576.01 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715258289.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 894	GFLOPS: 3392.04 / 41330.48	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.54, Tstamp:1715258290.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  for i.1 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 895	GFLOPS: 7991.52 / 41330.48	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.84, Tstamp:1715258290.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 896	GFLOPS: 5465.50 / 41330.48	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.34, Tstamp:1715258290.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 28.34 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.22 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1665	fail_ct: 383	Time elapsed: 2.52
GA Iter: 0	Max score: 0.6125	Min score: 0.3799	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6776	Min score: 0.4898	#Pop: 128	#M+: 1387	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 9.96
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 897	GFLOPS: 12972.35 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.64, Tstamp:1715258311.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 898	GFLOPS: 25746.24 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.78, Tstamp:1715258312.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 899	GFLOPS: 25009.79 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.13, Tstamp:1715258312.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 900	GFLOPS: 18184.35 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258312.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 901	GFLOPS: 25570.43 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.88, Tstamp:1715258313.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 902	GFLOPS: 24838.79 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.82, Tstamp:1715258313.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 903	GFLOPS: 19979.18 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715258314.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 904	GFLOPS: 24766.39 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.86, Tstamp:1715258314.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 905	GFLOPS: 24169.42 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.73, Tstamp:1715258314.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 906	GFLOPS: 25453.28 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.59, Tstamp:1715258315.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 907	GFLOPS: 17946.17 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.88, Tstamp:1715258315.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,24)
      for c (0,16)
        compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 908	GFLOPS: 23919.26 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.82, Tstamp:1715258315.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 909	GFLOPS: 23271.42 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.17, Tstamp:1715258315.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 910	GFLOPS: 24790.34 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.66, Tstamp:1715258316.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 911	GFLOPS: 21156.05 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715258316.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 912	GFLOPS: 23444.99 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715258316.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 913	GFLOPS: 23006.18 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.09, Tstamp:1715258317.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 914	GFLOPS: 16023.10 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.25, Tstamp:1715258317.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 915	GFLOPS: 23375.60 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.05, Tstamp:1715258318.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 916	GFLOPS: 19407.50 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.12, Tstamp:1715258318.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 917	GFLOPS: 19862.46 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715258318.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 918	GFLOPS: 21462.55 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715258319.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 919	GFLOPS: 23508.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.91, Tstamp:1715258319.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 920	GFLOPS: 22751.54 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.77, Tstamp:1715258319.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 921	GFLOPS: 21549.91 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715258319.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 922	GFLOPS: 19258.41 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.58, Tstamp:1715258320.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 923	GFLOPS: 20357.60 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715258320.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 924	GFLOPS: 22129.45 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715258320.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 925	GFLOPS: 21857.03 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715258321.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 926	GFLOPS: 18607.08 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715258321.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 927	GFLOPS: 19154.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715258321.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 928	GFLOPS: 21344.05 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715258322.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 929	GFLOPS: 21775.74 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258322.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 930	GFLOPS: 10538.92 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.43, Tstamp:1715258322.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 931	GFLOPS: 20428.67 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715258322.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 932	GFLOPS: 20171.38 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.60, Tstamp:1715258323.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 933	GFLOPS: 18608.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715258323.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 934	GFLOPS: 16757.49 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258323.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 935	GFLOPS: 20853.45 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.67, Tstamp:1715258324.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 936	GFLOPS: 22032.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715258324.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 937	GFLOPS: 21848.70 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715258324.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 938	GFLOPS: 21311.90 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715258325.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 939	GFLOPS: 25132.03 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715258325.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 940	GFLOPS: 21622.35 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715258325.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 941	GFLOPS: 20356.23 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715258325.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 942	GFLOPS: 21258.01 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.90, Tstamp:1715258326.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 943	GFLOPS: 21845.99 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715258326.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 944	GFLOPS: 19785.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715258327.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 945	GFLOPS: 23970.03 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715258327.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 946	GFLOPS: 21398.40 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715258327.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 947	GFLOPS: 20523.35 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715258328.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 948	GFLOPS: 18902.61 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.43, Tstamp:1715258328.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 949	GFLOPS: 21410.33 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715258328.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 950	GFLOPS: 22597.78 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.37, Tstamp:1715258328.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 951	GFLOPS: 21129.43 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715258329.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 952	GFLOPS: 23131.39 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715258329.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 953	GFLOPS: 22136.80 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715258329.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 954	GFLOPS: 20419.47 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.78, Tstamp:1715258330.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 955	GFLOPS: 21799.10 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.54, Tstamp:1715258330.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 956	GFLOPS: 13689.17 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.39, Tstamp:1715258330.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 957	GFLOPS: 20188.03 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.67, Tstamp:1715258331.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 958	GFLOPS: 4769.99 / 41330.48	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.99, Tstamp:1715258331.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 959	GFLOPS: 3038.57 / 41330.48	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.47, Tstamp:1715258331.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 960	GFLOPS: 8650.78 / 41330.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.46, Tstamp:1715258332.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,6)
      compute = ...

Time elapsed for measurement: 27.77 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.98 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1669	fail_ct: 379	Time elapsed: 2.55
GA Iter: 0	Max score: 0.5640	Min score: 0.3778	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6645	Min score: 0.5119	#Pop: 128	#M+: 1386	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 10.09
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 40 programs to measure:
........................................****************************************
==================================================
No: 961	GFLOPS: 12159.44 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.21, Tstamp:1715258351.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 962	GFLOPS: 25486.47 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.43, Tstamp:1715258352.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 963	GFLOPS: 25494.44 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.53, Tstamp:1715258352.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 964	GFLOPS: 24334.26 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715258352.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 965	GFLOPS: 26282.02 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.08, Tstamp:1715258353.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 966	GFLOPS: 14692.24 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.05, Tstamp:1715258353.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,32)
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 967	GFLOPS: 24229.37 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.22, Tstamp:1715258353.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 968	GFLOPS: 21218.68 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.37, Tstamp:1715258354.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 969	GFLOPS: 26581.15 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.68, Tstamp:1715258354.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 970	GFLOPS: 22165.18 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.54, Tstamp:1715258354.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 971	GFLOPS: 26858.06 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.82, Tstamp:1715258355.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 972	GFLOPS: 20853.76 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715258355.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 973	GFLOPS: 20787.77 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.56, Tstamp:1715258355.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,32)
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 974	GFLOPS: 9057.93 / 41330.48	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.82, Tstamp:1715258356.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 975	GFLOPS: 22532.80 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.52, Tstamp:1715258356.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 976	GFLOPS: 22789.19 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715258356.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 977	GFLOPS: 19817.04 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715258357.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 978	GFLOPS: 18056.08 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.01, Tstamp:1715258357.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,32)
    compute auto_unroll: 64
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 979	GFLOPS: 26183.44 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.41, Tstamp:1715258357.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 980	GFLOPS: 20843.01 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715258357.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 981	GFLOPS: 12874.08 / 41330.48	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.50, Tstamp:1715258358.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 982	GFLOPS: 19943.35 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715258358.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 983	GFLOPS: 27377.20 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715258358.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

==================================================
No: 984	GFLOPS: 20763.22 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715258358.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 985	GFLOPS: 23494.39 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.70, Tstamp:1715258359.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 986	GFLOPS: 21035.74 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.98, Tstamp:1715258359.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 987	GFLOPS: 19488.86 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.41, Tstamp:1715258360.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 988	GFLOPS: 18437.11 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.65, Tstamp:1715258360.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

==================================================
No: 989	GFLOPS: 18453.47 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715258360.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 990	GFLOPS: 21241.77 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715258360.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 991	GFLOPS: 18630.61 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.58, Tstamp:1715258361.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 992	GFLOPS: 17374.92 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.36, Tstamp:1715258361.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 993	GFLOPS: 20607.34 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.32, Tstamp:1715258361.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 994	GFLOPS: 27909.72 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715258362.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 995	GFLOPS: 20594.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.59, Tstamp:1715258362.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,24)
        compute = ...

==================================================
No: 996	GFLOPS: 19229.97 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.20, Tstamp:1715258362.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,24)
      compute = ...

==================================================
No: 997	GFLOPS: 25078.20 / 41330.48	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715258363.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 998	GFLOPS: 21445.37 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715258363.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 999	GFLOPS: 22142.21 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.35, Tstamp:1715258363.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 1000	GFLOPS: 19841.27 / 41330.48	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715258363.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,32)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,24)
        compute = ...

Time elapsed for measurement: 17.91 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
Lowered TIR:
@main = primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, compute_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_8: Pointer(float32), float32, [768, 3072], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [100, 16, 16], []),
             placeholder_2: Buffer(placeholder_10: Pointer(int32), int32, [100], []),
             placeholder_3: Buffer(placeholder_11: Pointer(int32), int32, [49], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, compute_1: compute} {
  for (m.outer: int32, 0, 128) "parallel" {
    allocate(compute_3: Pointer(global float32), float32, [288]), storage_scope = global;
    for (n.outer: int32, 0, 16) {
      for (nb_j.inner: int32, 0, 3) {
        let cse_var_1: int32 = (nb_j.inner*16)
         {
          compute_4: Buffer(compute_3, float32, [288], [])[cse_var_1] = 0f32
          compute_4[(cse_var_1 + 1)] = 0f32
          compute_4[(cse_var_1 + 2)] = 0f32
          compute_4[(cse_var_1 + 3)] = 0f32
          compute_4[(cse_var_1 + 4)] = 0f32
          compute_4[(cse_var_1 + 5)] = 0f32
          compute_4[(cse_var_1 + 6)] = 0f32
          compute_4[(cse_var_1 + 7)] = 0f32
          compute_4[(cse_var_1 + 8)] = 0f32
          compute_4[(cse_var_1 + 9)] = 0f32
          compute_4[(cse_var_1 + 10)] = 0f32
          compute_4[(cse_var_1 + 11)] = 0f32
          compute_4[(cse_var_1 + 12)] = 0f32
          compute_4[(cse_var_1 + 13)] = 0f32
          compute_4[(cse_var_1 + 14)] = 0f32
          compute_4[(cse_var_1 + 15)] = 0f32
          compute_4[(cse_var_1 + 48)] = 0f32
          compute_4[(cse_var_1 + 49)] = 0f32
          compute_4[(cse_var_1 + 50)] = 0f32
          compute_4[(cse_var_1 + 51)] = 0f32
          compute_4[(cse_var_1 + 52)] = 0f32
          compute_4[(cse_var_1 + 53)] = 0f32
          compute_4[(cse_var_1 + 54)] = 0f32
          compute_4[(cse_var_1 + 55)] = 0f32
          compute_4[(cse_var_1 + 56)] = 0f32
          compute_4[(cse_var_1 + 57)] = 0f32
          compute_4[(cse_var_1 + 58)] = 0f32
          compute_4[(cse_var_1 + 59)] = 0f32
          compute_4[(cse_var_1 + 60)] = 0f32
          compute_4[(cse_var_1 + 61)] = 0f32
          compute_4[(cse_var_1 + 62)] = 0f32
          compute_4[(cse_var_1 + 63)] = 0f32
          compute_4[(cse_var_1 + 96)] = 0f32
          compute_4[(cse_var_1 + 97)] = 0f32
          compute_4[(cse_var_1 + 98)] = 0f32
          compute_4[(cse_var_1 + 99)] = 0f32
          compute_4[(cse_var_1 + 100)] = 0f32
          compute_4[(cse_var_1 + 101)] = 0f32
          compute_4[(cse_var_1 + 102)] = 0f32
          compute_4[(cse_var_1 + 103)] = 0f32
          compute_4[(cse_var_1 + 104)] = 0f32
          compute_4[(cse_var_1 + 105)] = 0f32
          compute_4[(cse_var_1 + 106)] = 0f32
          compute_4[(cse_var_1 + 107)] = 0f32
          compute_4[(cse_var_1 + 108)] = 0f32
          compute_4[(cse_var_1 + 109)] = 0f32
          compute_4[(cse_var_1 + 110)] = 0f32
          compute_4[(cse_var_1 + 111)] = 0f32
          compute_4[(cse_var_1 + 144)] = 0f32
          compute_4[(cse_var_1 + 145)] = 0f32
          compute_4[(cse_var_1 + 146)] = 0f32
          compute_4[(cse_var_1 + 147)] = 0f32
          compute_4[(cse_var_1 + 148)] = 0f32
          compute_4[(cse_var_1 + 149)] = 0f32
          compute_4[(cse_var_1 + 150)] = 0f32
          compute_4[(cse_var_1 + 151)] = 0f32
          compute_4[(cse_var_1 + 152)] = 0f32
          compute_4[(cse_var_1 + 153)] = 0f32
          compute_4[(cse_var_1 + 154)] = 0f32
          compute_4[(cse_var_1 + 155)] = 0f32
          compute_4[(cse_var_1 + 156)] = 0f32
          compute_4[(cse_var_1 + 157)] = 0f32
          compute_4[(cse_var_1 + 158)] = 0f32
          compute_4[(cse_var_1 + 159)] = 0f32
          compute_4[(cse_var_1 + 192)] = 0f32
          compute_4[(cse_var_1 + 193)] = 0f32
          compute_4[(cse_var_1 + 194)] = 0f32
          compute_4[(cse_var_1 + 195)] = 0f32
          compute_4[(cse_var_1 + 196)] = 0f32
          compute_4[(cse_var_1 + 197)] = 0f32
          compute_4[(cse_var_1 + 198)] = 0f32
          compute_4[(cse_var_1 + 199)] = 0f32
          compute_4[(cse_var_1 + 200)] = 0f32
          compute_4[(cse_var_1 + 201)] = 0f32
          compute_4[(cse_var_1 + 202)] = 0f32
          compute_4[(cse_var_1 + 203)] = 0f32
          compute_4[(cse_var_1 + 204)] = 0f32
          compute_4[(cse_var_1 + 205)] = 0f32
          compute_4[(cse_var_1 + 206)] = 0f32
          compute_4[(cse_var_1 + 207)] = 0f32
          compute_4[(cse_var_1 + 240)] = 0f32
          compute_4[(cse_var_1 + 241)] = 0f32
          compute_4[(cse_var_1 + 242)] = 0f32
          compute_4[(cse_var_1 + 243)] = 0f32
          compute_4[(cse_var_1 + 244)] = 0f32
          compute_4[(cse_var_1 + 245)] = 0f32
          compute_4[(cse_var_1 + 246)] = 0f32
          compute_4[(cse_var_1 + 247)] = 0f32
          compute_4[(cse_var_1 + 248)] = 0f32
          compute_4[(cse_var_1 + 249)] = 0f32
          compute_4[(cse_var_1 + 250)] = 0f32
          compute_4[(cse_var_1 + 251)] = 0f32
          compute_4[(cse_var_1 + 252)] = 0f32
          compute_4[(cse_var_1 + 253)] = 0f32
          compute_4[(cse_var_1 + 254)] = 0f32
          compute_4[(cse_var_1 + 255)] = 0f32
          for (elem_idx: int32, 0, let cse_var_2: int32 = ((n.outer*3) + nb_j.inner) in (placeholder_12: Buffer(placeholder_11, int32, [49], [])[(cse_var_2 + 1)] - placeholder_12[cse_var_2])) {
            for (i.inner: int32, 0, 6) {
              let cse_var_21: int32 = (elem_idx*256)
              let cse_var_20: int32 = ((n.outer*3) + nb_j.inner)
              let cse_var_19: int32 = ((i.inner*48) + cse_var_1)
              let cse_var_18: int32 = ((m.outer*18432) + (i.inner*3072))
              let cse_var_17: int32 = (cse_var_19 + 9)
              let cse_var_16: int32 = (cse_var_19 + 8)
              let cse_var_15: int32 = (cse_var_19 + 7)
              let cse_var_14: int32 = (cse_var_19 + 6)
              let cse_var_13: int32 = (cse_var_19 + 5)
              let cse_var_12: int32 = (cse_var_19 + 4)
              let cse_var_11: int32 = (cse_var_19 + 3)
              let cse_var_10: int32 = (cse_var_19 + 2)
              let cse_var_9: int32 = (cse_var_19 + 15)
              let cse_var_8: int32 = (cse_var_19 + 14)
              let cse_var_7: int32 = (cse_var_19 + 13)
              let cse_var_6: int32 = (cse_var_19 + 12)
              let cse_var_5: int32 = (cse_var_19 + 11)
              let cse_var_4: int32 = (cse_var_19 + 10)
              let cse_var_3: int32 = (cse_var_19 + 1)
               {
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13: Buffer(placeholder_9, float32, [25600], [])[((placeholder_12[cse_var_20]*256) + cse_var_21)]*placeholder_14: Buffer(placeholder_8, float32, [2359296], [])[(cse_var_18 + (placeholder_15: Buffer(placeholder_10, int32, [100], [])[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 1)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 2)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 3)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 4)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 5)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 6)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 7)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 8)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 9)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 10)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 11)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 12)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 13)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 14)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 15)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 16)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 17)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 18)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 19)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 20)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 21)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 22)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 23)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 24)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 25)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 26)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 27)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 28)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 29)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 30)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 31)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 32)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 33)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 34)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 35)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 36)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 37)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 38)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 39)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 40)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 41)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 42)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 43)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 44)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 45)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 46)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 47)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 48)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 49)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 50)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 51)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 52)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 53)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 54)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 55)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 56)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 57)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 58)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 59)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 60)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 61)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 62)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 63)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 64)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 65)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 66)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 67)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 68)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 69)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 70)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 71)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 72)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 73)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 74)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 75)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 76)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 77)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 78)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 79)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 80)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 81)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 82)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 83)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 84)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 85)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 86)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 87)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 88)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 89)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 90)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 91)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 92)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 93)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 94)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 95)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 96)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 97)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 98)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 99)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 100)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 101)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 102)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 103)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 104)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 105)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 106)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 107)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 108)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 109)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 110)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 111)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 112)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 113)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 114)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 115)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 116)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 117)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 118)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 119)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 120)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 121)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 122)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 123)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 124)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 125)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 126)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 127)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 128)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 129)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 130)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 131)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 132)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 133)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 134)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 135)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 136)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 137)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 138)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 139)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 140)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 141)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 142)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 143)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 144)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 145)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 146)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 147)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 148)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 149)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 150)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 151)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 152)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 153)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 154)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 155)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 156)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 157)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 158)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 159)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 160)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 161)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 162)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 163)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 164)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 165)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 166)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 167)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 168)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 169)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 170)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 171)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 172)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 173)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 174)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 175)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 176)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 177)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 178)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 179)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 180)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 181)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 182)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 183)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 184)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 185)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 186)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 187)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 188)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 189)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 190)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 191)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 192)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 193)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 194)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 195)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 196)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 197)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 198)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 199)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 200)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 201)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 202)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 203)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 204)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 205)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 206)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 207)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 208)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 209)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 210)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 211)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 212)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 213)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 214)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 215)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 216)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 217)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 218)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 219)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 220)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 221)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 222)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 223)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 224)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 225)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 226)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 227)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 228)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 229)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 230)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 231)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 232)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 233)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 234)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 235)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 236)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 237)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 238)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 239)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 240)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 241)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 242)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 243)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 244)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 245)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 246)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 247)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 248)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 249)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 250)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 251)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 252)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 253)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 254)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 255)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
              }
            }
          }
        }
      }
      for (m.inner: int32, 0, 6) {
        compute_5: Buffer(compute_2, float32, [589824], [])[ramp((((m.outer*4608) + (m.inner*768)) + (n.outer*48)), 1, 48)] = compute_4[ramp((m.inner*48), 1, 48)]
      }
    }
  }
}

----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
Custom sketch rule "SparseDense" added.
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 1800	fail_ct: 248	Time elapsed: 2.42
GA Iter: 0	Max score: 0.9993	Min score: 0.9217	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9877	#Pop: 128	#M+: 1370	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 9.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
(768, 768)
(768, 768)
encoder.layer.8.output.dense.weight Execution time of this operator: 0.092 ms
encoder.layer.9.intermediate.dense.weight: num_row = 3072, num_col = 768, nnz = 22482

==================================================
No: 1	GFLOPS: 9259.72 / 9259.72	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:1.46, Tstamp:1715258389.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,64)
      compute = ...

==================================================
No: 2	GFLOPS: 1324.79 / 9259.72	results: MeasureResult(cost:[0.0109], error_no:0, all_cost:0.98, Tstamp:1715258389.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 3	GFLOPS: 2360.93 / 9259.72	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.09, Tstamp:1715258390.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,768)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 4	GFLOPS: 21532.65 / 21532.65	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.58, Tstamp:1715258390.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 5	GFLOPS: 839.18 / 21532.65	results: MeasureResult(cost:[0.0173], error_no:0, all_cost:2.09, Tstamp:1715258391.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1024)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 6	GFLOPS: 3562.82 / 21532.65	results: MeasureResult(cost:[0.0041], error_no:0, all_cost:1.09, Tstamp:1715258391.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,512)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 7	GFLOPS: 5982.23 / 21532.65	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:1.14, Tstamp:1715258391.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 8	GFLOPS: 1592.09 / 21532.65	results: MeasureResult(cost:[0.0091], error_no:0, all_cost:0.89, Tstamp:1715258392.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,1536)
    compute = ...

==================================================
No: 9	GFLOPS: 2834.55 / 21532.65	results: MeasureResult(cost:[0.0051], error_no:0, all_cost:2.18, Tstamp:1715258392.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    for n.1 (0,8)
      compute = ...

==================================================
No: 10	GFLOPS: 28975.46 / 28975.46	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.24, Tstamp:1715258393.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,64)
      compute = ...

==================================================
No: 11	GFLOPS: 6239.02 / 28975.46	results: MeasureResult(cost:[0.0023], error_no:0, all_cost:1.45, Tstamp:1715258393.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 101), 96))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 5), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 12	GFLOPS: 21465.90 / 28975.46	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.45, Tstamp:1715258394.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,32)
      compute = ...

==================================================
No: 13	GFLOPS: 17489.08 / 28975.46	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.95, Tstamp:1715258394.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 14	GFLOPS: 6814.82 / 28975.46	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:1.27, Tstamp:1715258395.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 15	GFLOPS: 5720.21 / 28975.46	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:2.11, Tstamp:1715258395.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 16	GFLOPS: 22031.18 / 28975.46	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.14, Tstamp:1715258396.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1572864)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 17	GFLOPS: 11699.97 / 28975.46	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.17, Tstamp:1715258396.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,32)
      compute = ...

==================================================
No: 18	GFLOPS: 29258.16 / 29258.16	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.34, Tstamp:1715258397.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 19	GFLOPS: 582.75 / 29258.16	results: MeasureResult(cost:[0.0249], error_no:0, all_cost:1.00, Tstamp:1715258397.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 20	GFLOPS: 20671.13 / 29258.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.99, Tstamp:1715258398.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 21	GFLOPS: 607.33 / 29258.16	results: MeasureResult(cost:[0.0239], error_no:0, all_cost:1.99, Tstamp:1715258398.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 22	GFLOPS: 2269.62 / 29258.16	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.76, Tstamp:1715258399.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 23	GFLOPS: 1390.44 / 29258.16	results: MeasureResult(cost:[0.0104], error_no:0, all_cost:1.53, Tstamp:1715258399.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 24	GFLOPS: 3606.01 / 29258.16	results: MeasureResult(cost:[0.0040], error_no:0, all_cost:0.88, Tstamp:1715258400.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,3072)
    compute auto_unroll: 16
    for i.1 (0,96)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,96)
      compute = ...

==================================================
No: 25	GFLOPS: 3867.98 / 29258.16	results: MeasureResult(cost:[0.0037], error_no:0, all_cost:0.55, Tstamp:1715258400.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  for i.1 (0,32)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,512)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 26	GFLOPS: 13061.35 / 29258.16	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.93, Tstamp:1715258401.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1572864)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 27	GFLOPS: 9822.06 / 29258.16	results: MeasureResult(cost:[0.0015], error_no:0, all_cost:1.03, Tstamp:1715258401.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 28	GFLOPS: 2421.59 / 29258.16	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:1.04, Tstamp:1715258401.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,32)
      compute = ...

==================================================
No: 29	GFLOPS: 8782.94 / 29258.16	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:1.11, Tstamp:1715258402.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,32)
      compute = ...

==================================================
No: 30	GFLOPS: 1847.30 / 29258.16	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:1.30, Tstamp:1715258402.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,768)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 31	GFLOPS: 2973.48 / 29258.16	results: MeasureResult(cost:[0.0049], error_no:0, all_cost:1.03, Tstamp:1715258403.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 32	GFLOPS: 15495.16 / 29258.16	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.83, Tstamp:1715258403.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 33	GFLOPS: 2923.19 / 29258.16	results: MeasureResult(cost:[0.0050], error_no:0, all_cost:1.38, Tstamp:1715258404.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 34	GFLOPS: 1827.42 / 29258.16	results: MeasureResult(cost:[0.0079], error_no:0, all_cost:0.65, Tstamp:1715258404.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1024)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 35	GFLOPS: 19676.10 / 29258.16	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.02, Tstamp:1715258405.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 36	GFLOPS: 33722.45 / 33722.45	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.37, Tstamp:1715258405.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 37	GFLOPS: 29011.72 / 33722.45	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.48, Tstamp:1715258406.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 38	GFLOPS: 22174.35 / 33722.45	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.87, Tstamp:1715258406.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,32)
      compute = ...

==================================================
No: 39	GFLOPS: 25085.61 / 33722.45	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.21, Tstamp:1715258406.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 40	GFLOPS: 15503.93 / 33722.45	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.62, Tstamp:1715258407.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,24)
      compute = ...

==================================================
No: 41	GFLOPS: 4869.14 / 33722.45	results: MeasureResult(cost:[0.0030], error_no:0, all_cost:0.79, Tstamp:1715258408.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 42	GFLOPS: 4521.10 / 33722.45	results: MeasureResult(cost:[0.0032], error_no:0, all_cost:2.70, Tstamp:1715258408.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 43	GFLOPS: 3872.28 / 33722.45	results: MeasureResult(cost:[0.0037], error_no:0, all_cost:1.09, Tstamp:1715258409.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 44	GFLOPS: 1167.41 / 33722.45	results: MeasureResult(cost:[0.0124], error_no:0, all_cost:0.80, Tstamp:1715258409.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 45	GFLOPS: 2056.25 / 33722.45	results: MeasureResult(cost:[0.0070], error_no:0, all_cost:0.84, Tstamp:1715258409.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,256)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,1536)
    for n.1 (0,32)
      compute = ...

==================================================
No: 46	GFLOPS: 6518.53 / 33722.45	results: MeasureResult(cost:[0.0022], error_no:0, all_cost:0.70, Tstamp:1715258410.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 47	GFLOPS: 30638.91 / 33722.45	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.74, Tstamp:1715258410.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 48	GFLOPS: 18286.26 / 33722.45	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.67, Tstamp:1715258411.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 49	GFLOPS: 13155.10 / 33722.45	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.37, Tstamp:1715258411.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 50	GFLOPS: 44204.37 / 44204.37	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.10, Tstamp:1715258412.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 51	GFLOPS: 9442.87 / 44204.37	results: MeasureResult(cost:[0.0015], error_no:0, all_cost:0.69, Tstamp:1715258412.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 52	GFLOPS: 229.47 / 44204.37	results: MeasureResult(cost:[0.0632], error_no:0, all_cost:1.30, Tstamp:1715258413.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    for n.1 (0,2)
      compute = ...

==================================================
No: 53	GFLOPS: 2423.59 / 44204.37	results: MeasureResult(cost:[0.0060], error_no:0, all_cost:0.59, Tstamp:1715258413.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 54	GFLOPS: 8032.12 / 44204.37	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.87, Tstamp:1715258414.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 55	GFLOPS: 31713.59 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.67, Tstamp:1715258414.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 56	GFLOPS: 774.08 / 44204.37	results: MeasureResult(cost:[0.0187], error_no:0, all_cost:0.56, Tstamp:1715258415.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 57	GFLOPS: 2264.93 / 44204.37	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.54, Tstamp:1715258415.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    for n.1 (0,16)
      compute = ...

==================================================
No: 58	GFLOPS: 1586.13 / 44204.37	results: MeasureResult(cost:[0.0091], error_no:0, all_cost:1.15, Tstamp:1715258416.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 512
  for i.1 (0,1024)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3072)
    for n.1 (0,64)
      compute = ...

==================================================
No: 59	GFLOPS: 1130.40 / 44204.37	results: MeasureResult(cost:[0.0128], error_no:0, all_cost:0.57, Tstamp:1715258416.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  for i.1 (0,384)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3072)
    for n.1 (0,32)
      compute = ...

==================================================
No: 60	GFLOPS: 8477.04 / 44204.37	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.61, Tstamp:1715258416.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2359296)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,4)
    compute = ...

==================================================
No: 61	GFLOPS: 4096.26 / 44204.37	results: MeasureResult(cost:[0.0035], error_no:0, all_cost:0.55, Tstamp:1715258417.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2359296)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 62	GFLOPS: 1224.24 / 44204.37	results: MeasureResult(cost:[0.0118], error_no:0, all_cost:1.29, Tstamp:1715258417.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,384)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 63	GFLOPS: 4127.04 / 44204.37	results: MeasureResult(cost:[0.0035], error_no:0, all_cost:5.08, Tstamp:1715258418.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 64	GFLOPS: 13108.52 / 44204.37	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.23, Tstamp:1715258418.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

Time elapsed for measurement: 39.43 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.93 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1796	fail_ct: 252	Time elapsed: 2.41
GA Iter: 0	Max score: 0.9992	Min score: 0.9271	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9996	Min score: 0.9866	#Pop: 128	#M+: 1380	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 65	GFLOPS: 2822.39 / 44204.37	results: MeasureResult(cost:[0.0051], error_no:0, all_cost:1.02, Tstamp:1715258442.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,512)
    compute = ...

==================================================
No: 66	GFLOPS: 1958.71 / 44204.37	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:1.56, Tstamp:1715258443.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,192)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 67	GFLOPS: 177.00 / 44204.37	results: MeasureResult(cost:[0.0819], error_no:0, all_cost:1.48, Tstamp:1715258443.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,512)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 68	GFLOPS: 1391.07 / 44204.37	results: MeasureResult(cost:[0.0104], error_no:0, all_cost:1.83, Tstamp:1715258444.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 69	GFLOPS: 610.41 / 44204.37	results: MeasureResult(cost:[0.0237], error_no:0, all_cost:1.87, Tstamp:1715258444.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
for n.0 (0,48)
  compute auto_unroll: 512
  for i.1 (0,3072)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    for n.1 (0,64)
      compute = ...

==================================================
No: 70	GFLOPS: 3880.98 / 44204.37	results: MeasureResult(cost:[0.0037], error_no:0, all_cost:1.56, Tstamp:1715258445.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,512)
    for n.1 (0,48)
      compute = ...

==================================================
No: 71	GFLOPS: 185.18 / 44204.37	results: MeasureResult(cost:[0.0783], error_no:0, all_cost:1.03, Tstamp:1715258445.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,1536)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 72	GFLOPS: 4023.35 / 44204.37	results: MeasureResult(cost:[0.0036], error_no:0, all_cost:2.05, Tstamp:1715258446.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 73	GFLOPS: 5526.47 / 44204.37	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:1.58, Tstamp:1715258446.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 74	GFLOPS: 1053.52 / 44204.37	results: MeasureResult(cost:[0.0138], error_no:0, all_cost:1.39, Tstamp:1715258447.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 75	GFLOPS: 26718.20 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.20, Tstamp:1715258447.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 76	GFLOPS: 10533.35 / 44204.37	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:1.21, Tstamp:1715258447.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

==================================================
No: 77	GFLOPS: 1074.14 / 44204.37	results: MeasureResult(cost:[0.0135], error_no:0, all_cost:0.73, Tstamp:1715258448.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,512)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,3072)
    compute = ...

==================================================
No: 78	GFLOPS: 1962.89 / 44204.37	results: MeasureResult(cost:[0.0074], error_no:0, all_cost:0.88, Tstamp:1715258448.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,48)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 79	GFLOPS: 15929.16 / 44204.37	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.04, Tstamp:1715258449.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 80	GFLOPS: 16725.63 / 44204.37	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.09, Tstamp:1715258449.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,24)
      compute = ...

==================================================
No: 81	GFLOPS: 2373.56 / 44204.37	results: MeasureResult(cost:[0.0061], error_no:0, all_cost:1.19, Tstamp:1715258450.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    for n.1 (0,16)
      compute = ...

==================================================
No: 82	GFLOPS: 221.24 / 44204.37	results: MeasureResult(cost:[0.0655], error_no:0, all_cost:1.40, Tstamp:1715258450.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3072)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3072)
    for n.1 (0,2)
      compute = ...

==================================================
No: 83	GFLOPS: 19058.43 / 44204.37	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.25, Tstamp:1715258451.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 84	GFLOPS: 394.76 / 44204.37	results: MeasureResult(cost:[0.0367], error_no:0, all_cost:1.55, Tstamp:1715258451.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 85	GFLOPS: 23755.78 / 44204.37	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.72, Tstamp:1715258452.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,64)
      compute = ...

==================================================
No: 86	GFLOPS: 7534.67 / 44204.37	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:1.04, Tstamp:1715258452.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,48)
      compute = ...

==================================================
No: 87	GFLOPS: 299.72 / 44204.37	results: MeasureResult(cost:[0.0484], error_no:0, all_cost:1.14, Tstamp:1715258452.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 88	GFLOPS: 3068.33 / 44204.37	results: MeasureResult(cost:[0.0047], error_no:0, all_cost:0.85, Tstamp:1715258453.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 89	GFLOPS: 2093.60 / 44204.37	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.93, Tstamp:1715258453.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,1536)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    for n.1 (0,48)
      compute = ...

==================================================
No: 90	GFLOPS: 16647.68 / 44204.37	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.06, Tstamp:1715258454.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 91	GFLOPS: 173.89 / 44204.37	results: MeasureResult(cost:[0.0834], error_no:0, all_cost:0.95, Tstamp:1715258454.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 92	GFLOPS: 11895.89 / 44204.37	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.14, Tstamp:1715258455.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,128)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 93	GFLOPS: 1234.92 / 44204.37	results: MeasureResult(cost:[0.0117], error_no:0, all_cost:0.67, Tstamp:1715258455.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,32)
        for c (0,16)
          compute = ...
  for m.1 (0,1536)
    compute = ...

==================================================
No: 94	GFLOPS: 2103.93 / 44204.37	results: MeasureResult(cost:[0.0069], error_no:0, all_cost:0.79, Tstamp:1715258456.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 95	GFLOPS: 536.94 / 44204.37	results: MeasureResult(cost:[0.0270], error_no:0, all_cost:1.37, Tstamp:1715258456.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 101), 96))
    for i.1 (0,192)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 96	GFLOPS: 1492.30 / 44204.37	results: MeasureResult(cost:[0.0097], error_no:0, all_cost:0.75, Tstamp:1715258457.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,3072)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 97	GFLOPS: 25609.32 / 44204.37	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.00, Tstamp:1715258457.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 98	GFLOPS: 577.95 / 44204.37	results: MeasureResult(cost:[0.0251], error_no:0, all_cost:0.83, Tstamp:1715258458.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 99	GFLOPS: 1118.72 / 44204.37	results: MeasureResult(cost:[0.0130], error_no:0, all_cost:1.51, Tstamp:1715258458.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 100	GFLOPS: 3016.13 / 44204.37	results: MeasureResult(cost:[0.0048], error_no:0, all_cost:1.50, Tstamp:1715258458.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 101	GFLOPS: 36542.10 / 44204.37	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.94, Tstamp:1715258459.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 102	GFLOPS: 4340.24 / 44204.37	results: MeasureResult(cost:[0.0033], error_no:0, all_cost:0.83, Tstamp:1715258459.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 103	GFLOPS: 7681.47 / 44204.37	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.60, Tstamp:1715258460.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,24)
      compute = ...

==================================================
No: 104	GFLOPS: 2490.25 / 44204.37	results: MeasureResult(cost:[0.0058], error_no:0, all_cost:4.58, Tstamp:1715258460.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,16)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 105	GFLOPS: 1416.69 / 44204.37	results: MeasureResult(cost:[0.0102], error_no:0, all_cost:0.65, Tstamp:1715258461.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,768)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3072)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 106	GFLOPS: 7303.04 / 44204.37	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.62, Tstamp:1715258461.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 107	GFLOPS: 4274.86 / 44204.37	results: MeasureResult(cost:[0.0034], error_no:0, all_cost:2.63, Tstamp:1715258462.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,131072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    for n.1 (0,3)
      compute = ...

==================================================
No: 108	GFLOPS: 8564.51 / 44204.37	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.71, Tstamp:1715258462.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,64)
      compute = ...

==================================================
No: 109	GFLOPS: 27535.20 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.69, Tstamp:1715258463.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 110	GFLOPS: 31022.56 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.74, Tstamp:1715258463.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 111	GFLOPS: 1726.03 / 44204.37	results: MeasureResult(cost:[0.0084], error_no:0, all_cost:0.78, Tstamp:1715258463.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 112	GFLOPS: 1167.70 / 44204.37	results: MeasureResult(cost:[0.0124], error_no:0, all_cost:0.64, Tstamp:1715258464.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  for i.1 (0,64)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3072)
    for n.1 (0,32)
      compute = ...

==================================================
No: 113	GFLOPS: 8578.99 / 44204.37	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.71, Tstamp:1715258464.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,16)
      compute = ...

==================================================
No: 114	GFLOPS: 3728.94 / 44204.37	results: MeasureResult(cost:[0.0039], error_no:0, all_cost:0.57, Tstamp:1715258465.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 115	GFLOPS: 1819.90 / 44204.37	results: MeasureResult(cost:[0.0080], error_no:0, all_cost:0.56, Tstamp:1715258465.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for i.1 (0,1536)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    for n.1 (0,24)
      compute = ...

==================================================
No: 116	GFLOPS: 21736.87 / 44204.37	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.63, Tstamp:1715258466.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4718592)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 117	GFLOPS: 3417.39 / 44204.37	results: MeasureResult(cost:[0.0042], error_no:0, all_cost:0.71, Tstamp:1715258466.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,48)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 118	GFLOPS: 30583.45 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.70, Tstamp:1715258467.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,64)
    compute = ...

==================================================
No: 119	GFLOPS: 11728.36 / 44204.37	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.65, Tstamp:1715258467.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 120	GFLOPS: 3842.99 / 44204.37	results: MeasureResult(cost:[0.0038], error_no:0, all_cost:0.59, Tstamp:1715258468.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,262144)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 121	GFLOPS: 1381.36 / 44204.37	results: MeasureResult(cost:[0.0105], error_no:0, all_cost:1.03, Tstamp:1715258468.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,512)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 122	GFLOPS: 7491.86 / 44204.37	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.84, Tstamp:1715258469.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 101), 96))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 512)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 123	GFLOPS: 7111.09 / 44204.37	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:1.31, Tstamp:1715258469.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 124	GFLOPS: 1136.85 / 44204.37	results: MeasureResult(cost:[0.0128], error_no:0, all_cost:0.56, Tstamp:1715258469.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  for i.1 (0,1024)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3072)
    for n.1 (0,32)
      compute = ...

==================================================
No: 125	GFLOPS: 2278.63 / 44204.37	results: MeasureResult(cost:[0.0064], error_no:0, all_cost:0.63, Tstamp:1715258470.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 126	GFLOPS: 527.50 / 44204.37	results: MeasureResult(cost:[0.0275], error_no:0, all_cost:0.62, Tstamp:1715258470.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,1536)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 127	GFLOPS: 4693.91 / 44204.37	results: MeasureResult(cost:[0.0031], error_no:0, all_cost:0.75, Tstamp:1715258471.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 128	GFLOPS: 1159.25 / 44204.37	results: MeasureResult(cost:[0.0125], error_no:0, all_cost:1.08, Tstamp:1715258471.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 39.45 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.73 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1778	fail_ct: 270	Time elapsed: 2.46
GA Iter: 0	Max score: 0.9552	Min score: 0.5713	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9552	Min score: 0.8374	#Pop: 128	#M+: 1389	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 9.66
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 129	GFLOPS: 31570.08 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.86, Tstamp:1715258491.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 130	GFLOPS: 29824.75 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.08, Tstamp:1715258492.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 131	GFLOPS: 31375.35 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.18, Tstamp:1715258492.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 132	GFLOPS: 30800.70 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.97, Tstamp:1715258493.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 133	GFLOPS: 31303.56 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.16, Tstamp:1715258493.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 134	GFLOPS: 30750.88 / 44204.37	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.04, Tstamp:1715258494.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 135	GFLOPS: 20234.28 / 44204.37	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.68, Tstamp:1715258494.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 136	GFLOPS: 47940.79 / 47940.79	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.21, Tstamp:1715258495.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 137	GFLOPS: 48841.03 / 48841.03	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.10, Tstamp:1715258496.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 138	GFLOPS: 43614.19 / 48841.03	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.15, Tstamp:1715258496.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 139	GFLOPS: 33364.50 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.24, Tstamp:1715258497.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 140	GFLOPS: 33866.21 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.05, Tstamp:1715258497.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 141	GFLOPS: 34448.05 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.97, Tstamp:1715258498.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 142	GFLOPS: 22140.44 / 48841.03	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.87, Tstamp:1715258498.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 143	GFLOPS: 35044.17 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.21, Tstamp:1715258499.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 144	GFLOPS: 33885.31 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.97, Tstamp:1715258499.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 145	GFLOPS: 30937.21 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.31, Tstamp:1715258500.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 146	GFLOPS: 30621.94 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.05, Tstamp:1715258500.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 147	GFLOPS: 30056.01 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.08, Tstamp:1715258501.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 148	GFLOPS: 29564.66 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.08, Tstamp:1715258501.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 149	GFLOPS: 34808.89 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.52, Tstamp:1715258502.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 150	GFLOPS: 30052.48 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.28, Tstamp:1715258502.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 151	GFLOPS: 36055.24 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.71, Tstamp:1715258503.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 152	GFLOPS: 36662.23 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.69, Tstamp:1715258503.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 153	GFLOPS: 21286.15 / 48841.03	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.44, Tstamp:1715258504.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 154	GFLOPS: 33816.93 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.76, Tstamp:1715258504.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 155	GFLOPS: 34379.09 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.69, Tstamp:1715258505.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 156	GFLOPS: 33252.51 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.65, Tstamp:1715258505.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 157	GFLOPS: 35005.82 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.71, Tstamp:1715258505.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 158	GFLOPS: 30352.72 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.84, Tstamp:1715258506.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 159	GFLOPS: 31189.12 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.93, Tstamp:1715258507.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 160	GFLOPS: 30560.43 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.83, Tstamp:1715258507.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 161	GFLOPS: 31282.82 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.96, Tstamp:1715258508.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 162	GFLOPS: 30524.10 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.72, Tstamp:1715258508.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 163	GFLOPS: 36957.03 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.72, Tstamp:1715258509.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 164	GFLOPS: 30511.00 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.69, Tstamp:1715258509.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 165	GFLOPS: 31099.50 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.75, Tstamp:1715258510.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 166	GFLOPS: 30257.47 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.69, Tstamp:1715258510.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 167	GFLOPS: 30243.02 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.77, Tstamp:1715258511.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 168	GFLOPS: 30939.73 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.88, Tstamp:1715258511.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 169	GFLOPS: 33351.13 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.67, Tstamp:1715258512.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 170	GFLOPS: 36195.47 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.11, Tstamp:1715258512.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 171	GFLOPS: 32058.40 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.04, Tstamp:1715258513.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 172	GFLOPS: 32369.45 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.58, Tstamp:1715258513.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 173	GFLOPS: 33777.72 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.64, Tstamp:1715258514.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 174	GFLOPS: 30861.86 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.65, Tstamp:1715258514.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 175	GFLOPS: 30570.60 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.62, Tstamp:1715258514.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 176	GFLOPS: 34493.94 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.35, Tstamp:1715258515.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 177	GFLOPS: 36078.56 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.85, Tstamp:1715258516.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 178	GFLOPS: 29833.28 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.70, Tstamp:1715258516.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 179	GFLOPS: 29386.52 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.66, Tstamp:1715258517.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 180	GFLOPS: 32139.60 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.54, Tstamp:1715258517.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 181	GFLOPS: 34877.51 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.01, Tstamp:1715258517.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 182	GFLOPS: 30133.18 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.17, Tstamp:1715258518.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 183	GFLOPS: 29371.42 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.21, Tstamp:1715258518.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 184	GFLOPS: 27521.89 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.66, Tstamp:1715258519.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 185	GFLOPS: 38224.96 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.06, Tstamp:1715258519.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 186	GFLOPS: 32249.76 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.65, Tstamp:1715258520.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 187	GFLOPS: 27971.47 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.75, Tstamp:1715258521.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 188	GFLOPS: 33036.29 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.89, Tstamp:1715258521.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 189	GFLOPS: 27148.63 / 48841.03	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.67, Tstamp:1715258522.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 190	GFLOPS: 1367.80 / 48841.03	results: MeasureResult(cost:[0.0106], error_no:0, all_cost:1.29, Tstamp:1715258522.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3072)
    for n.1 (0,32)
      compute = ...

==================================================
No: 191	GFLOPS: 23883.38 / 48841.03	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.22, Tstamp:1715258522.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,393216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 192	GFLOPS: 1869.93 / 48841.03	results: MeasureResult(cost:[0.0078], error_no:0, all_cost:0.82, Tstamp:1715258523.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 38.70 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.71 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1795	fail_ct: 253	Time elapsed: 2.51
GA Iter: 0	Max score: 0.7718	Min score: 0.5053	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9325	Min score: 0.6621	#Pop: 128	#M+: 1385	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 9.88
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 193	GFLOPS: 22915.98 / 48841.03	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.49, Tstamp:1715258544.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 194	GFLOPS: 40674.67 / 48841.03	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.61, Tstamp:1715258544.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 195	GFLOPS: 50535.94 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.51, Tstamp:1715258545.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 196	GFLOPS: 41465.45 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.45, Tstamp:1715258545.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 197	GFLOPS: 44647.43 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.09, Tstamp:1715258546.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 198	GFLOPS: 38772.84 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.66, Tstamp:1715258546.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,32)
      compute = ...

==================================================
No: 199	GFLOPS: 44703.05 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.50, Tstamp:1715258547.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 200	GFLOPS: 27793.85 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.04, Tstamp:1715258547.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 201	GFLOPS: 34994.67 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.89, Tstamp:1715258548.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 202	GFLOPS: 42133.83 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.77, Tstamp:1715258548.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 203	GFLOPS: 47144.22 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.55, Tstamp:1715258549.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 204	GFLOPS: 46798.73 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.14, Tstamp:1715258549.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 205	GFLOPS: 43275.05 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.14, Tstamp:1715258550.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 206	GFLOPS: 42243.70 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.09, Tstamp:1715258550.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 207	GFLOPS: 42425.19 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.15, Tstamp:1715258551.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 208	GFLOPS: 18050.41 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.15, Tstamp:1715258551.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 209	GFLOPS: 20243.38 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.42, Tstamp:1715258552.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 210	GFLOPS: 38964.82 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.39, Tstamp:1715258552.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,32)
      compute = ...

==================================================
No: 211	GFLOPS: 43856.72 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.06, Tstamp:1715258553.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 212	GFLOPS: 43529.95 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.41, Tstamp:1715258553.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,32)
      compute = ...

==================================================
No: 213	GFLOPS: 43693.22 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.87, Tstamp:1715258554.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,64)
      compute = ...

==================================================
No: 214	GFLOPS: 20085.52 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.00, Tstamp:1715258554.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 215	GFLOPS: 19106.67 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.07, Tstamp:1715258555.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 216	GFLOPS: 40447.76 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.00, Tstamp:1715258555.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 217	GFLOPS: 39165.54 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.01, Tstamp:1715258556.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 218	GFLOPS: 20192.72 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.04, Tstamp:1715258556.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 219	GFLOPS: 22585.22 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.97, Tstamp:1715258557.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 220	GFLOPS: 36467.97 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.48, Tstamp:1715258557.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 221	GFLOPS: 35035.48 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.31, Tstamp:1715258558.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 222	GFLOPS: 47902.33 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.60, Tstamp:1715258558.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 223	GFLOPS: 46444.71 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.42, Tstamp:1715258559.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 224	GFLOPS: 43341.55 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.47, Tstamp:1715258559.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 225	GFLOPS: 41878.39 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.62, Tstamp:1715258560.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 226	GFLOPS: 33564.53 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.00, Tstamp:1715258560.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 227	GFLOPS: 43350.18 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.82, Tstamp:1715258561.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 228	GFLOPS: 33653.43 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.65, Tstamp:1715258561.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 229	GFLOPS: 19644.57 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.80, Tstamp:1715258562.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 230	GFLOPS: 21112.66 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.89, Tstamp:1715258562.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 231	GFLOPS: 19358.30 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.70, Tstamp:1715258563.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 232	GFLOPS: 27561.72 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.64, Tstamp:1715258563.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 233	GFLOPS: 44989.80 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.79, Tstamp:1715258564.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 234	GFLOPS: 34015.00 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.93, Tstamp:1715258564.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 235	GFLOPS: 36738.21 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.02, Tstamp:1715258565.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 236	GFLOPS: 35671.43 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.02, Tstamp:1715258565.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 237	GFLOPS: 36249.26 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.53, Tstamp:1715258566.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 238	GFLOPS: 34173.39 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.93, Tstamp:1715258566.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 239	GFLOPS: 35800.38 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.05, Tstamp:1715258567.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 240	GFLOPS: 35290.63 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.08, Tstamp:1715258567.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 241	GFLOPS: 36293.07 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.05, Tstamp:1715258568.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 242	GFLOPS: 35900.77 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.20, Tstamp:1715258568.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 243	GFLOPS: 34412.39 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.68, Tstamp:1715258569.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 244	GFLOPS: 36146.22 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.99, Tstamp:1715258569.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 245	GFLOPS: 25378.93 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.41, Tstamp:1715258570.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 246	GFLOPS: 25532.38 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.82, Tstamp:1715258570.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 247	GFLOPS: 30242.22 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.77, Tstamp:1715258571.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 248	GFLOPS: 30485.18 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.77, Tstamp:1715258571.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 249	GFLOPS: 17099.55 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.58, Tstamp:1715258572.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 250	GFLOPS: 32212.55 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.65, Tstamp:1715258572.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 251	GFLOPS: 37202.07 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.50, Tstamp:1715258573.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 252	GFLOPS: 44453.81 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.37, Tstamp:1715258573.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 253	GFLOPS: 34691.58 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.13, Tstamp:1715258574.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 254	GFLOPS: 28363.47 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.83, Tstamp:1715258574.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,32)
      compute = ...

==================================================
No: 255	GFLOPS: 3756.17 / 50535.94	results: MeasureResult(cost:[0.0039], error_no:0, all_cost:0.56, Tstamp:1715258575.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 256	GFLOPS: 1820.10 / 50535.94	results: MeasureResult(cost:[0.0080], error_no:0, all_cost:0.73, Tstamp:1715258575.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,1024)
    for n.1 (0,32)
      compute = ...

Time elapsed for measurement: 38.88 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.77 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1805	fail_ct: 243	Time elapsed: 2.53
GA Iter: 0	Max score: 0.8196	Min score: 0.4935	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8742	Min score: 0.6621	#Pop: 128	#M+: 1379	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 9.91
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 257	GFLOPS: 22808.34 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.84, Tstamp:1715258596.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 258	GFLOPS: 41381.65 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.81, Tstamp:1715258597.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 259	GFLOPS: 45588.24 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.72, Tstamp:1715258597.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 260	GFLOPS: 40407.19 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.70, Tstamp:1715258597.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 261	GFLOPS: 46663.01 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.44, Tstamp:1715258598.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 262	GFLOPS: 40271.24 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.48, Tstamp:1715258598.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 263	GFLOPS: 40649.18 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.53, Tstamp:1715258599.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 264	GFLOPS: 45706.14 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.82, Tstamp:1715258599.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 265	GFLOPS: 29669.74 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.11, Tstamp:1715258600.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 266	GFLOPS: 41135.75 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.32, Tstamp:1715258600.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 267	GFLOPS: 41010.55 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.93, Tstamp:1715258601.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 268	GFLOPS: 43844.22 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.61, Tstamp:1715258601.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 269	GFLOPS: 29348.03 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.11, Tstamp:1715258602.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,32)
      compute = ...

==================================================
No: 270	GFLOPS: 40708.52 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.08, Tstamp:1715258602.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 271	GFLOPS: 29611.16 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.41, Tstamp:1715258603.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,32)
      compute = ...

==================================================
No: 272	GFLOPS: 46734.53 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.38, Tstamp:1715258603.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,64)
      compute = ...

==================================================
No: 273	GFLOPS: 44313.29 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.23, Tstamp:1715258604.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 274	GFLOPS: 40254.11 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.21, Tstamp:1715258604.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 275	GFLOPS: 38351.28 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.54, Tstamp:1715258605.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 276	GFLOPS: 42628.26 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.06, Tstamp:1715258606.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 277	GFLOPS: 34091.57 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.80, Tstamp:1715258606.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 278	GFLOPS: 47002.11 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.73, Tstamp:1715258606.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 279	GFLOPS: 28925.27 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.97, Tstamp:1715258607.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,32)
      compute = ...

==================================================
No: 280	GFLOPS: 41140.91 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.89, Tstamp:1715258607.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 281	GFLOPS: 35252.12 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.92, Tstamp:1715258608.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 282	GFLOPS: 45432.61 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.88, Tstamp:1715258608.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 283	GFLOPS: 39682.25 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.58, Tstamp:1715258609.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 284	GFLOPS: 36997.67 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.64, Tstamp:1715258609.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 285	GFLOPS: 40681.95 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.54, Tstamp:1715258610.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 286	GFLOPS: 42013.36 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.73, Tstamp:1715258610.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,64)
      compute = ...

==================================================
No: 287	GFLOPS: 40274.43 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.65, Tstamp:1715258611.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 288	GFLOPS: 32776.32 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.39, Tstamp:1715258611.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 289	GFLOPS: 42963.53 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.67, Tstamp:1715258612.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 290	GFLOPS: 43317.07 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.67, Tstamp:1715258612.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,64)
      compute = ...

==================================================
No: 291	GFLOPS: 29621.79 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.71, Tstamp:1715258613.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 292	GFLOPS: 29897.84 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.53, Tstamp:1715258613.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 293	GFLOPS: 32918.23 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.44, Tstamp:1715258614.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 294	GFLOPS: 35200.85 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.07, Tstamp:1715258614.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 295	GFLOPS: 35733.94 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.42, Tstamp:1715258615.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 296	GFLOPS: 46646.60 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.64, Tstamp:1715258615.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,64)
      compute = ...

==================================================
No: 297	GFLOPS: 48996.77 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.62, Tstamp:1715258616.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 298	GFLOPS: 43173.09 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.75, Tstamp:1715258616.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 299	GFLOPS: 27094.72 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.45, Tstamp:1715258617.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 300	GFLOPS: 31844.99 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.58, Tstamp:1715258617.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 301	GFLOPS: 40034.67 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.36, Tstamp:1715258618.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 302	GFLOPS: 36511.04 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.48, Tstamp:1715258618.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 303	GFLOPS: 40053.83 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.45, Tstamp:1715258619.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,64)
      compute = ...

==================================================
No: 304	GFLOPS: 31348.73 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.61, Tstamp:1715258619.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 305	GFLOPS: 36169.81 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.68, Tstamp:1715258620.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 306	GFLOPS: 34108.97 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.92, Tstamp:1715258620.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 307	GFLOPS: 34361.14 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.59, Tstamp:1715258621.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 308	GFLOPS: 32723.39 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.68, Tstamp:1715258621.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 309	GFLOPS: 34463.72 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.33, Tstamp:1715258622.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 310	GFLOPS: 28500.35 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.53, Tstamp:1715258622.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 311	GFLOPS: 30956.02 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.76, Tstamp:1715258623.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 312	GFLOPS: 35833.56 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.37, Tstamp:1715258623.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 313	GFLOPS: 32753.91 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.94, Tstamp:1715258624.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 314	GFLOPS: 29273.88 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.49, Tstamp:1715258624.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,32)
      compute = ...

==================================================
No: 315	GFLOPS: 34186.88 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.68, Tstamp:1715258625.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 316	GFLOPS: 36882.11 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.27, Tstamp:1715258625.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 317	GFLOPS: 30733.08 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.67, Tstamp:1715258626.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 318	GFLOPS: 2677.70 / 50535.94	results: MeasureResult(cost:[0.0054], error_no:0, all_cost:1.01, Tstamp:1715258626.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 319	GFLOPS: 5083.44 / 50535.94	results: MeasureResult(cost:[0.0029], error_no:0, all_cost:0.66, Tstamp:1715258627.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,24)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 320	GFLOPS: 14577.10 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.96, Tstamp:1715258627.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,64)
      compute = ...

Time elapsed for measurement: 38.96 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.96 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 257	Time elapsed: 2.54
GA Iter: 0	Max score: 0.8136	Min score: 0.4421	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8336	Min score: 0.6408	#Pop: 128	#M+: 1373	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 9.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 321	GFLOPS: 45548.83 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.14, Tstamp:1715258648.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 322	GFLOPS: 42437.69 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.73, Tstamp:1715258649.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 323	GFLOPS: 39712.37 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.08, Tstamp:1715258649.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 324	GFLOPS: 21139.45 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.57, Tstamp:1715258650.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 325	GFLOPS: 31767.14 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.56, Tstamp:1715258650.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 326	GFLOPS: 43689.56 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.75, Tstamp:1715258651.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 327	GFLOPS: 38745.68 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.52, Tstamp:1715258651.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 328	GFLOPS: 30587.23 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.62, Tstamp:1715258652.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 329	GFLOPS: 36608.24 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.35, Tstamp:1715258652.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 330	GFLOPS: 43374.41 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.39, Tstamp:1715258653.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 331	GFLOPS: 32042.67 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.47, Tstamp:1715258653.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 332	GFLOPS: 43147.63 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.38, Tstamp:1715258654.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 333	GFLOPS: 34905.23 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.97, Tstamp:1715258654.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 334	GFLOPS: 35498.16 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.33, Tstamp:1715258655.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 335	GFLOPS: 34638.10 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.71, Tstamp:1715258655.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 336	GFLOPS: 38318.62 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.11, Tstamp:1715258656.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 337	GFLOPS: 28400.42 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.98, Tstamp:1715258656.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,32)
      compute = ...

==================================================
No: 338	GFLOPS: 34735.20 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.21, Tstamp:1715258656.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 339	GFLOPS: 33745.77 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.55, Tstamp:1715258657.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 340	GFLOPS: 33639.12 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.90, Tstamp:1715258657.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 341	GFLOPS: 34093.18 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.62, Tstamp:1715258658.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 342	GFLOPS: 34968.93 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.28, Tstamp:1715258658.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,32)
      compute = ...

==================================================
No: 343	GFLOPS: 33910.61 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.07, Tstamp:1715258659.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 344	GFLOPS: 33873.45 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.05, Tstamp:1715258659.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 345	GFLOPS: 34731.89 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.15, Tstamp:1715258660.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 346	GFLOPS: 33544.60 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.48, Tstamp:1715258660.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 347	GFLOPS: 31643.50 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.58, Tstamp:1715258661.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 348	GFLOPS: 36327.32 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.44, Tstamp:1715258661.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 349	GFLOPS: 44461.88 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.70, Tstamp:1715258662.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 350	GFLOPS: 33297.77 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.28, Tstamp:1715258662.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 351	GFLOPS: 36037.58 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.32, Tstamp:1715258663.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,64)
      compute = ...

==================================================
No: 352	GFLOPS: 32216.64 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.40, Tstamp:1715258663.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,32)
      compute = ...

==================================================
No: 353	GFLOPS: 36168.29 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.32, Tstamp:1715258664.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 354	GFLOPS: 38757.70 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.62, Tstamp:1715258664.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 355	GFLOPS: 34542.13 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.10, Tstamp:1715258665.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 356	GFLOPS: 35188.22 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.11, Tstamp:1715258665.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 357	GFLOPS: 36187.19 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.01, Tstamp:1715258666.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 358	GFLOPS: 32316.92 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.67, Tstamp:1715258666.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 359	GFLOPS: 33906.53 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.31, Tstamp:1715258667.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,32)
      compute = ...

==================================================
No: 360	GFLOPS: 42264.00 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.63, Tstamp:1715258667.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 361	GFLOPS: 32796.11 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.56, Tstamp:1715258668.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 362	GFLOPS: 32775.83 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.32, Tstamp:1715258668.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 363	GFLOPS: 35357.23 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.42, Tstamp:1715258669.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 364	GFLOPS: 33464.17 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.38, Tstamp:1715258669.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 365	GFLOPS: 35475.99 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.14, Tstamp:1715258670.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 366	GFLOPS: 34098.23 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.08, Tstamp:1715258670.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 367	GFLOPS: 33917.93 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.69, Tstamp:1715258671.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 368	GFLOPS: 34053.83 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.59, Tstamp:1715258671.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 369	GFLOPS: 34776.04 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.96, Tstamp:1715258672.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 370	GFLOPS: 33922.59 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.90, Tstamp:1715258672.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 371	GFLOPS: 36873.31 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.03, Tstamp:1715258673.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 372	GFLOPS: 35844.67 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.99, Tstamp:1715258673.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 373	GFLOPS: 32004.74 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.29, Tstamp:1715258674.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 374	GFLOPS: 25110.95 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.64, Tstamp:1715258674.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 375	GFLOPS: 34866.33 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.28, Tstamp:1715258675.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,64)
      compute = ...

==================================================
No: 376	GFLOPS: 30553.62 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.73, Tstamp:1715258675.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 377	GFLOPS: 30878.04 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.69, Tstamp:1715258676.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 378	GFLOPS: 33548.20 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.65, Tstamp:1715258676.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 379	GFLOPS: 29233.19 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.76, Tstamp:1715258677.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 380	GFLOPS: 35214.89 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.95, Tstamp:1715258677.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 381	GFLOPS: 33810.84 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715258678.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 382	GFLOPS: 7709.01 / 50535.94	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:0.62, Tstamp:1715258678.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 383	GFLOPS: 15462.46 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.92, Tstamp:1715258679.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 384	GFLOPS: 8263.55 / 50535.94	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:1.08, Tstamp:1715258679.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,256)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,48)
      compute = ...

Time elapsed for measurement: 38.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.84 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 254	Time elapsed: 2.54
GA Iter: 0	Max score: 0.7787	Min score: 0.4135	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8468	Min score: 0.6284	#Pop: 128	#M+: 1381	#M-: 68
EvolutionarySearch		#s: 128	Time elapsed: 10.04
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 385	GFLOPS: 23246.57 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.41, Tstamp:1715258701.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 386	GFLOPS: 40387.96 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.32, Tstamp:1715258702.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 387	GFLOPS: 41751.59 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.73, Tstamp:1715258702.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 388	GFLOPS: 49134.71 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.43, Tstamp:1715258703.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 389	GFLOPS: 45760.80 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.07, Tstamp:1715258703.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 390	GFLOPS: 36134.16 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.82, Tstamp:1715258704.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 391	GFLOPS: 36051.76 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.91, Tstamp:1715258704.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,64)
        compute = ...

==================================================
No: 392	GFLOPS: 34038.82 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.29, Tstamp:1715258705.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 393	GFLOPS: 43290.62 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.19, Tstamp:1715258705.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 394	GFLOPS: 43027.66 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.96, Tstamp:1715258706.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 395	GFLOPS: 30435.33 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:3.41, Tstamp:1715258706.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 396	GFLOPS: 43614.46 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.28, Tstamp:1715258707.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 397	GFLOPS: 35536.08 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.76, Tstamp:1715258707.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 398	GFLOPS: 33940.51 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.78, Tstamp:1715258708.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 399	GFLOPS: 49430.37 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.68, Tstamp:1715258708.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 400	GFLOPS: 45302.27 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.29, Tstamp:1715258709.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 401	GFLOPS: 35703.07 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.13, Tstamp:1715258709.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 402	GFLOPS: 33953.02 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.58, Tstamp:1715258710.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,64)
        compute = ...

==================================================
No: 403	GFLOPS: 25765.58 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.17, Tstamp:1715258710.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 404	GFLOPS: 48582.52 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.22, Tstamp:1715258711.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 405	GFLOPS: 35778.30 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.29, Tstamp:1715258711.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 406	GFLOPS: 36826.98 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.66, Tstamp:1715258712.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,64)
        compute = ...

==================================================
No: 407	GFLOPS: 36187.50 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.57, Tstamp:1715258712.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 408	GFLOPS: 28810.38 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.68, Tstamp:1715258713.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 409	GFLOPS: 34434.17 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.83, Tstamp:1715258713.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 410	GFLOPS: 36824.00 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.20, Tstamp:1715258714.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 411	GFLOPS: 31796.27 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.83, Tstamp:1715258714.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 412	GFLOPS: 32853.18 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.57, Tstamp:1715258715.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,64)
        compute = ...

==================================================
No: 413	GFLOPS: 31124.83 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.79, Tstamp:1715258715.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 414	GFLOPS: 45838.97 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.08, Tstamp:1715258716.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 415	GFLOPS: 34832.48 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.19, Tstamp:1715258716.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 416	GFLOPS: 45242.93 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.85, Tstamp:1715258717.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 417	GFLOPS: 47427.37 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.65, Tstamp:1715258717.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 418	GFLOPS: 18941.02 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.98, Tstamp:1715258718.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 419	GFLOPS: 36761.76 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.43, Tstamp:1715258718.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 420	GFLOPS: 35478.66 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.28, Tstamp:1715258719.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 421	GFLOPS: 30636.81 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.56, Tstamp:1715258719.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 422	GFLOPS: 36246.79 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.93, Tstamp:1715258720.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 423	GFLOPS: 33663.20 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.66, Tstamp:1715258720.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 424	GFLOPS: 26372.67 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.66, Tstamp:1715258721.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 425	GFLOPS: 30824.85 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.05, Tstamp:1715258721.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 426	GFLOPS: 34836.39 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.38, Tstamp:1715258722.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 427	GFLOPS: 41035.01 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.39, Tstamp:1715258722.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 428	GFLOPS: 33336.66 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.65, Tstamp:1715258723.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,64)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 429	GFLOPS: 44694.57 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.47, Tstamp:1715258723.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 430	GFLOPS: 29615.30 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.08, Tstamp:1715258724.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 431	GFLOPS: 27956.91 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.70, Tstamp:1715258724.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 432	GFLOPS: 39145.18 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.94, Tstamp:1715258725.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 433	GFLOPS: 33475.39 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715258725.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 434	GFLOPS: 38968.85 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.79, Tstamp:1715258726.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 435	GFLOPS: 31288.96 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.53, Tstamp:1715258726.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 436	GFLOPS: 34980.26 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.09, Tstamp:1715258727.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,64)
      compute = ...

==================================================
No: 437	GFLOPS: 31557.87 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.31, Tstamp:1715258727.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 438	GFLOPS: 41500.43 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.33, Tstamp:1715258728.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 439	GFLOPS: 33853.90 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.32, Tstamp:1715258728.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 440	GFLOPS: 26574.50 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.95, Tstamp:1715258729.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 441	GFLOPS: 26515.23 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.42, Tstamp:1715258729.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,32)
      compute = ...

==================================================
No: 442	GFLOPS: 40558.08 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.28, Tstamp:1715258730.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 443	GFLOPS: 32441.70 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.57, Tstamp:1715258730.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,32)
    compute = ...

==================================================
No: 444	GFLOPS: 15869.45 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.63, Tstamp:1715258731.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 445	GFLOPS: 31296.49 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.51, Tstamp:1715258731.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 446	GFLOPS: 30482.32 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.89, Tstamp:1715258732.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 447	GFLOPS: 16164.49 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.59, Tstamp:1715258732.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,786432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 448	GFLOPS: 2295.33 / 50535.94	results: MeasureResult(cost:[0.0063], error_no:0, all_cost:0.55, Tstamp:1715258732.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 39.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.90 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1795	fail_ct: 253	Time elapsed: 2.47
GA Iter: 0	Max score: 0.6648	Min score: 0.4465	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9757	Min score: 0.7296	#Pop: 128	#M+: 1386	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 9.99
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 449	GFLOPS: 26294.28 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.87, Tstamp:1715258754.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 450	GFLOPS: 43137.21 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.26, Tstamp:1715258754.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 451	GFLOPS: 39614.69 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.44, Tstamp:1715258755.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 452	GFLOPS: 40383.13 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.68, Tstamp:1715258755.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 453	GFLOPS: 35524.27 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.22, Tstamp:1715258756.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 454	GFLOPS: 30080.78 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.02, Tstamp:1715258756.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 455	GFLOPS: 36045.88 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.98, Tstamp:1715258757.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 456	GFLOPS: 19007.64 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.41, Tstamp:1715258757.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 457	GFLOPS: 34269.54 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.60, Tstamp:1715258758.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 458	GFLOPS: 30719.29 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.33, Tstamp:1715258759.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 459	GFLOPS: 42778.51 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.47, Tstamp:1715258759.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 460	GFLOPS: 40626.74 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.29, Tstamp:1715258760.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 461	GFLOPS: 30531.49 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.34, Tstamp:1715258760.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 462	GFLOPS: 32242.27 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.07, Tstamp:1715258761.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 463	GFLOPS: 29443.15 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.15, Tstamp:1715258761.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 464	GFLOPS: 31242.93 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.18, Tstamp:1715258762.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 465	GFLOPS: 28831.77 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.42, Tstamp:1715258762.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 466	GFLOPS: 28155.79 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.39, Tstamp:1715258763.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 467	GFLOPS: 29663.83 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.12, Tstamp:1715258763.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 468	GFLOPS: 30347.95 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.93, Tstamp:1715258764.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 469	GFLOPS: 26377.01 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.04, Tstamp:1715258764.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 470	GFLOPS: 29799.51 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.13, Tstamp:1715258765.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 471	GFLOPS: 25847.89 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.21, Tstamp:1715258765.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 472	GFLOPS: 22406.41 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.00, Tstamp:1715258766.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 473	GFLOPS: 20867.34 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.06, Tstamp:1715258767.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 474	GFLOPS: 32811.60 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.85, Tstamp:1715258767.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 475	GFLOPS: 29322.73 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.83, Tstamp:1715258768.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 476	GFLOPS: 36409.58 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.73, Tstamp:1715258768.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 477	GFLOPS: 27179.69 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.89, Tstamp:1715258769.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 478	GFLOPS: 25139.00 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.96, Tstamp:1715258769.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 479	GFLOPS: 25914.94 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.62, Tstamp:1715258770.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 480	GFLOPS: 27206.41 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.85, Tstamp:1715258770.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 481	GFLOPS: 34757.55 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.59, Tstamp:1715258771.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 482	GFLOPS: 31019.36 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.90, Tstamp:1715258771.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 483	GFLOPS: 33010.65 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.85, Tstamp:1715258772.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 484	GFLOPS: 23185.93 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.10, Tstamp:1715258772.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,96)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 485	GFLOPS: 32767.03 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.34, Tstamp:1715258773.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 486	GFLOPS: 32704.33 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.78, Tstamp:1715258773.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 487	GFLOPS: 29778.17 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.88, Tstamp:1715258774.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 488	GFLOPS: 34432.47 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.12, Tstamp:1715258774.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 489	GFLOPS: 38330.01 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.73, Tstamp:1715258775.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 490	GFLOPS: 23593.99 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.36, Tstamp:1715258775.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 491	GFLOPS: 37266.13 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.29, Tstamp:1715258776.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 492	GFLOPS: 33303.70 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.61, Tstamp:1715258776.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 493	GFLOPS: 39641.12 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.57, Tstamp:1715258777.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 494	GFLOPS: 43824.73 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.76, Tstamp:1715258777.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 495	GFLOPS: 25347.49 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.80, Tstamp:1715258778.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,64)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 496	GFLOPS: 29325.54 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.66, Tstamp:1715258778.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 497	GFLOPS: 21075.21 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.71, Tstamp:1715258779.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 498	GFLOPS: 18562.15 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.04, Tstamp:1715258779.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 499	GFLOPS: 28712.40 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.75, Tstamp:1715258780.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 500	GFLOPS: 28145.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.65, Tstamp:1715258780.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 501	GFLOPS: 20377.75 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.15, Tstamp:1715258781.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 502	GFLOPS: 33008.76 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.40, Tstamp:1715258781.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 503	GFLOPS: 22583.10 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.93, Tstamp:1715258782.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 504	GFLOPS: 26148.60 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.65, Tstamp:1715258782.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 505	GFLOPS: 32535.42 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.95, Tstamp:1715258783.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 506	GFLOPS: 30437.77 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.84, Tstamp:1715258783.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 507	GFLOPS: 19620.43 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.71, Tstamp:1715258784.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,12)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 508	GFLOPS: 34505.42 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.49, Tstamp:1715258784.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 509	GFLOPS: 30445.77 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.58, Tstamp:1715258785.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,192)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 510	GFLOPS: 3947.19 / 50535.94	results: MeasureResult(cost:[0.0037], error_no:0, all_cost:0.53, Tstamp:1715258785.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,786432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 511	GFLOPS: 4622.57 / 50535.94	results: MeasureResult(cost:[0.0031], error_no:0, all_cost:1.20, Tstamp:1715258785.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 512	GFLOPS: 5155.76 / 50535.94	results: MeasureResult(cost:[0.0028], error_no:0, all_cost:0.75, Tstamp:1715258786.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 3072), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 3072), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

Time elapsed for measurement: 40.03 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.05 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1767	fail_ct: 281	Time elapsed: 2.52
GA Iter: 0	Max score: 0.7558	Min score: 0.4391	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8541	Min score: 0.6498	#Pop: 128	#M+: 1377	#M-: 76
EvolutionarySearch		#s: 128	Time elapsed: 10.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 513	GFLOPS: 23590.43 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.80, Tstamp:1715258808.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 514	GFLOPS: 39400.55 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.84, Tstamp:1715258808.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 515	GFLOPS: 39839.40 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.17, Tstamp:1715258809.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 516	GFLOPS: 34034.64 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.07, Tstamp:1715258809.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 517	GFLOPS: 45366.46 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.05, Tstamp:1715258810.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 518	GFLOPS: 45149.12 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.90, Tstamp:1715258810.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 519	GFLOPS: 37874.48 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.17, Tstamp:1715258811.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 520	GFLOPS: 29427.46 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:3.46, Tstamp:1715258811.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 521	GFLOPS: 42354.38 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.83, Tstamp:1715258812.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 522	GFLOPS: 39494.57 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.26, Tstamp:1715258812.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 523	GFLOPS: 30422.95 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.78, Tstamp:1715258813.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 524	GFLOPS: 43863.80 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.79, Tstamp:1715258813.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 525	GFLOPS: 36805.01 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.25, Tstamp:1715258814.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 526	GFLOPS: 40804.65 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.72, Tstamp:1715258814.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 527	GFLOPS: 41423.13 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.32, Tstamp:1715258815.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 528	GFLOPS: 39827.68 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.25, Tstamp:1715258815.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 529	GFLOPS: 41222.82 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.60, Tstamp:1715258816.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 530	GFLOPS: 41843.02 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.34, Tstamp:1715258816.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 531	GFLOPS: 44319.42 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.38, Tstamp:1715258817.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 532	GFLOPS: 23771.06 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.25, Tstamp:1715258817.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,64)
        compute = ...

==================================================
No: 533	GFLOPS: 42490.30 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.21, Tstamp:1715258818.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,64)
      compute = ...

==================================================
No: 534	GFLOPS: 33619.17 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.91, Tstamp:1715258818.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 535	GFLOPS: 32302.34 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.11, Tstamp:1715258819.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 536	GFLOPS: 32586.86 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.97, Tstamp:1715258819.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      for n.1 (0,16)
        compute = ...

==================================================
No: 537	GFLOPS: 41196.83 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.46, Tstamp:1715258820.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 538	GFLOPS: 42013.62 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.16, Tstamp:1715258820.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 539	GFLOPS: 26131.54 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.18, Tstamp:1715258821.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 540	GFLOPS: 36652.73 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.50, Tstamp:1715258821.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 541	GFLOPS: 37111.43 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.49, Tstamp:1715258822.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 542	GFLOPS: 33812.45 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.73, Tstamp:1715258822.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 543	GFLOPS: 30699.57 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.28, Tstamp:1715258823.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,64)
      compute = ...

==================================================
No: 544	GFLOPS: 26465.56 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.56, Tstamp:1715258823.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 545	GFLOPS: 39699.40 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.36, Tstamp:1715258824.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 546	GFLOPS: 29648.44 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.39, Tstamp:1715258824.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,32)
        compute = ...

==================================================
No: 547	GFLOPS: 35280.59 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.89, Tstamp:1715258825.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 548	GFLOPS: 36301.18 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.20, Tstamp:1715258825.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 549	GFLOPS: 32186.62 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.15, Tstamp:1715258826.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 550	GFLOPS: 28468.53 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.98, Tstamp:1715258826.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,32)
        compute = ...

==================================================
No: 551	GFLOPS: 40786.07 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.80, Tstamp:1715258827.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 552	GFLOPS: 34301.26 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.09, Tstamp:1715258827.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,64)
      compute = ...

==================================================
No: 553	GFLOPS: 25830.01 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.19, Tstamp:1715258828.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 554	GFLOPS: 33292.10 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.97, Tstamp:1715258829.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 555	GFLOPS: 32558.06 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.07, Tstamp:1715258829.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 556	GFLOPS: 29155.59 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.53, Tstamp:1715258829.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      for n.1 (0,16)
        compute = ...

==================================================
No: 557	GFLOPS: 33276.16 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.99, Tstamp:1715258830.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 558	GFLOPS: 35650.89 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.09, Tstamp:1715258830.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 559	GFLOPS: 34027.92 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.69, Tstamp:1715258831.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 560	GFLOPS: 32750.19 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.64, Tstamp:1715258831.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 561	GFLOPS: 32514.74 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.77, Tstamp:1715258832.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 562	GFLOPS: 33819.50 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.70, Tstamp:1715258832.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 563	GFLOPS: 22476.41 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.56, Tstamp:1715258833.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 564	GFLOPS: 39232.19 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.68, Tstamp:1715258834.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 565	GFLOPS: 30979.25 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.43, Tstamp:1715258834.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 566	GFLOPS: 33742.45 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.50, Tstamp:1715258835.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,64)
      compute = ...

==================================================
No: 567	GFLOPS: 33448.52 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.58, Tstamp:1715258835.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 568	GFLOPS: 30296.51 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.39, Tstamp:1715258835.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,32)
      compute = ...

==================================================
No: 569	GFLOPS: 41158.34 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.05, Tstamp:1715258836.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 570	GFLOPS: 32735.63 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.71, Tstamp:1715258836.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 571	GFLOPS: 29099.71 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.99, Tstamp:1715258837.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      for n.1 (0,32)
        compute = ...

==================================================
No: 572	GFLOPS: 31565.60 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.68, Tstamp:1715258837.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 573	GFLOPS: 31930.40 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.55, Tstamp:1715258838.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 574	GFLOPS: 5804.68 / 50535.94	results: MeasureResult(cost:[0.0025], error_no:0, all_cost:1.49, Tstamp:1715258838.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,32)
      compute = ...

==================================================
No: 575	GFLOPS: 24459.90 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.85, Tstamp:1715258839.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,32)
      compute = ...

==================================================
No: 576	GFLOPS: 11638.81 / 50535.94	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.73, Tstamp:1715258839.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,12)
      compute = ...

Time elapsed for measurement: 39.84 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.15 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1791	fail_ct: 257	Time elapsed: 2.53
GA Iter: 0	Max score: 0.6905	Min score: 0.4544	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8876	Min score: 0.6450	#Pop: 128	#M+: 1396	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 9.97
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 577	GFLOPS: 25550.19 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.83, Tstamp:1715258862.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 578	GFLOPS: 41092.09 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.70, Tstamp:1715258863.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 579	GFLOPS: 31002.84 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:3.17, Tstamp:1715258863.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 580	GFLOPS: 37448.94 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.81, Tstamp:1715258864.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 581	GFLOPS: 36060.36 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.21, Tstamp:1715258864.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 582	GFLOPS: 43183.68 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.45, Tstamp:1715258865.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 583	GFLOPS: 43391.71 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.87, Tstamp:1715258865.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 584	GFLOPS: 33893.29 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.20, Tstamp:1715258865.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,32)
      compute = ...

==================================================
No: 585	GFLOPS: 36716.50 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.92, Tstamp:1715258866.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 586	GFLOPS: 34058.18 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.62, Tstamp:1715258867.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,64)
      compute = ...

==================================================
No: 587	GFLOPS: 31502.41 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.60, Tstamp:1715258867.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 588	GFLOPS: 31403.23 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.28, Tstamp:1715258868.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 589	GFLOPS: 44349.12 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.81, Tstamp:1715258868.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,64)
        compute = ...

==================================================
No: 590	GFLOPS: 43984.98 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.64, Tstamp:1715258869.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,64)
        compute = ...

==================================================
No: 591	GFLOPS: 35915.13 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.04, Tstamp:1715258869.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,32)
        compute = ...

==================================================
No: 592	GFLOPS: 35647.08 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.72, Tstamp:1715258870.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 593	GFLOPS: 37678.28 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.52, Tstamp:1715258870.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,32)
        compute = ...

==================================================
No: 594	GFLOPS: 21869.78 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.34, Tstamp:1715258871.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,32)
        compute = ...

==================================================
No: 595	GFLOPS: 24504.23 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.18, Tstamp:1715258871.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 596	GFLOPS: 25084.58 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.32, Tstamp:1715258872.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 597	GFLOPS: 27606.92 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.11, Tstamp:1715258872.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      for n.1 (0,16)
        compute = ...

==================================================
No: 598	GFLOPS: 27721.81 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.99, Tstamp:1715258873.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 599	GFLOPS: 25060.33 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.17, Tstamp:1715258873.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 600	GFLOPS: 28452.25 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.89, Tstamp:1715258873.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 601	GFLOPS: 20074.87 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.04, Tstamp:1715258874.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 602	GFLOPS: 31406.41 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.80, Tstamp:1715258874.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 603	GFLOPS: 31485.18 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.22, Tstamp:1715258875.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 604	GFLOPS: 32517.41 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.82, Tstamp:1715258875.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 605	GFLOPS: 34472.68 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.85, Tstamp:1715258876.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 606	GFLOPS: 32255.20 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.45, Tstamp:1715258876.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 607	GFLOPS: 45577.51 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.02, Tstamp:1715258877.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 608	GFLOPS: 45916.68 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.80, Tstamp:1715258877.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 609	GFLOPS: 38338.07 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.94, Tstamp:1715258878.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 610	GFLOPS: 28312.29 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.38, Tstamp:1715258878.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 611	GFLOPS: 37239.26 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.92, Tstamp:1715258879.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 612	GFLOPS: 40942.99 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.75, Tstamp:1715258879.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 613	GFLOPS: 36385.90 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.15, Tstamp:1715258880.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 614	GFLOPS: 25376.75 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.22, Tstamp:1715258880.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 615	GFLOPS: 45630.54 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.81, Tstamp:1715258881.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 616	GFLOPS: 45009.35 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.86, Tstamp:1715258881.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 617	GFLOPS: 34562.80 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.57, Tstamp:1715258882.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,64)
        compute = ...

==================================================
No: 618	GFLOPS: 35602.63 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.00, Tstamp:1715258882.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 619	GFLOPS: 35835.28 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.16, Tstamp:1715258883.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 620	GFLOPS: 33530.08 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.00, Tstamp:1715258883.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,32)
      compute = ...

==================================================
No: 621	GFLOPS: 35605.37 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.09, Tstamp:1715258884.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 622	GFLOPS: 33718.36 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.99, Tstamp:1715258884.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,32)
      compute = ...

==================================================
No: 623	GFLOPS: 36603.90 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.10, Tstamp:1715258885.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 624	GFLOPS: 32325.41 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.44, Tstamp:1715258885.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 625	GFLOPS: 35233.39 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.48, Tstamp:1715258886.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 626	GFLOPS: 33196.96 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.60, Tstamp:1715258886.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 627	GFLOPS: 34103.16 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.28, Tstamp:1715258887.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 628	GFLOPS: 31545.54 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.87, Tstamp:1715258887.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 629	GFLOPS: 17729.73 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.61, Tstamp:1715258888.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,48)
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 630	GFLOPS: 29915.47 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.75, Tstamp:1715258888.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 631	GFLOPS: 35265.84 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.77, Tstamp:1715258889.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 632	GFLOPS: 33949.51 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.45, Tstamp:1715258889.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 633	GFLOPS: 32433.70 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.56, Tstamp:1715258890.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 634	GFLOPS: 32848.03 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.67, Tstamp:1715258890.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 635	GFLOPS: 45890.12 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.69, Tstamp:1715258891.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 636	GFLOPS: 32431.04 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.14, Tstamp:1715258891.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,32)
        compute = ...

==================================================
No: 637	GFLOPS: 29918.36 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.74, Tstamp:1715258892.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 638	GFLOPS: 8584.96 / 50535.94	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.72, Tstamp:1715258892.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,192)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,64)
      compute = ...

==================================================
No: 639	GFLOPS: 1703.65 / 50535.94	results: MeasureResult(cost:[0.0085], error_no:0, all_cost:0.58, Tstamp:1715258892.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,128)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 640	GFLOPS: 5068.35 / 50535.94	results: MeasureResult(cost:[0.0029], error_no:0, all_cost:0.77, Tstamp:1715258893.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    for n.1 (0,48)
      compute = ...

Time elapsed for measurement: 39.86 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.45 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1797	fail_ct: 251	Time elapsed: 2.53
GA Iter: 0	Max score: 0.6445	Min score: 0.4213	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8659	Min score: 0.6377	#Pop: 128	#M+: 1382	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 10.06
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 641	GFLOPS: 24826.47 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.89, Tstamp:1715258916.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 642	GFLOPS: 46449.55 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.20, Tstamp:1715258916.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 643	GFLOPS: 35662.70 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.00, Tstamp:1715258917.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 644	GFLOPS: 40536.60 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.24, Tstamp:1715258917.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 645	GFLOPS: 42893.08 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.64, Tstamp:1715258918.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 646	GFLOPS: 42407.52 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.84, Tstamp:1715258918.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 647	GFLOPS: 40387.11 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.20, Tstamp:1715258919.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 648	GFLOPS: 41179.71 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.05, Tstamp:1715258919.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 649	GFLOPS: 35661.63 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.78, Tstamp:1715258920.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 650	GFLOPS: 38199.12 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.13, Tstamp:1715258920.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 651	GFLOPS: 47830.30 / 50535.94	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:2.88, Tstamp:1715258921.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,64)
        compute = ...

==================================================
No: 652	GFLOPS: 34798.48 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.77, Tstamp:1715258921.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,64)
        compute = ...

==================================================
No: 653	GFLOPS: 33088.47 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.41, Tstamp:1715258922.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 654	GFLOPS: 19023.47 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.19, Tstamp:1715258922.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      for n.1 (0,16)
        compute = ...

==================================================
No: 655	GFLOPS: 30880.28 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.24, Tstamp:1715258923.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      for n.1 (0,16)
        compute = ...

==================================================
No: 656	GFLOPS: 36018.02 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.08, Tstamp:1715258923.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 657	GFLOPS: 36750.63 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.86, Tstamp:1715258924.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 658	GFLOPS: 36560.91 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.93, Tstamp:1715258924.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 659	GFLOPS: 32006.33 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.31, Tstamp:1715258925.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 660	GFLOPS: 24526.27 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.38, Tstamp:1715258925.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 661	GFLOPS: 36465.45 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.95, Tstamp:1715258925.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 662	GFLOPS: 29351.49 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.76, Tstamp:1715258926.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 663	GFLOPS: 27357.97 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.68, Tstamp:1715258926.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 664	GFLOPS: 30360.38 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.60, Tstamp:1715258927.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 665	GFLOPS: 31572.24 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.83, Tstamp:1715258927.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,16)
        compute = ...

==================================================
No: 666	GFLOPS: 26735.55 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.53, Tstamp:1715258928.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 667	GFLOPS: 39903.44 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.89, Tstamp:1715258929.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 668	GFLOPS: 28158.83 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.97, Tstamp:1715258929.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 669	GFLOPS: 31482.28 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.01, Tstamp:1715258929.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,64)
        compute = ...

==================================================
No: 670	GFLOPS: 28073.36 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.41, Tstamp:1715258930.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      for n.1 (0,32)
        compute = ...

==================================================
No: 671	GFLOPS: 20141.40 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.49, Tstamp:1715258930.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 672	GFLOPS: 23602.69 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.80, Tstamp:1715258931.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 673	GFLOPS: 22405.37 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.52, Tstamp:1715258931.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 674	GFLOPS: 24728.77 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.77, Tstamp:1715258931.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,64)
        compute = ...

==================================================
No: 675	GFLOPS: 20453.71 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.86, Tstamp:1715258932.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 676	GFLOPS: 20004.88 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.60, Tstamp:1715258932.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 677	GFLOPS: 24235.28 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.97, Tstamp:1715258933.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,32)
        compute = ...

==================================================
No: 678	GFLOPS: 18601.90 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.85, Tstamp:1715258933.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 679	GFLOPS: 21851.59 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.81, Tstamp:1715258934.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 680	GFLOPS: 19741.57 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.89, Tstamp:1715258934.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 681	GFLOPS: 25530.81 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.76, Tstamp:1715258935.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 682	GFLOPS: 19698.05 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.99, Tstamp:1715258935.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 683	GFLOPS: 17653.64 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.05, Tstamp:1715258935.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 684	GFLOPS: 20648.34 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.90, Tstamp:1715258936.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,48)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 685	GFLOPS: 17774.82 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.76, Tstamp:1715258936.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,48)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 686	GFLOPS: 27585.86 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.70, Tstamp:1715258937.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 687	GFLOPS: 28020.35 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.77, Tstamp:1715258937.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 688	GFLOPS: 19020.27 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.34, Tstamp:1715258938.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 689	GFLOPS: 29933.22 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.62, Tstamp:1715258938.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 690	GFLOPS: 17511.38 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.47, Tstamp:1715258938.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 691	GFLOPS: 22651.83 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.06, Tstamp:1715258939.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 692	GFLOPS: 19559.30 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.60, Tstamp:1715258939.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 693	GFLOPS: 27580.78 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.73, Tstamp:1715258940.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 694	GFLOPS: 27276.41 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.24, Tstamp:1715258940.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 695	GFLOPS: 10961.71 / 50535.94	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:1.50, Tstamp:1715258941.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 696	GFLOPS: 26141.61 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.35, Tstamp:1715258941.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 697	GFLOPS: 26014.36 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.42, Tstamp:1715258942.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 698	GFLOPS: 18291.48 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.42, Tstamp:1715258942.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 699	GFLOPS: 12093.05 / 50535.94	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:1.45, Tstamp:1715258943.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 700	GFLOPS: 26947.21 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.51, Tstamp:1715258943.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 701	GFLOPS: 28245.19 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.68, Tstamp:1715258944.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 702	GFLOPS: 17369.77 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.67, Tstamp:1715258944.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,48)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,32)
      compute = ...

==================================================
No: 703	GFLOPS: 3416.65 / 50535.94	results: MeasureResult(cost:[0.0042], error_no:0, all_cost:1.29, Tstamp:1715258945.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,24)
      compute = ...

==================================================
No: 704	GFLOPS: 234.71 / 50535.94	results: MeasureResult(cost:[0.0618], error_no:0, all_cost:1.14, Tstamp:1715258945.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,1024)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 37.93 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.01 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1812	fail_ct: 236	Time elapsed: 2.12
GA Iter: 0	Max score: 0.6495	Min score: 0.4238	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8475	Min score: 0.6202	#Pop: 128	#M+: 1382	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 9.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 705	GFLOPS: 24082.23 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:3.22, Tstamp:1715258967.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,64)
        compute = ...

==================================================
No: 706	GFLOPS: 31618.06 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.48, Tstamp:1715258968.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 707	GFLOPS: 22199.82 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.46, Tstamp:1715258968.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 708	GFLOPS: 22099.87 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:3.03, Tstamp:1715258969.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,64)
        compute = ...

==================================================
No: 709	GFLOPS: 22018.04 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:3.26, Tstamp:1715258969.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,64)
        compute = ...

==================================================
No: 710	GFLOPS: 21110.77 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.44, Tstamp:1715258970.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 711	GFLOPS: 21268.13 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.85, Tstamp:1715258970.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,32)
        compute = ...

==================================================
No: 712	GFLOPS: 27919.98 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.50, Tstamp:1715258970.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 713	GFLOPS: 21454.82 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.53, Tstamp:1715258971.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 714	GFLOPS: 24724.96 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.30, Tstamp:1715258971.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 715	GFLOPS: 29893.22 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.57, Tstamp:1715258972.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,48)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 716	GFLOPS: 28700.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.12, Tstamp:1715258972.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 717	GFLOPS: 20762.72 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.77, Tstamp:1715258973.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,64)
        compute = ...

==================================================
No: 718	GFLOPS: 23198.26 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.55, Tstamp:1715258973.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 719	GFLOPS: 22716.97 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.19, Tstamp:1715258974.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,96)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 720	GFLOPS: 19041.84 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.54, Tstamp:1715258974.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 721	GFLOPS: 23694.60 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.27, Tstamp:1715258975.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,96)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 722	GFLOPS: 25701.89 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.60, Tstamp:1715258975.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,64)
        compute = ...

==================================================
No: 723	GFLOPS: 21938.28 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.61, Tstamp:1715258976.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 724	GFLOPS: 19534.73 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.99, Tstamp:1715258976.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 725	GFLOPS: 20170.45 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.19, Tstamp:1715258976.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 726	GFLOPS: 21828.75 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.89, Tstamp:1715258977.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 727	GFLOPS: 24699.63 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.88, Tstamp:1715258978.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,48)
        compute = ...

==================================================
No: 728	GFLOPS: 17757.95 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.61, Tstamp:1715258978.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 729	GFLOPS: 28266.16 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.97, Tstamp:1715258979.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 730	GFLOPS: 19159.32 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.97, Tstamp:1715258979.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 731	GFLOPS: 20317.40 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.10, Tstamp:1715258979.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 732	GFLOPS: 27629.42 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.96, Tstamp:1715258980.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 733	GFLOPS: 28660.91 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.59, Tstamp:1715258981.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 734	GFLOPS: 27795.37 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.89, Tstamp:1715258981.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,589824)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 735	GFLOPS: 17827.11 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.78, Tstamp:1715258982.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,64)
      compute = ...

==================================================
No: 736	GFLOPS: 20958.86 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.64, Tstamp:1715258982.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 737	GFLOPS: 16870.12 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.92, Tstamp:1715258983.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,64)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 738	GFLOPS: 17085.94 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.89, Tstamp:1715258983.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 739	GFLOPS: 23062.74 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.87, Tstamp:1715258984.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,64)
        compute = ...

==================================================
No: 740	GFLOPS: 28461.06 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.93, Tstamp:1715258984.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 741	GFLOPS: 26819.40 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.84, Tstamp:1715258985.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 742	GFLOPS: 28665.58 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.81, Tstamp:1715258985.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 743	GFLOPS: 19686.07 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.25, Tstamp:1715258986.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 744	GFLOPS: 19820.60 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.14, Tstamp:1715258986.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 745	GFLOPS: 23755.66 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.28, Tstamp:1715258987.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 746	GFLOPS: 28915.61 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.83, Tstamp:1715258987.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 747	GFLOPS: 27872.27 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.75, Tstamp:1715258988.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 748	GFLOPS: 27638.62 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.74, Tstamp:1715258988.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 749	GFLOPS: 29116.38 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.14, Tstamp:1715258989.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,64)
        compute = ...

==================================================
No: 750	GFLOPS: 28606.99 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.89, Tstamp:1715258990.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 751	GFLOPS: 19482.45 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.94, Tstamp:1715258990.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 752	GFLOPS: 27426.81 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.73, Tstamp:1715258991.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 753	GFLOPS: 19485.39 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.97, Tstamp:1715258991.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 754	GFLOPS: 28302.27 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.52, Tstamp:1715258992.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 755	GFLOPS: 20313.55 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.18, Tstamp:1715258992.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 756	GFLOPS: 28838.95 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.48, Tstamp:1715258992.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 757	GFLOPS: 25759.47 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.68, Tstamp:1715258993.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 758	GFLOPS: 27509.98 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.64, Tstamp:1715258993.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 759	GFLOPS: 23357.63 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.52, Tstamp:1715258994.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 760	GFLOPS: 31678.10 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.29, Tstamp:1715258994.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 761	GFLOPS: 28101.94 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.67, Tstamp:1715258995.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 762	GFLOPS: 18815.90 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.57, Tstamp:1715258995.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 763	GFLOPS: 28249.02 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.64, Tstamp:1715258996.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 764	GFLOPS: 19805.82 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.49, Tstamp:1715258996.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,3072)
  for n.0 (0,64)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 765	GFLOPS: 19984.01 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.50, Tstamp:1715258997.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,3072)
  for n.0 (0,48)
    compute auto_unroll: 64
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,64)
      compute = ...

==================================================
No: 766	GFLOPS: 1800.93 / 50535.94	results: MeasureResult(cost:[0.0080], error_no:0, all_cost:3.19, Tstamp:1715258997.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 767	GFLOPS: 817.48 / 50535.94	results: MeasureResult(cost:[0.0177], error_no:0, all_cost:1.28, Tstamp:1715258997.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 768	GFLOPS: 456.29 / 50535.94	results: MeasureResult(cost:[0.0318], error_no:0, all_cost:0.93, Tstamp:1715258998.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,1536)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 39.73 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.28 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1794	fail_ct: 254	Time elapsed: 2.26
GA Iter: 0	Max score: 0.7231	Min score: 0.4002	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8530	Min score: 0.5896	#Pop: 128	#M+: 1378	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 9.86
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 769	GFLOPS: 23049.87 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:3.20, Tstamp:1715259020.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 770	GFLOPS: 32983.86 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.87, Tstamp:1715259021.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 771	GFLOPS: 19628.62 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.70, Tstamp:1715259021.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 772	GFLOPS: 25203.72 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.51, Tstamp:1715259021.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,32)
      compute = ...

==================================================
No: 773	GFLOPS: 21738.42 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.90, Tstamp:1715259022.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 774	GFLOPS: 26260.49 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.61, Tstamp:1715259022.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      for n.1 (0,64)
        compute = ...

==================================================
No: 775	GFLOPS: 29274.80 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.49, Tstamp:1715259023.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,64)
      compute = ...

==================================================
No: 776	GFLOPS: 17860.97 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.42, Tstamp:1715259023.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 777	GFLOPS: 30142.66 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.21, Tstamp:1715259024.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 778	GFLOPS: 32600.54 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.31, Tstamp:1715259024.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,32)
      compute = ...

==================================================
No: 779	GFLOPS: 22728.05 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.32, Tstamp:1715259025.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 780	GFLOPS: 21530.78 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.98, Tstamp:1715259025.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 781	GFLOPS: 25664.84 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.17, Tstamp:1715259025.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,64)
      compute = ...

==================================================
No: 782	GFLOPS: 28499.82 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.94, Tstamp:1715259026.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 783	GFLOPS: 19212.92 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.18, Tstamp:1715259026.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 784	GFLOPS: 19322.99 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.70, Tstamp:1715259027.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 785	GFLOPS: 18648.65 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.68, Tstamp:1715259027.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,64)
        compute = ...

==================================================
No: 786	GFLOPS: 20593.11 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.80, Tstamp:1715259028.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,64)
        compute = ...

==================================================
No: 787	GFLOPS: 25589.52 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.01, Tstamp:1715259028.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,32)
      compute = ...

==================================================
No: 788	GFLOPS: 20152.06 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.20, Tstamp:1715259028.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 789	GFLOPS: 17123.68 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.49, Tstamp:1715259029.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 790	GFLOPS: 20090.63 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.99, Tstamp:1715259029.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 791	GFLOPS: 20455.56 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.45, Tstamp:1715259030.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 792	GFLOPS: 17000.92 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.99, Tstamp:1715259030.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 793	GFLOPS: 20916.25 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:3.33, Tstamp:1715259031.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 794	GFLOPS: 27805.85 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.11, Tstamp:1715259031.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 795	GFLOPS: 29207.42 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.17, Tstamp:1715259032.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 796	GFLOPS: 17555.17 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.70, Tstamp:1715259032.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,192)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 797	GFLOPS: 18856.05 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.38, Tstamp:1715259033.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,32)
      compute = ...

==================================================
No: 798	GFLOPS: 31975.04 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.35, Tstamp:1715259033.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 799	GFLOPS: 20819.36 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.23, Tstamp:1715259033.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 800	GFLOPS: 29137.54 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.54, Tstamp:1715259034.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,16)
      compute = ...

==================================================
No: 801	GFLOPS: 29592.09 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.88, Tstamp:1715259034.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 802	GFLOPS: 28750.15 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.85, Tstamp:1715259035.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 803	GFLOPS: 20020.27 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.13, Tstamp:1715259035.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 804	GFLOPS: 19635.51 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.96, Tstamp:1715259036.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 805	GFLOPS: 20960.05 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.93, Tstamp:1715259036.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 806	GFLOPS: 20333.02 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.77, Tstamp:1715259037.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 807	GFLOPS: 27167.17 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.86, Tstamp:1715259037.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 808	GFLOPS: 27832.18 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.58, Tstamp:1715259037.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,64)
    compute = ...

==================================================
No: 809	GFLOPS: 27273.05 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.82, Tstamp:1715259038.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 810	GFLOPS: 29661.21 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.19, Tstamp:1715259038.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,64)
        compute = ...

==================================================
No: 811	GFLOPS: 27211.55 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.87, Tstamp:1715259039.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 812	GFLOPS: 32105.23 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.95, Tstamp:1715259039.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 813	GFLOPS: 31457.92 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.13, Tstamp:1715259040.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 814	GFLOPS: 29832.03 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.75, Tstamp:1715259040.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 815	GFLOPS: 18751.97 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.07, Tstamp:1715259041.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,16)
      compute = ...

==================================================
No: 816	GFLOPS: 28891.78 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.66, Tstamp:1715259041.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 817	GFLOPS: 29452.41 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.71, Tstamp:1715259042.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 818	GFLOPS: 27236.70 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.59, Tstamp:1715259042.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32768)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 819	GFLOPS: 20028.98 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.52, Tstamp:1715259043.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 820	GFLOPS: 19229.29 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.65, Tstamp:1715259043.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 821	GFLOPS: 19531.46 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.66, Tstamp:1715259043.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 822	GFLOPS: 25701.24 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.31, Tstamp:1715259044.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 823	GFLOPS: 28302.22 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.71, Tstamp:1715259044.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 824	GFLOPS: 39233.28 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.01, Tstamp:1715259045.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 825	GFLOPS: 27913.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.66, Tstamp:1715259045.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 826	GFLOPS: 20839.06 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.65, Tstamp:1715259046.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 827	GFLOPS: 19805.05 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.62, Tstamp:1715259046.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 828	GFLOPS: 25812.01 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.47, Tstamp:1715259047.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 829	GFLOPS: 20000.04 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.66, Tstamp:1715259047.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 830	GFLOPS: 14303.55 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.71, Tstamp:1715259047.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,32)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 831	GFLOPS: 20943.46 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.71, Tstamp:1715259048.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,64)
      compute = ...

==================================================
No: 832	GFLOPS: 1068.88 / 50535.94	results: MeasureResult(cost:[0.0136], error_no:0, all_cost:0.72, Tstamp:1715259048.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

Time elapsed for measurement: 36.87 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.37 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1809	fail_ct: 239	Time elapsed: 2.43
GA Iter: 0	Max score: 0.6771	Min score: 0.3988	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9462	Min score: 0.5720	#Pop: 128	#M+: 1382	#M-: 81
EvolutionarySearch		#s: 128	Time elapsed: 9.44
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 833	GFLOPS: 33732.53 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.78, Tstamp:1715259070.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 834	GFLOPS: 22708.48 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:3.99, Tstamp:1715259070.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,32)
        compute = ...

==================================================
No: 835	GFLOPS: 29417.77 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.94, Tstamp:1715259071.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 836	GFLOPS: 16856.40 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:2.51, Tstamp:1715259071.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 837	GFLOPS: 22136.37 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.09, Tstamp:1715259072.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 838	GFLOPS: 39806.47 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.02, Tstamp:1715259072.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 839	GFLOPS: 38900.96 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.40, Tstamp:1715259072.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 840	GFLOPS: 31676.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.95, Tstamp:1715259073.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 841	GFLOPS: 24082.68 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.47, Tstamp:1715259073.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 842	GFLOPS: 14291.99 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:2.38, Tstamp:1715259074.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 843	GFLOPS: 29176.89 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:3.10, Tstamp:1715259074.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 844	GFLOPS: 14565.17 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:2.02, Tstamp:1715259075.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,32)
      compute = ...

==================================================
No: 845	GFLOPS: 25871.48 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.71, Tstamp:1715259075.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 846	GFLOPS: 19992.65 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.51, Tstamp:1715259075.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,32)
      compute = ...

==================================================
No: 847	GFLOPS: 27702.82 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.85, Tstamp:1715259076.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 848	GFLOPS: 27122.69 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.93, Tstamp:1715259076.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 849	GFLOPS: 27216.73 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.37, Tstamp:1715259077.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 850	GFLOPS: 23600.42 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.97, Tstamp:1715259077.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 851	GFLOPS: 29876.82 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.96, Tstamp:1715259078.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      for n.1 (0,32)
        compute = ...

==================================================
No: 852	GFLOPS: 24237.89 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.36, Tstamp:1715259078.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 853	GFLOPS: 32316.11 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:2.52, Tstamp:1715259079.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      for n.1 (0,48)
        compute = ...

==================================================
No: 854	GFLOPS: 30783.16 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.97, Tstamp:1715259079.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      for n.1 (0,48)
        compute = ...

==================================================
No: 855	GFLOPS: 30456.53 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.34, Tstamp:1715259080.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 856	GFLOPS: 22089.29 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.08, Tstamp:1715259080.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 857	GFLOPS: 28026.04 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.49, Tstamp:1715259081.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,64)
        compute = ...

==================================================
No: 858	GFLOPS: 23954.56 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.72, Tstamp:1715259081.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 859	GFLOPS: 17763.27 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.94, Tstamp:1715259082.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1536)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 860	GFLOPS: 17656.59 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.67, Tstamp:1715259082.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 861	GFLOPS: 17508.52 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.81, Tstamp:1715259083.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 862	GFLOPS: 28301.40 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.97, Tstamp:1715259083.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 863	GFLOPS: 28489.11 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.85, Tstamp:1715259084.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 864	GFLOPS: 28343.72 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.99, Tstamp:1715259084.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,192)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 865	GFLOPS: 19481.82 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.63, Tstamp:1715259085.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 866	GFLOPS: 20140.53 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.76, Tstamp:1715259085.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 867	GFLOPS: 17299.96 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.73, Tstamp:1715259086.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,192)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 868	GFLOPS: 23816.04 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.68, Tstamp:1715259086.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,32)
      compute = ...

==================================================
No: 869	GFLOPS: 17891.57 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.60, Tstamp:1715259087.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 870	GFLOPS: 20509.80 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.72, Tstamp:1715259087.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 871	GFLOPS: 34871.99 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.10, Tstamp:1715259087.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 872	GFLOPS: 29587.14 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.63, Tstamp:1715259088.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 873	GFLOPS: 28618.81 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.57, Tstamp:1715259088.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,32)
    compute = ...

==================================================
No: 874	GFLOPS: 23723.75 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.54, Tstamp:1715259089.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 875	GFLOPS: 18699.25 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.99, Tstamp:1715259089.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,64)
      compute = ...

==================================================
No: 876	GFLOPS: 34683.27 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.16, Tstamp:1715259090.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,64)
      compute = ...

==================================================
No: 877	GFLOPS: 18560.01 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.97, Tstamp:1715259090.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 878	GFLOPS: 18970.03 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.87, Tstamp:1715259091.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,96)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 879	GFLOPS: 20887.44 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.60, Tstamp:1715259091.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 880	GFLOPS: 37593.49 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.30, Tstamp:1715259092.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 881	GFLOPS: 19091.62 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.67, Tstamp:1715259092.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,96)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 882	GFLOPS: 25864.97 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.52, Tstamp:1715259093.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 883	GFLOPS: 18505.10 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.29, Tstamp:1715259093.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 884	GFLOPS: 25580.46 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.66, Tstamp:1715259093.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 885	GFLOPS: 27157.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.48, Tstamp:1715259094.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 886	GFLOPS: 27012.37 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.72, Tstamp:1715259094.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,64)
        compute = ...

==================================================
No: 887	GFLOPS: 20525.98 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.64, Tstamp:1715259095.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 888	GFLOPS: 27702.33 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.60, Tstamp:1715259095.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 889	GFLOPS: 24835.84 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.54, Tstamp:1715259095.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 890	GFLOPS: 28697.23 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.53, Tstamp:1715259096.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 891	GFLOPS: 30685.28 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.60, Tstamp:1715259096.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 892	GFLOPS: 26859.56 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.64, Tstamp:1715259097.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 893	GFLOPS: 28712.25 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.48, Tstamp:1715259097.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 894	GFLOPS: 2999.67 / 50535.94	results: MeasureResult(cost:[0.0048], error_no:0, all_cost:0.74, Tstamp:1715259098.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 895	GFLOPS: 2018.58 / 50535.94	results: MeasureResult(cost:[0.0072], error_no:0, all_cost:0.68, Tstamp:1715259098.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 1024)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 896	GFLOPS: 17039.79 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.62, Tstamp:1715259099.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,65536)
  for i.1 (0,3)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 37.09 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.23 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1753	fail_ct: 295	Time elapsed: 2.27
GA Iter: 0	Max score: 0.6867	Min score: 0.3792	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7504	Min score: 0.5541	#Pop: 128	#M+: 1382	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 9.80
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 897	GFLOPS: 31210.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.63, Tstamp:1715259120.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 898	GFLOPS: 28537.20 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.59, Tstamp:1715259120.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 899	GFLOPS: 14545.93 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:2.38, Tstamp:1715259121.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 900	GFLOPS: 23592.15 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.84, Tstamp:1715259121.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 901	GFLOPS: 21509.54 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:3.10, Tstamp:1715259122.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 902	GFLOPS: 28702.48 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.07, Tstamp:1715259122.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 903	GFLOPS: 22840.63 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.54, Tstamp:1715259123.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,64)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 904	GFLOPS: 22590.42 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.92, Tstamp:1715259123.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,48)
      compute = ...

==================================================
No: 905	GFLOPS: 22310.37 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.65, Tstamp:1715259124.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 906	GFLOPS: 27573.14 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.45, Tstamp:1715259124.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 907	GFLOPS: 21403.32 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.72, Tstamp:1715259124.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,48)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 908	GFLOPS: 17867.80 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.58, Tstamp:1715259125.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 909	GFLOPS: 27975.97 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.17, Tstamp:1715259126.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 910	GFLOPS: 32302.02 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.78, Tstamp:1715259126.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 911	GFLOPS: 24801.88 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.25, Tstamp:1715259127.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 912	GFLOPS: 17649.40 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.10, Tstamp:1715259127.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 913	GFLOPS: 19660.55 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.35, Tstamp:1715259127.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,64)
      for n.1 (0,64)
        compute = ...

==================================================
No: 914	GFLOPS: 18259.75 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.01, Tstamp:1715259128.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 915	GFLOPS: 17459.05 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.76, Tstamp:1715259128.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 916	GFLOPS: 16404.91 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.08, Tstamp:1715259129.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,32)
    compute = ...

==================================================
No: 917	GFLOPS: 28851.55 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:2.56, Tstamp:1715259129.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 918	GFLOPS: 32891.62 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.87, Tstamp:1715259130.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 919	GFLOPS: 20539.19 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.52, Tstamp:1715259130.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,64)
        compute = ...

==================================================
No: 920	GFLOPS: 16695.38 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:2.18, Tstamp:1715259131.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,32)
        compute = ...

==================================================
No: 921	GFLOPS: 28269.85 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.98, Tstamp:1715259131.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 922	GFLOPS: 24752.54 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.95, Tstamp:1715259132.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 923	GFLOPS: 24161.02 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.29, Tstamp:1715259132.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,64)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    for n.1 (0,64)
      compute = ...

==================================================
No: 924	GFLOPS: 16995.53 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:2.15, Tstamp:1715259133.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 925	GFLOPS: 20462.34 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.02, Tstamp:1715259133.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,48)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,64)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 926	GFLOPS: 27391.15 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.98, Tstamp:1715259134.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 927	GFLOPS: 28581.55 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.87, Tstamp:1715259134.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 928	GFLOPS: 19816.26 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.98, Tstamp:1715259135.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 929	GFLOPS: 17652.53 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.67, Tstamp:1715259135.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 930	GFLOPS: 22765.62 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.80, Tstamp:1715259136.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 931	GFLOPS: 29610.97 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.96, Tstamp:1715259136.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 932	GFLOPS: 19868.16 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.10, Tstamp:1715259137.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,64)
      compute = ...

==================================================
No: 933	GFLOPS: 18434.78 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.83, Tstamp:1715259137.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 934	GFLOPS: 27602.52 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.79, Tstamp:1715259138.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,64)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 935	GFLOPS: 31114.88 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.88, Tstamp:1715259138.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,48)
      for n.1 (0,64)
        compute = ...

==================================================
No: 936	GFLOPS: 29647.50 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.87, Tstamp:1715259139.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 937	GFLOPS: 24985.06 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.76, Tstamp:1715259139.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 938	GFLOPS: 20371.48 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.93, Tstamp:1715259140.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,192)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 939	GFLOPS: 15277.21 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.78, Tstamp:1715259140.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,48)
    compute auto_unroll: 512
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,64)
        compute = ...

==================================================
No: 940	GFLOPS: 28880.11 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.83, Tstamp:1715259141.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,64)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 941	GFLOPS: 27690.24 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.66, Tstamp:1715259141.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,3)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,64)
      compute = ...

==================================================
No: 942	GFLOPS: 13496.09 / 50535.94	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.74, Tstamp:1715259142.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,393216)
  compute auto_unroll: 64
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,24)
    compute = ...

==================================================
No: 943	GFLOPS: 18995.48 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.87, Tstamp:1715259142.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 944	GFLOPS: 21994.36 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.03, Tstamp:1715259143.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 945	GFLOPS: 18477.53 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.53, Tstamp:1715259143.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,192)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 946	GFLOPS: 16039.89 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.12, Tstamp:1715259143.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 947	GFLOPS: 19643.55 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.23, Tstamp:1715259144.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 948	GFLOPS: 18311.10 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.61, Tstamp:1715259144.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 949	GFLOPS: 29590.65 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.57, Tstamp:1715259145.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 950	GFLOPS: 24187.16 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.55, Tstamp:1715259145.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 951	GFLOPS: 29035.11 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.68, Tstamp:1715259146.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,48)
    for i.1 (0,2)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 952	GFLOPS: 18739.45 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.66, Tstamp:1715259146.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 953	GFLOPS: 16055.51 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.60, Tstamp:1715259147.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,4)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 954	GFLOPS: 20903.55 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.67, Tstamp:1715259147.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 955	GFLOPS: 21391.40 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.74, Tstamp:1715259148.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,64)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,48)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 956	GFLOPS: 16639.58 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.68, Tstamp:1715259148.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 957	GFLOPS: 18028.48 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.63, Tstamp:1715259149.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,64)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 958	GFLOPS: 6140.18 / 50535.94	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.72, Tstamp:1715259149.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,256)
    for n.1 (0,48)
      compute = ...

==================================================
No: 959	GFLOPS: 558.56 / 50535.94	results: MeasureResult(cost:[0.0260], error_no:0, all_cost:0.68, Tstamp:1715259150.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,512)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 960	GFLOPS: 1506.10 / 50535.94	results: MeasureResult(cost:[0.0096], error_no:0, all_cost:0.62, Tstamp:1715259150.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 37.95 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.33 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1793	fail_ct: 255	Time elapsed: 2.40
GA Iter: 0	Max score: 0.5908	Min score: 0.3943	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7496	Min score: 0.5346	#Pop: 128	#M+: 1388	#M-: 82
EvolutionarySearch		#s: 128	Time elapsed: 9.95
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 40 programs to measure:
........................................****************************************
==================================================
No: 961	GFLOPS: 17200.73 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.99, Tstamp:1715259170.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 962	GFLOPS: 21406.73 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.10, Tstamp:1715259170.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 963	GFLOPS: 24209.58 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.88, Tstamp:1715259171.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,64)
      compute = ...

==================================================
No: 964	GFLOPS: 11536.15 / 50535.94	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:2.30, Tstamp:1715259171.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 965	GFLOPS: 12207.47 / 50535.94	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:2.30, Tstamp:1715259172.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,768)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 966	GFLOPS: 28274.78 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.79, Tstamp:1715259172.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 967	GFLOPS: 20739.25 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.26, Tstamp:1715259173.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 968	GFLOPS: 27888.95 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.95, Tstamp:1715259173.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 969	GFLOPS: 11491.70 / 50535.94	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:1.88, Tstamp:1715259174.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,96)
    compute auto_unroll: 512
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 970	GFLOPS: 13439.43 / 50535.94	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.79, Tstamp:1715259174.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 971	GFLOPS: 14602.49 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.79, Tstamp:1715259175.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1536)
  for n.0 (0,192)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 972	GFLOPS: 16468.37 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.99, Tstamp:1715259175.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,64)
      compute = ...

==================================================
No: 973	GFLOPS: 21908.46 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.50, Tstamp:1715259176.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for nb_j.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,64)
      compute = ...

==================================================
No: 974	GFLOPS: 34667.70 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.02, Tstamp:1715259176.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 975	GFLOPS: 35780.63 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.86, Tstamp:1715259176.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 976	GFLOPS: 28521.17 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.71, Tstamp:1715259177.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 977	GFLOPS: 29843.10 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.63, Tstamp:1715259178.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,192)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 978	GFLOPS: 16896.60 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.52, Tstamp:1715259178.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 979	GFLOPS: 28299.51 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.59, Tstamp:1715259178.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 980	GFLOPS: 20638.70 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.70, Tstamp:1715259179.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 981	GFLOPS: 19927.10 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.76, Tstamp:1715259179.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 982	GFLOPS: 21722.20 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.61, Tstamp:1715259180.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 983	GFLOPS: 27929.42 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.56, Tstamp:1715259180.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 984	GFLOPS: 28456.52 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.80, Tstamp:1715259181.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 985	GFLOPS: 28636.84 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.64, Tstamp:1715259181.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for nb_j.1 (0,4)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,64)
        compute = ...

==================================================
No: 986	GFLOPS: 28229.66 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.65, Tstamp:1715259182.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 987	GFLOPS: 29693.76 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.71, Tstamp:1715259182.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,32)
      compute = ...

==================================================
No: 988	GFLOPS: 24978.73 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.67, Tstamp:1715259183.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 192) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 192)]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 989	GFLOPS: 36591.56 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.99, Tstamp:1715259183.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 990	GFLOPS: 37238.28 / 50535.94	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.93, Tstamp:1715259184.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,512)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 991	GFLOPS: 21229.50 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:2.10, Tstamp:1715259184.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,48)
        compute = ...

==================================================
No: 992	GFLOPS: 20456.45 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.70, Tstamp:1715259185.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 993	GFLOPS: 15633.61 / 50535.94	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.68, Tstamp:1715259185.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,32)
      compute = ...

==================================================
No: 994	GFLOPS: 28359.37 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.70, Tstamp:1715259186.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,192)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 995	GFLOPS: 14188.00 / 50535.94	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:1.86, Tstamp:1715259186.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 996	GFLOPS: 17771.56 / 50535.94	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.01, Tstamp:1715259187.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 997	GFLOPS: 23694.56 / 50535.94	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.87, Tstamp:1715259187.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,1024)
  for n.0 (0,64)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 998	GFLOPS: 20069.24 / 50535.94	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.85, Tstamp:1715259188.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,192)
  for n.0 (0,96)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,2)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      for n.1 (0,32)
        compute = ...

==================================================
No: 999	GFLOPS: 28653.41 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.53, Tstamp:1715259188.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

==================================================
No: 1000	GFLOPS: 29987.08 / 50535.94	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.63, Tstamp:1715259189.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0 (0,256)
  for n.0 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,32)
        compute = ...

Time elapsed for measurement: 24.81 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
Lowered TIR:
@main = primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, compute_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_8: Pointer(float32), float32, [3072, 768], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [88, 16, 16], []),
             placeholder_2: Buffer(placeholder_10: Pointer(int32), int32, [88], []),
             placeholder_3: Buffer(placeholder_11: Pointer(int32), int32, [193], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [3072, 3072], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, compute_1: compute} {
  for (m.outer.n.outer.fused: int32, 0, 98304) "parallel" {
    allocate(compute_3: Pointer(global float32), float32, [96]), storage_scope = global {
      compute_4: Buffer(compute_3, float32, [96], [])[0] = 0f32
      compute_4[1] = 0f32
      compute_4[2] = 0f32
      compute_4[3] = 0f32
      compute_4[4] = 0f32
      compute_4[5] = 0f32
      compute_4[6] = 0f32
      compute_4[7] = 0f32
      compute_4[8] = 0f32
      compute_4[9] = 0f32
      compute_4[10] = 0f32
      compute_4[11] = 0f32
      compute_4[12] = 0f32
      compute_4[13] = 0f32
      compute_4[14] = 0f32
      compute_4[15] = 0f32
      compute_4[16] = 0f32
      compute_4[17] = 0f32
      compute_4[18] = 0f32
      compute_4[19] = 0f32
      compute_4[20] = 0f32
      compute_4[21] = 0f32
      compute_4[22] = 0f32
      compute_4[23] = 0f32
      compute_4[24] = 0f32
      compute_4[25] = 0f32
      compute_4[26] = 0f32
      compute_4[27] = 0f32
      compute_4[28] = 0f32
      compute_4[29] = 0f32
      compute_4[30] = 0f32
      compute_4[31] = 0f32
      compute_4[32] = 0f32
      compute_4[33] = 0f32
      compute_4[34] = 0f32
      compute_4[35] = 0f32
      compute_4[36] = 0f32
      compute_4[37] = 0f32
      compute_4[38] = 0f32
      compute_4[39] = 0f32
      compute_4[40] = 0f32
      compute_4[41] = 0f32
      compute_4[42] = 0f32
      compute_4[43] = 0f32
      compute_4[44] = 0f32
      compute_4[45] = 0f32
      compute_4[46] = 0f32
      compute_4[47] = 0f32
      compute_4[48] = 0f32
      compute_4[49] = 0f32
      compute_4[50] = 0f32
      compute_4[51] = 0f32
      compute_4[52] = 0f32
      compute_4[53] = 0f32
      compute_4[54] = 0f32
      compute_4[55] = 0f32
      compute_4[56] = 0f32
      compute_4[57] = 0f32
      compute_4[58] = 0f32
      compute_4[59] = 0f32
      compute_4[60] = 0f32
      compute_4[61] = 0f32
      compute_4[62] = 0f32
      compute_4[63] = 0f32
      compute_4[64] = 0f32
      compute_4[65] = 0f32
      compute_4[66] = 0f32
      compute_4[67] = 0f32
      compute_4[68] = 0f32
      compute_4[69] = 0f32
      compute_4[70] = 0f32
      compute_4[71] = 0f32
      compute_4[72] = 0f32
      compute_4[73] = 0f32
      compute_4[74] = 0f32
      compute_4[75] = 0f32
      compute_4[76] = 0f32
      compute_4[77] = 0f32
      compute_4[78] = 0f32
      compute_4[79] = 0f32
      compute_4[80] = 0f32
      compute_4[81] = 0f32
      compute_4[82] = 0f32
      compute_4[83] = 0f32
      compute_4[84] = 0f32
      compute_4[85] = 0f32
      compute_4[86] = 0f32
      compute_4[87] = 0f32
      compute_4[88] = 0f32
      compute_4[89] = 0f32
      compute_4[90] = 0f32
      compute_4[91] = 0f32
      compute_4[92] = 0f32
      compute_4[93] = 0f32
      compute_4[94] = 0f32
      compute_4[95] = 0f32
      for (elem_idx: int32, 0, let cse_var_1: int32 = floormod(m.outer.n.outer.fused, 192) in (placeholder_12: Buffer(placeholder_11, int32, [193], [])[(cse_var_1 + 1)] - placeholder_12[cse_var_1])) {
        for (i.inner: int32, 0, 6) {
          let cse_var_2: int32 = floormod(m.outer.n.outer.fused, 192)
           {
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_3: int32 = (i.inner*16)
              compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13: Buffer(placeholder_9, float32, [22528], [])[((placeholder_12[cse_var_2]*256) + (elem_idx*256))]*placeholder_14: Buffer(placeholder_8, float32, [2359296], [])[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15: Buffer(placeholder_10, int32, [88], [])[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_4: int32 = (i.inner*16)
              compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 1)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_5: int32 = (i.inner*16)
              compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 2)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_6: int32 = (i.inner*16)
              compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 3)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_7: int32 = (i.inner*16)
              compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 4)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_8: int32 = (i.inner*16)
              compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 5)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_9: int32 = (i.inner*16)
              compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 6)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_10: int32 = (i.inner*16)
              compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 7)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_11: int32 = (i.inner*16)
              compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 8)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_12: int32 = (i.inner*16)
              compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 9)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_13: int32 = (i.inner*16)
              compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 10)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_14: int32 = (i.inner*16)
              compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 11)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_15: int32 = (i.inner*16)
              compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 12)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_16: int32 = (i.inner*16)
              compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 13)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_17: int32 = (i.inner*16)
              compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 14)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_18: int32 = (i.inner*16)
              compute_4[cse_var_18] = (compute_4[cse_var_18] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 15)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_19: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 16)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_20: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_20] = (compute_4[cse_var_20] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 17)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_21: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_21] = (compute_4[cse_var_21] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 18)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_22: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_22] = (compute_4[cse_var_22] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 19)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_23: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_23] = (compute_4[cse_var_23] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 20)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_24: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_24] = (compute_4[cse_var_24] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 21)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_25: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_25] = (compute_4[cse_var_25] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 22)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_26: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_26] = (compute_4[cse_var_26] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 23)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_27: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_27] = (compute_4[cse_var_27] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 24)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_28: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_28] = (compute_4[cse_var_28] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 25)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_29: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_29] = (compute_4[cse_var_29] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 26)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_30: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_30] = (compute_4[cse_var_30] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 27)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_31: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_31] = (compute_4[cse_var_31] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 28)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_32: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_32] = (compute_4[cse_var_32] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 29)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_33: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_33] = (compute_4[cse_var_33] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 30)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_34: int32 = ((i.inner*16) + 1)
              compute_4[cse_var_34] = (compute_4[cse_var_34] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 31)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_35: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_35] = (compute_4[cse_var_35] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 32)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_36: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_36] = (compute_4[cse_var_36] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 33)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_37: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_37] = (compute_4[cse_var_37] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 34)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_38: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_38] = (compute_4[cse_var_38] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 35)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_39: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_39] = (compute_4[cse_var_39] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 36)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_40: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_40] = (compute_4[cse_var_40] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 37)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_41: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_41] = (compute_4[cse_var_41] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 38)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_42: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_42] = (compute_4[cse_var_42] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 39)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_43: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_43] = (compute_4[cse_var_43] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 40)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_44: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_44] = (compute_4[cse_var_44] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 41)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_45: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_45] = (compute_4[cse_var_45] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 42)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_46: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_46] = (compute_4[cse_var_46] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 43)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_47: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_47] = (compute_4[cse_var_47] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 44)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_48: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_48] = (compute_4[cse_var_48] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 45)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_49: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_49] = (compute_4[cse_var_49] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 46)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_50: int32 = ((i.inner*16) + 2)
              compute_4[cse_var_50] = (compute_4[cse_var_50] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 47)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_51: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_51] = (compute_4[cse_var_51] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 48)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_52: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_52] = (compute_4[cse_var_52] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 49)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_53: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_53] = (compute_4[cse_var_53] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 50)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_54: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_54] = (compute_4[cse_var_54] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 51)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_55: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_55] = (compute_4[cse_var_55] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 52)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_56: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_56] = (compute_4[cse_var_56] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 53)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_57: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_57] = (compute_4[cse_var_57] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 54)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_58: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_58] = (compute_4[cse_var_58] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 55)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_59: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_59] = (compute_4[cse_var_59] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 56)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_60: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_60] = (compute_4[cse_var_60] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 57)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_61: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_61] = (compute_4[cse_var_61] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 58)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_62: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_62] = (compute_4[cse_var_62] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 59)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_63: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_63] = (compute_4[cse_var_63] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 60)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_64: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_64] = (compute_4[cse_var_64] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 61)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_65: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_65] = (compute_4[cse_var_65] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 62)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_66: int32 = ((i.inner*16) + 3)
              compute_4[cse_var_66] = (compute_4[cse_var_66] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 63)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_67: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_67] = (compute_4[cse_var_67] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 64)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_68: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_68] = (compute_4[cse_var_68] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 65)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_69: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_69] = (compute_4[cse_var_69] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 66)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_70: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_70] = (compute_4[cse_var_70] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 67)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_71: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_71] = (compute_4[cse_var_71] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 68)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_72: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_72] = (compute_4[cse_var_72] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 69)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_73: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_73] = (compute_4[cse_var_73] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 70)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_74: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_74] = (compute_4[cse_var_74] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 71)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_75: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_75] = (compute_4[cse_var_75] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 72)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_76: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_76] = (compute_4[cse_var_76] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 73)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_77: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_77] = (compute_4[cse_var_77] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 74)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_78: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_78] = (compute_4[cse_var_78] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 75)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_79: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_79] = (compute_4[cse_var_79] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 76)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_80: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_80] = (compute_4[cse_var_80] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 77)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_81: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_81] = (compute_4[cse_var_81] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 78)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_82: int32 = ((i.inner*16) + 4)
              compute_4[cse_var_82] = (compute_4[cse_var_82] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 79)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_83: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_83] = (compute_4[cse_var_83] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 80)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_84: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_84] = (compute_4[cse_var_84] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 81)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_85: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_85] = (compute_4[cse_var_85] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 82)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_86: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_86] = (compute_4[cse_var_86] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 83)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_87: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_87] = (compute_4[cse_var_87] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 84)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_88: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_88] = (compute_4[cse_var_88] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 85)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_89: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_89] = (compute_4[cse_var_89] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 86)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_90: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_90] = (compute_4[cse_var_90] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 87)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_91: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_91] = (compute_4[cse_var_91] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 88)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_92: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_92] = (compute_4[cse_var_92] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 89)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_93: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_93] = (compute_4[cse_var_93] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 90)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_94: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_94] = (compute_4[cse_var_94] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 91)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_95: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_95] = (compute_4[cse_var_95] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 92)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_96: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_96] = (compute_4[cse_var_96] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 93)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_97: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_97] = (compute_4[cse_var_97] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 94)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_98: int32 = ((i.inner*16) + 5)
              compute_4[cse_var_98] = (compute_4[cse_var_98] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 95)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_99: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_99] = (compute_4[cse_var_99] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 96)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_100: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_100] = (compute_4[cse_var_100] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 97)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_101: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_101] = (compute_4[cse_var_101] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 98)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_102: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_102] = (compute_4[cse_var_102] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 99)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_103: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_103] = (compute_4[cse_var_103] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 100)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_104: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_104] = (compute_4[cse_var_104] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 101)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_105: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_105] = (compute_4[cse_var_105] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 102)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_106: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_106] = (compute_4[cse_var_106] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 103)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_107: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_107] = (compute_4[cse_var_107] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 104)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_108: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_108] = (compute_4[cse_var_108] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 105)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_109: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_109] = (compute_4[cse_var_109] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 106)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_110: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_110] = (compute_4[cse_var_110] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 107)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_111: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_111] = (compute_4[cse_var_111] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 108)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_112: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_112] = (compute_4[cse_var_112] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 109)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_113: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_113] = (compute_4[cse_var_113] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 110)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_114: int32 = ((i.inner*16) + 6)
              compute_4[cse_var_114] = (compute_4[cse_var_114] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 111)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_115: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_115] = (compute_4[cse_var_115] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 112)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_116: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_116] = (compute_4[cse_var_116] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 113)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_117: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_117] = (compute_4[cse_var_117] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 114)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_118: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_118] = (compute_4[cse_var_118] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 115)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_119: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_119] = (compute_4[cse_var_119] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 116)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_120: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_120] = (compute_4[cse_var_120] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 117)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_121: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_121] = (compute_4[cse_var_121] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 118)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_122: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_122] = (compute_4[cse_var_122] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 119)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_123: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_123] = (compute_4[cse_var_123] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 120)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_124: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_124] = (compute_4[cse_var_124] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 121)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_125: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_125] = (compute_4[cse_var_125] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 122)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_126: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_126] = (compute_4[cse_var_126] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 123)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_127: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_127] = (compute_4[cse_var_127] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 124)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_128: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_128] = (compute_4[cse_var_128] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 125)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_129: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_129] = (compute_4[cse_var_129] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 126)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_130: int32 = ((i.inner*16) + 7)
              compute_4[cse_var_130] = (compute_4[cse_var_130] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 127)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_131: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_131] = (compute_4[cse_var_131] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 128)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_132: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_132] = (compute_4[cse_var_132] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 129)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_133: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_133] = (compute_4[cse_var_133] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 130)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_134: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_134] = (compute_4[cse_var_134] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 131)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_135: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_135] = (compute_4[cse_var_135] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 132)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_136: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_136] = (compute_4[cse_var_136] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 133)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_137: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_137] = (compute_4[cse_var_137] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 134)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_138: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_138] = (compute_4[cse_var_138] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 135)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_139: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_139] = (compute_4[cse_var_139] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 136)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_140: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_140] = (compute_4[cse_var_140] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 137)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_141: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_141] = (compute_4[cse_var_141] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 138)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_142: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_142] = (compute_4[cse_var_142] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 139)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_143: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_143] = (compute_4[cse_var_143] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 140)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_144: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_144] = (compute_4[cse_var_144] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 141)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_145: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_145] = (compute_4[cse_var_145] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 142)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_146: int32 = ((i.inner*16) + 8)
              compute_4[cse_var_146] = (compute_4[cse_var_146] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 143)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_147: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_147] = (compute_4[cse_var_147] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 144)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_148: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_148] = (compute_4[cse_var_148] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 145)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_149: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_149] = (compute_4[cse_var_149] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 146)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_150: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_150] = (compute_4[cse_var_150] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 147)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_151: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_151] = (compute_4[cse_var_151] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 148)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_152: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_152] = (compute_4[cse_var_152] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 149)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_153: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_153] = (compute_4[cse_var_153] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 150)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_154: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_154] = (compute_4[cse_var_154] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 151)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_155: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_155] = (compute_4[cse_var_155] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 152)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_156: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_156] = (compute_4[cse_var_156] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 153)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_157: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_157] = (compute_4[cse_var_157] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 154)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_158: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_158] = (compute_4[cse_var_158] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 155)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_159: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_159] = (compute_4[cse_var_159] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 156)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_160: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_160] = (compute_4[cse_var_160] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 157)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_161: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_161] = (compute_4[cse_var_161] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 158)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_162: int32 = ((i.inner*16) + 9)
              compute_4[cse_var_162] = (compute_4[cse_var_162] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 159)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_163: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_163] = (compute_4[cse_var_163] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 160)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_164: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_164] = (compute_4[cse_var_164] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 161)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_165: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_165] = (compute_4[cse_var_165] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 162)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_166: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_166] = (compute_4[cse_var_166] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 163)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_167: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_167] = (compute_4[cse_var_167] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 164)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_168: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_168] = (compute_4[cse_var_168] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 165)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_169: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_169] = (compute_4[cse_var_169] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 166)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_170: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_170] = (compute_4[cse_var_170] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 167)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_171: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_171] = (compute_4[cse_var_171] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 168)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_172: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_172] = (compute_4[cse_var_172] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 169)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_173: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_173] = (compute_4[cse_var_173] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 170)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_174: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_174] = (compute_4[cse_var_174] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 171)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_175: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_175] = (compute_4[cse_var_175] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 172)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_176: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_176] = (compute_4[cse_var_176] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 173)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_177: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_177] = (compute_4[cse_var_177] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 174)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_178: int32 = ((i.inner*16) + 10)
              compute_4[cse_var_178] = (compute_4[cse_var_178] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 175)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_179: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_179] = (compute_4[cse_var_179] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 176)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_180: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_180] = (compute_4[cse_var_180] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 177)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_181: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_181] = (compute_4[cse_var_181] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 178)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_182: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_182] = (compute_4[cse_var_182] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 179)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_183: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_183] = (compute_4[cse_var_183] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 180)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_184: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_184] = (compute_4[cse_var_184] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 181)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_185: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_185] = (compute_4[cse_var_185] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 182)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_186: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_186] = (compute_4[cse_var_186] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 183)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_187: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_187] = (compute_4[cse_var_187] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 184)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_188: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_188] = (compute_4[cse_var_188] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 185)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_189: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_189] = (compute_4[cse_var_189] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 186)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_190: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_190] = (compute_4[cse_var_190] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 187)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_191: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_191] = (compute_4[cse_var_191] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 188)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_192: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_192] = (compute_4[cse_var_192] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 189)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_193: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_193] = (compute_4[cse_var_193] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 190)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_194: int32 = ((i.inner*16) + 11)
              compute_4[cse_var_194] = (compute_4[cse_var_194] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 191)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_195: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_195] = (compute_4[cse_var_195] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 192)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_196: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_196] = (compute_4[cse_var_196] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 193)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_197: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_197] = (compute_4[cse_var_197] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 194)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_198: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_198] = (compute_4[cse_var_198] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 195)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_199: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_199] = (compute_4[cse_var_199] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 196)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_200: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_200] = (compute_4[cse_var_200] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 197)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_201: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_201] = (compute_4[cse_var_201] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 198)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_202: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_202] = (compute_4[cse_var_202] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 199)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_203: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_203] = (compute_4[cse_var_203] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 200)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_204: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_204] = (compute_4[cse_var_204] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 201)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_205: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_205] = (compute_4[cse_var_205] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 202)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_206: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_206] = (compute_4[cse_var_206] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 203)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_207: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_207] = (compute_4[cse_var_207] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 204)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_208: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_208] = (compute_4[cse_var_208] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 205)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_209: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_209] = (compute_4[cse_var_209] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 206)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_210: int32 = ((i.inner*16) + 12)
              compute_4[cse_var_210] = (compute_4[cse_var_210] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 207)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_211: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_211] = (compute_4[cse_var_211] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 208)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_212: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_212] = (compute_4[cse_var_212] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 209)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_213: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_213] = (compute_4[cse_var_213] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 210)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_214: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_214] = (compute_4[cse_var_214] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 211)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_215: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_215] = (compute_4[cse_var_215] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 212)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_216: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_216] = (compute_4[cse_var_216] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 213)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_217: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_217] = (compute_4[cse_var_217] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 214)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_218: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_218] = (compute_4[cse_var_218] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 215)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_219: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_219] = (compute_4[cse_var_219] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 216)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_220: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_220] = (compute_4[cse_var_220] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 217)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_221: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_221] = (compute_4[cse_var_221] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 218)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_222: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_222] = (compute_4[cse_var_222] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 219)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_223: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_223] = (compute_4[cse_var_223] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 220)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_224: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_224] = (compute_4[cse_var_224] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 221)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_225: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_225] = (compute_4[cse_var_225] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 222)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_226: int32 = ((i.inner*16) + 13)
              compute_4[cse_var_226] = (compute_4[cse_var_226] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 223)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_227: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_227] = (compute_4[cse_var_227] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 224)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_228: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_228] = (compute_4[cse_var_228] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 225)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_229: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_229] = (compute_4[cse_var_229] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 226)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_230: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_230] = (compute_4[cse_var_230] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 227)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_231: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_231] = (compute_4[cse_var_231] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 228)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_232: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_232] = (compute_4[cse_var_232] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 229)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_233: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_233] = (compute_4[cse_var_233] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 230)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_234: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_234] = (compute_4[cse_var_234] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 231)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_235: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_235] = (compute_4[cse_var_235] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 232)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_236: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_236] = (compute_4[cse_var_236] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 233)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_237: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_237] = (compute_4[cse_var_237] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 234)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_238: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_238] = (compute_4[cse_var_238] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 235)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_239: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_239] = (compute_4[cse_var_239] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 236)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_240: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_240] = (compute_4[cse_var_240] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 237)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_241: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_241] = (compute_4[cse_var_241] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 238)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_242: int32 = ((i.inner*16) + 14)
              compute_4[cse_var_242] = (compute_4[cse_var_242] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 239)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_243: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_243] = (compute_4[cse_var_243] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 240)]*placeholder_14[(((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16))]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_244: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_244] = (compute_4[cse_var_244] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 241)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 1)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_245: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_245] = (compute_4[cse_var_245] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 242)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 2)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_246: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_246] = (compute_4[cse_var_246] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 243)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 3)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_247: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_247] = (compute_4[cse_var_247] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 244)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 4)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_248: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_248] = (compute_4[cse_var_248] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 245)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 5)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_249: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_249] = (compute_4[cse_var_249] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 246)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 6)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_250: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_250] = (compute_4[cse_var_250] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 247)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 7)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_251: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_251] = (compute_4[cse_var_251] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 248)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 8)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_252: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_252] = (compute_4[cse_var_252] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 249)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 9)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_253: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_253] = (compute_4[cse_var_253] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 250)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 10)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_254: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_254] = (compute_4[cse_var_254] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 251)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 11)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_255: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_255] = (compute_4[cse_var_255] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 252)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 12)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_256: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_256] = (compute_4[cse_var_256] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 253)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 13)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_257: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_257] = (compute_4[cse_var_257] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 254)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 14)]))
            }
            if @tir.likely((elem_idx < (placeholder_12[(cse_var_2 + 1)] - placeholder_12[cse_var_2])), dtype=bool) {
              let cse_var_258: int32 = ((i.inner*16) + 15)
              compute_4[cse_var_258] = (compute_4[cse_var_258] + (placeholder_13[(((placeholder_12[cse_var_2]*256) + (elem_idx*256)) + 255)]*placeholder_14[((((floordiv(m.outer.n.outer.fused, 192)*4608) + (i.inner*768)) + (placeholder_15[(placeholder_12[cse_var_2] + elem_idx)]*16)) + 15)]))
            }
          }
        }
      }
      for (m.inner: int32, 0, 6) {
        for (n.inner: int32, 0, 16) {
          compute_5: Buffer(compute_2, float32, [9437184], [])[((((floordiv(m.outer.n.outer.fused, 192)*18432) + (m.inner*3072)) + (floormod(m.outer.n.outer.fused, 192)*16)) + n.inner)] = compute_4[((m.inner*16) + n.inner)]
        }
      }
    }
  }
}

----------------------------------------------------------------------
------------------------------  [ Call init-search callbacks ]
----------------------------------------------------------------------
Custom sketch rule "SparseDense" added.
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Generate Sketches		#s: 1
Sample Initial Population	#s: 1644	fail_ct: 404	Time elapsed: 2.53
GA Iter: 0	Max score: 1.0000	Min score: 0.9189	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 1.0000	Min score: 0.9883	#Pop: 128	#M+: 1382	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 10.24
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
(3072, 3072)
(3072, 3072)
encoder.layer.9.intermediate.dense.weight Execution time of this operator: 0.285 ms
encoder.layer.9.output.dense.weight: num_row = 768, num_col = 3072, nnz = 12271

==================================================
No: 1	GFLOPS: 4396.25 / 4396.25	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.94, Tstamp:1715259215.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  for i.1 (0,192)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 2	GFLOPS: 2536.23 / 4396.25	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:2.63, Tstamp:1715259215.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 512
  for i.1 (0,384)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 3	GFLOPS: 10651.19 / 10651.19	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.91, Tstamp:1715259215.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 4	GFLOPS: 32095.38 / 32095.38	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259216.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 5	GFLOPS: 7953.81 / 32095.38	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.18, Tstamp:1715259216.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,24)
      compute = ...

==================================================
No: 6	GFLOPS: 1748.19 / 32095.38	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:2.43, Tstamp:1715259216.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    for n.1 (0,2)
      compute = ...

==================================================
No: 7	GFLOPS: 4159.72 / 32095.38	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.24, Tstamp:1715259216.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 8	GFLOPS: 8230.71 / 32095.38	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.07, Tstamp:1715259217.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,48)
  compute auto_unroll: 16
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 9	GFLOPS: 22668.62 / 32095.38	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715259217.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 10	GFLOPS: 17563.91 / 32095.38	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715259217.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 11	GFLOPS: 5188.70 / 32095.38	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.89, Tstamp:1715259217.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 12	GFLOPS: 29143.74 / 32095.38	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715259218.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 13	GFLOPS: 8701.80 / 32095.38	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.86, Tstamp:1715259218.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,48)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    for n.1 (0,8)
      compute = ...

==================================================
No: 14	GFLOPS: 4366.58 / 32095.38	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.88, Tstamp:1715259218.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,384)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 15	GFLOPS: 5636.55 / 32095.38	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.04, Tstamp:1715259219.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 16	GFLOPS: 2950.75 / 32095.38	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:3.41, Tstamp:1715259219.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 17	GFLOPS: 4817.99 / 32095.38	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.11, Tstamp:1715259219.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 18	GFLOPS: 12464.47 / 32095.38	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.97, Tstamp:1715259219.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    compute = ...

==================================================
No: 19	GFLOPS: 36115.45 / 36115.45	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715259220.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 20	GFLOPS: 23832.11 / 36115.45	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.96, Tstamp:1715259220.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 21	GFLOPS: 33782.49 / 36115.45	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.39, Tstamp:1715259220.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 22	GFLOPS: 2111.80 / 36115.45	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:1.47, Tstamp:1715259221.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 23	GFLOPS: 40838.04 / 40838.04	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715259221.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 24	GFLOPS: 13559.48 / 40838.04	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.01, Tstamp:1715259221.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,3)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 25	GFLOPS: 21740.92 / 40838.04	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715259222.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 26	GFLOPS: 21102.57 / 40838.04	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.54, Tstamp:1715259222.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 27	GFLOPS: 8896.04 / 40838.04	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.98, Tstamp:1715259222.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 28	GFLOPS: 14181.88 / 40838.04	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.48, Tstamp:1715259223.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,64)
      for c (0,16)
        compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 29	GFLOPS: 11954.07 / 40838.04	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.62, Tstamp:1715259223.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,16)
    for n.1 (0,6)
      compute = ...

==================================================
No: 30	GFLOPS: 43362.09 / 43362.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715259223.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 31	GFLOPS: 4055.91 / 43362.09	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.69, Tstamp:1715259223.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 64
  for i.1 (0,24)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 32	GFLOPS: 11996.90 / 43362.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715259224.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 33	GFLOPS: 14878.27 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715259224.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,64)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 34	GFLOPS: 13070.58 / 43362.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715259224.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,4)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,24)
      compute = ...

==================================================
No: 35	GFLOPS: 17446.21 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.40, Tstamp:1715259224.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,24)
      compute = ...

==================================================
No: 36	GFLOPS: 10146.83 / 43362.09	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.54, Tstamp:1715259225.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 37	GFLOPS: 14313.56 / 43362.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.89, Tstamp:1715259225.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 38	GFLOPS: 4192.07 / 43362.09	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.65, Tstamp:1715259225.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 39	GFLOPS: 5820.48 / 43362.09	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.07, Tstamp:1715259226.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 512
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 40	GFLOPS: 4328.86 / 43362.09	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:0.66, Tstamp:1715259226.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 41	GFLOPS: 2943.37 / 43362.09	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.42, Tstamp:1715259226.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 42	GFLOPS: 11606.96 / 43362.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.13, Tstamp:1715259226.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 43	GFLOPS: 1515.55 / 43362.09	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:1.02, Tstamp:1715259227.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 44	GFLOPS: 18126.28 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.35, Tstamp:1715259227.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,32)
      for c (0,16)
        compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 45	GFLOPS: 10118.80 / 43362.09	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.25, Tstamp:1715259227.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 46	GFLOPS: 5079.53 / 43362.09	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.34, Tstamp:1715259227.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 47	GFLOPS: 29377.52 / 43362.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259228.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 48	GFLOPS: 8528.53 / 43362.09	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.43, Tstamp:1715259228.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 49	GFLOPS: 30616.47 / 43362.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259228.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 50	GFLOPS: 11659.31 / 43362.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.73, Tstamp:1715259229.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 51	GFLOPS: 28883.91 / 43362.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715259229.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 52	GFLOPS: 2874.90 / 43362.09	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.92, Tstamp:1715259229.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    for n.1 (0,2)
      compute = ...

==================================================
No: 53	GFLOPS: 17433.06 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.92, Tstamp:1715259229.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,64)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 54	GFLOPS: 2992.65 / 43362.09	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:3.83, Tstamp:1715259230.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,32)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 55	GFLOPS: 22935.73 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.42, Tstamp:1715259230.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    for n.1 (0,48)
      compute = ...

==================================================
No: 56	GFLOPS: 11369.31 / 43362.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.43, Tstamp:1715259230.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 57	GFLOPS: 3616.74 / 43362.09	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.66, Tstamp:1715259231.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,48)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,48)
      compute = ...

==================================================
No: 58	GFLOPS: 2978.94 / 43362.09	results: MeasureResult(cost:[0.0012], error_no:0, all_cost:0.39, Tstamp:1715259231.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 59	GFLOPS: 1490.98 / 43362.09	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.57, Tstamp:1715259231.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    for n.1 (0,2)
      compute = ...

==================================================
No: 60	GFLOPS: 4655.75 / 43362.09	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:2.74, Tstamp:1715259232.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,24)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 61	GFLOPS: 20027.50 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715259232.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 62	GFLOPS: 2059.30 / 43362.09	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:0.37, Tstamp:1715259232.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 63	GFLOPS: 9477.43 / 43362.09	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.39, Tstamp:1715259233.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 64	GFLOPS: 8645.78 / 43362.09	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.52, Tstamp:1715259233.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 28.31 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.72 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1660	fail_ct: 388	Time elapsed: 2.50
GA Iter: 0	Max score: 0.9995	Min score: 0.9205	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9999	Min score: 0.9870	#Pop: 128	#M+: 1381	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 10.22
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 65	GFLOPS: 21970.65 / 43362.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715259256.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 66	GFLOPS: 43715.80 / 43715.80	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.74, Tstamp:1715259257.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 67	GFLOPS: 513.80 / 43715.80	results: MeasureResult(cost:[0.0071], error_no:0, all_cost:1.07, Tstamp:1715259257.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
for n.0 (0,96)
  compute auto_unroll: 16
  for i.1 (0,384)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 68	GFLOPS: 2052.47 / 43715.80	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:1.48, Tstamp:1715259257.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 69	GFLOPS: 3170.09 / 43715.80	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.61, Tstamp:1715259257.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 70	GFLOPS: 14314.85 / 43715.80	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.14, Tstamp:1715259258.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 71	GFLOPS: 4590.84 / 43715.80	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:1.14, Tstamp:1715259258.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 72	GFLOPS: 11121.27 / 43715.80	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.68, Tstamp:1715259258.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,48)
      compute = ...

==================================================
No: 73	GFLOPS: 1149.15 / 43715.80	results: MeasureResult(cost:[0.0032], error_no:0, all_cost:1.90, Tstamp:1715259259.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 74	GFLOPS: 7577.79 / 43715.80	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:1.08, Tstamp:1715259259.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 75	GFLOPS: 3168.84 / 43715.80	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.68, Tstamp:1715259259.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,64)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 76	GFLOPS: 13352.02 / 43715.80	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.44, Tstamp:1715259260.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,32)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 77	GFLOPS: 35167.02 / 43715.80	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715259260.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 78	GFLOPS: 31452.40 / 43715.80	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715259260.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 79	GFLOPS: 8066.75 / 43715.80	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:3.17, Tstamp:1715259260.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,16384)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 80	GFLOPS: 7630.27 / 43715.80	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.85, Tstamp:1715259261.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    for n.1 (0,8)
      compute = ...

==================================================
No: 81	GFLOPS: 2037.74 / 43715.80	results: MeasureResult(cost:[0.0018], error_no:0, all_cost:3.56, Tstamp:1715259261.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 82	GFLOPS: 10946.67 / 43715.80	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:1.69, Tstamp:1715259261.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 512
  for i.1 (0,96)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 83	GFLOPS: 7157.29 / 43715.80	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.80, Tstamp:1715259261.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 84	GFLOPS: 4235.08 / 43715.80	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.27, Tstamp:1715259262.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 85	GFLOPS: 45662.09 / 45662.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259262.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 86	GFLOPS: 4048.31 / 45662.09	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:1.11, Tstamp:1715259262.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 87	GFLOPS: 4679.06 / 45662.09	results: MeasureResult(cost:[0.0008], error_no:0, all_cost:4.38, Tstamp:1715259263.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,6)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,64)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 88	GFLOPS: 1391.22 / 45662.09	results: MeasureResult(cost:[0.0026], error_no:0, all_cost:0.66, Tstamp:1715259263.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 89	GFLOPS: 4863.20 / 45662.09	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:1.23, Tstamp:1715259263.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 90	GFLOPS: 3357.85 / 45662.09	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:1.41, Tstamp:1715259263.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    for n.1 (0,4)
      compute = ...

==================================================
No: 91	GFLOPS: 8045.85 / 45662.09	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.77, Tstamp:1715259263.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 92	GFLOPS: 10936.36 / 45662.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.79, Tstamp:1715259264.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 93	GFLOPS: 5793.78 / 45662.09	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.69, Tstamp:1715259264.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,384)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 94	GFLOPS: 8700.84 / 45662.09	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.47, Tstamp:1715259264.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,64)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    compute = ...

==================================================
No: 95	GFLOPS: 20939.55 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715259265.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 96	GFLOPS: 41763.45 / 45662.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715259265.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 97	GFLOPS: 21736.72 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715259265.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 98	GFLOPS: 22973.24 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.45, Tstamp:1715259266.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,24)
      compute = ...

==================================================
No: 99	GFLOPS: 7064.93 / 45662.09	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.35, Tstamp:1715259266.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    compute = ...

==================================================
No: 100	GFLOPS: 5636.18 / 45662.09	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:1.24, Tstamp:1715259266.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,2)
      compute = ...

==================================================
No: 101	GFLOPS: 2794.15 / 45662.09	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:1.77, Tstamp:1715259267.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,128)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 102	GFLOPS: 10993.61 / 45662.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.59, Tstamp:1715259267.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,4)
      compute = ...

==================================================
No: 103	GFLOPS: 2116.02 / 45662.09	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.65, Tstamp:1715259267.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 104	GFLOPS: 15965.80 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.49, Tstamp:1715259267.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,96)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 105	GFLOPS: 10945.34 / 45662.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.47, Tstamp:1715259268.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    compute = ...

==================================================
No: 106	GFLOPS: 21796.18 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715259268.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 107	GFLOPS: 42537.91 / 45662.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.39, Tstamp:1715259268.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 108	GFLOPS: 18571.85 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.32, Tstamp:1715259268.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,64)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 109	GFLOPS: 5260.84 / 45662.09	results: MeasureResult(cost:[0.0007], error_no:0, all_cost:0.52, Tstamp:1715259269.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 110	GFLOPS: 1800.49 / 45662.09	results: MeasureResult(cost:[0.0020], error_no:0, all_cost:0.54, Tstamp:1715259269.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,48)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 111	GFLOPS: 21253.31 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.71, Tstamp:1715259269.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 112	GFLOPS: 14384.44 / 45662.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.56, Tstamp:1715259270.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 113	GFLOPS: 3891.87 / 45662.09	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:3.31, Tstamp:1715259270.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,64)
    for n.1 (0,3)
      compute = ...

==================================================
No: 114	GFLOPS: 2116.88 / 45662.09	results: MeasureResult(cost:[0.0017], error_no:0, all_cost:0.83, Tstamp:1715259270.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,48)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 115	GFLOPS: 3156.19 / 45662.09	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.82, Tstamp:1715259271.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 116	GFLOPS: 12607.76 / 45662.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.60, Tstamp:1715259271.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 117	GFLOPS: 6001.19 / 45662.09	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:2.10, Tstamp:1715259271.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  compute auto_unroll: 512
  for i.1 (0,96)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,192)
    for n.1 (0,24)
      compute = ...

==================================================
No: 118	GFLOPS: 6943.56 / 45662.09	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.50, Tstamp:1715259271.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 119	GFLOPS: 4035.90 / 45662.09	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.56, Tstamp:1715259272.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 64
  for i.1 (0,48)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,768)
    for n.1 (0,24)
      compute = ...

==================================================
No: 120	GFLOPS: 28451.41 / 45662.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259272.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 121	GFLOPS: 7077.46 / 45662.09	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.55, Tstamp:1715259272.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,32)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 122	GFLOPS: 17139.49 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715259272.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 123	GFLOPS: 26314.75 / 45662.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259273.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 124	GFLOPS: 5638.21 / 45662.09	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.81, Tstamp:1715259273.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 125	GFLOPS: 15835.89 / 45662.09	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715259273.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 126	GFLOPS: 13368.88 / 45662.09	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.52, Tstamp:1715259274.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 64
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 127	GFLOPS: 35766.33 / 45662.09	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259274.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 128	GFLOPS: 2727.04 / 45662.09	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.53, Tstamp:1715259274.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 28.02 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.94 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1687	fail_ct: 361	Time elapsed: 2.57
GA Iter: 0	Max score: 0.9600	Min score: 0.5745	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9975	Min score: 0.8603	#Pop: 128	#M+: 1380	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 10.02
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 129	GFLOPS: 45757.72 / 45757.72	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259295.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 130	GFLOPS: 45157.10 / 45757.72	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.28, Tstamp:1715259296.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 131	GFLOPS: 52404.03 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.90, Tstamp:1715259296.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 132	GFLOPS: 51108.60 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.00, Tstamp:1715259296.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 133	GFLOPS: 24769.60 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259296.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 134	GFLOPS: 43184.22 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715259297.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 135	GFLOPS: 24654.60 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715259297.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 136	GFLOPS: 24761.30 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715259297.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 137	GFLOPS: 23630.62 / 52404.03	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.81, Tstamp:1715259298.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 138	GFLOPS: 42765.85 / 52404.03	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715259298.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 139	GFLOPS: 56220.20 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.84, Tstamp:1715259298.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 140	GFLOPS: 40985.98 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715259298.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 141	GFLOPS: 41922.59 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715259299.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 142	GFLOPS: 42149.60 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259299.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 143	GFLOPS: 44201.40 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259299.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 144	GFLOPS: 43289.73 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715259299.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 145	GFLOPS: 43572.35 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715259299.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 146	GFLOPS: 44953.89 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.88, Tstamp:1715259300.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 147	GFLOPS: 46229.27 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259300.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 148	GFLOPS: 42080.82 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715259300.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 149	GFLOPS: 36672.96 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.88, Tstamp:1715259301.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 150	GFLOPS: 42097.87 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259301.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 151	GFLOPS: 46074.47 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259301.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 152	GFLOPS: 33774.73 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715259302.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 153	GFLOPS: 48123.51 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259302.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 154	GFLOPS: 45969.26 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715259302.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 155	GFLOPS: 56156.33 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715259302.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 156	GFLOPS: 42289.18 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259303.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 157	GFLOPS: 47349.66 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715259303.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 158	GFLOPS: 45678.26 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259303.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 159	GFLOPS: 45583.14 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715259303.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 160	GFLOPS: 43531.59 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259304.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 161	GFLOPS: 41577.66 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259304.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 162	GFLOPS: 46159.82 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715259304.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 163	GFLOPS: 41476.11 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715259305.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 164	GFLOPS: 40963.60 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259305.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 165	GFLOPS: 33567.50 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259305.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 166	GFLOPS: 39210.84 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715259306.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 167	GFLOPS: 31745.31 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259306.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 168	GFLOPS: 42727.74 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259306.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 169	GFLOPS: 31088.72 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259307.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 170	GFLOPS: 40449.96 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.12, Tstamp:1715259307.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 171	GFLOPS: 28079.62 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259307.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 172	GFLOPS: 43083.71 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.38, Tstamp:1715259307.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 173	GFLOPS: 45832.42 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259308.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 174	GFLOPS: 48454.19 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259308.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 175	GFLOPS: 46217.19 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259308.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 176	GFLOPS: 43658.53 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.39, Tstamp:1715259309.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 177	GFLOPS: 44175.05 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259309.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 178	GFLOPS: 41931.09 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.37, Tstamp:1715259309.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 179	GFLOPS: 34161.52 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259310.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 180	GFLOPS: 45985.78 / 56220.20	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715259310.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 181	GFLOPS: 56494.89 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715259310.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 182	GFLOPS: 36017.17 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.35, Tstamp:1715259310.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 183	GFLOPS: 38123.40 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259311.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 184	GFLOPS: 39565.30 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715259311.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 185	GFLOPS: 43254.53 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715259311.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 186	GFLOPS: 42962.42 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259312.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 187	GFLOPS: 42745.30 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259312.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 188	GFLOPS: 48834.58 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259312.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 189	GFLOPS: 46737.17 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259313.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 190	GFLOPS: 3275.96 / 56494.89	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.30, Tstamp:1715259313.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 191	GFLOPS: 1532.76 / 56494.89	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.46, Tstamp:1715259313.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 192	GFLOPS: 10776.36 / 56494.89	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.41, Tstamp:1715259313.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,128)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 25.37 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.75 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1642	fail_ct: 406	Time elapsed: 2.54
GA Iter: 0	Max score: 0.9352	Min score: 0.4674	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9352	Min score: 0.6910	#Pop: 128	#M+: 1379	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 9.92
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 193	GFLOPS: 43510.37 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.72, Tstamp:1715259336.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 194	GFLOPS: 51773.96 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.32, Tstamp:1715259336.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 195	GFLOPS: 48757.88 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.15, Tstamp:1715259337.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 196	GFLOPS: 46305.92 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.39, Tstamp:1715259337.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 197	GFLOPS: 32773.67 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.83, Tstamp:1715259338.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 198	GFLOPS: 33062.25 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.55, Tstamp:1715259338.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 199	GFLOPS: 37069.92 / 56494.89	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.86, Tstamp:1715259338.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 200	GFLOPS: 59326.47 / 59326.47	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.06, Tstamp:1715259338.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 201	GFLOPS: 54079.47 / 59326.47	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.15, Tstamp:1715259339.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 202	GFLOPS: 56603.63 / 59326.47	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.85, Tstamp:1715259339.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 203	GFLOPS: 29359.97 / 59326.47	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.15, Tstamp:1715259339.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 204	GFLOPS: 33893.66 / 59326.47	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.00, Tstamp:1715259339.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 205	GFLOPS: 43830.28 / 59326.47	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.89, Tstamp:1715259340.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 206	GFLOPS: 59748.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.94, Tstamp:1715259340.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 207	GFLOPS: 30207.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.97, Tstamp:1715259340.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 208	GFLOPS: 57907.96 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.47, Tstamp:1715259341.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 209	GFLOPS: 30024.41 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.89, Tstamp:1715259341.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 210	GFLOPS: 53108.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.83, Tstamp:1715259341.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 211	GFLOPS: 29339.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.66, Tstamp:1715259341.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 212	GFLOPS: 32020.22 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.68, Tstamp:1715259342.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 213	GFLOPS: 25600.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.73, Tstamp:1715259342.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 214	GFLOPS: 42653.98 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.58, Tstamp:1715259342.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 215	GFLOPS: 43573.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259343.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 216	GFLOPS: 28906.40 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715259343.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 217	GFLOPS: 30975.80 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.49, Tstamp:1715259343.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 218	GFLOPS: 39480.41 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259343.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 219	GFLOPS: 28222.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259344.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 220	GFLOPS: 39205.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715259344.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 221	GFLOPS: 21981.22 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.68, Tstamp:1715259344.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 222	GFLOPS: 31347.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259344.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 223	GFLOPS: 44374.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259345.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 224	GFLOPS: 34694.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.99, Tstamp:1715259345.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 225	GFLOPS: 25582.58 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.57, Tstamp:1715259345.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 226	GFLOPS: 24741.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.47, Tstamp:1715259346.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 227	GFLOPS: 43566.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.30, Tstamp:1715259346.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 228	GFLOPS: 50309.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.58, Tstamp:1715259346.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 229	GFLOPS: 33957.64 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259347.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 230	GFLOPS: 24009.10 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.15, Tstamp:1715259347.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 231	GFLOPS: 44936.22 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259347.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 232	GFLOPS: 23500.61 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715259348.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 233	GFLOPS: 31173.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715259348.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 234	GFLOPS: 35070.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259348.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 235	GFLOPS: 22264.81 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715259349.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 236	GFLOPS: 39733.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.43, Tstamp:1715259349.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 237	GFLOPS: 25108.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.42, Tstamp:1715259349.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 238	GFLOPS: 27325.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.43, Tstamp:1715259349.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 239	GFLOPS: 47067.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259350.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 240	GFLOPS: 55084.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.35, Tstamp:1715259350.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 241	GFLOPS: 35801.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259350.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 242	GFLOPS: 23044.15 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.66, Tstamp:1715259351.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 243	GFLOPS: 45067.61 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715259351.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 244	GFLOPS: 48246.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.41, Tstamp:1715259351.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 245	GFLOPS: 28558.72 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715259352.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 246	GFLOPS: 44063.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.11, Tstamp:1715259352.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 247	GFLOPS: 34677.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.41, Tstamp:1715259352.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 248	GFLOPS: 38258.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259353.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 249	GFLOPS: 35910.13 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715259353.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 250	GFLOPS: 50519.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259353.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 251	GFLOPS: 43083.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259354.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 252	GFLOPS: 46267.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259354.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 253	GFLOPS: 41494.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259354.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 254	GFLOPS: 15993.79 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715259354.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

==================================================
No: 255	GFLOPS: 1949.74 / 59748.01	results: MeasureResult(cost:[0.0019], error_no:0, all_cost:3.08, Tstamp:1715259355.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,8)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,16)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 256	GFLOPS: 32414.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259355.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

Time elapsed for measurement: 28.50 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.79 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1674	fail_ct: 374	Time elapsed: 2.61
GA Iter: 0	Max score: 0.7479	Min score: 0.3953	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.9618	Min score: 0.6149	#Pop: 128	#M+: 1382	#M-: 74
EvolutionarySearch		#s: 128	Time elapsed: 9.89
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 257	GFLOPS: 31402.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.71, Tstamp:1715259377.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 258	GFLOPS: 24054.62 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.61, Tstamp:1715259377.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 259	GFLOPS: 31310.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.65, Tstamp:1715259377.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 260	GFLOPS: 44708.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.93, Tstamp:1715259378.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 261	GFLOPS: 47773.55 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.06, Tstamp:1715259378.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 262	GFLOPS: 41370.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715259378.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 263	GFLOPS: 47933.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.45, Tstamp:1715259379.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 264	GFLOPS: 37128.09 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259379.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 265	GFLOPS: 45387.73 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.15, Tstamp:1715259379.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 266	GFLOPS: 33568.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.43, Tstamp:1715259380.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 267	GFLOPS: 46125.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259380.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 268	GFLOPS: 45874.65 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259380.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 269	GFLOPS: 33249.66 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715259381.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 270	GFLOPS: 45178.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259381.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 271	GFLOPS: 28617.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259381.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 272	GFLOPS: 24611.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.56, Tstamp:1715259382.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 273	GFLOPS: 46905.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259382.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 274	GFLOPS: 30863.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715259382.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 275	GFLOPS: 33730.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259383.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 276	GFLOPS: 33836.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.99, Tstamp:1715259383.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 277	GFLOPS: 39097.17 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.40, Tstamp:1715259383.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 278	GFLOPS: 21981.30 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.92, Tstamp:1715259383.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 279	GFLOPS: 45984.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259384.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 280	GFLOPS: 15735.48 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.88, Tstamp:1715259384.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 281	GFLOPS: 27100.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.88, Tstamp:1715259384.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,16)
        compute = ...

==================================================
No: 282	GFLOPS: 26992.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715259385.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 283	GFLOPS: 33468.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259385.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 284	GFLOPS: 33590.41 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715259385.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 285	GFLOPS: 31167.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715259386.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 286	GFLOPS: 48964.85 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.20, Tstamp:1715259386.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 287	GFLOPS: 30997.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259386.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,16)
        compute = ...

==================================================
No: 288	GFLOPS: 26731.58 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715259386.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 289	GFLOPS: 39512.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715259387.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 290	GFLOPS: 34758.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259387.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 291	GFLOPS: 32520.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259387.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 292	GFLOPS: 37528.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259388.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 293	GFLOPS: 42062.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715259388.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 294	GFLOPS: 40780.90 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.54, Tstamp:1715259388.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 295	GFLOPS: 26445.20 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259389.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 296	GFLOPS: 38065.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.00, Tstamp:1715259389.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 297	GFLOPS: 32095.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715259389.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 298	GFLOPS: 29335.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259390.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 299	GFLOPS: 38309.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259390.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 300	GFLOPS: 44309.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.37, Tstamp:1715259390.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 301	GFLOPS: 42468.55 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259391.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 302	GFLOPS: 33109.83 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.46, Tstamp:1715259391.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 303	GFLOPS: 28250.03 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.34, Tstamp:1715259391.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 304	GFLOPS: 30860.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259391.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 305	GFLOPS: 30165.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259392.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 306	GFLOPS: 38809.11 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715259392.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 307	GFLOPS: 27427.39 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715259392.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 308	GFLOPS: 48858.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259393.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 309	GFLOPS: 35324.85 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715259393.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 310	GFLOPS: 43354.90 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715259393.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 311	GFLOPS: 31741.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259394.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,24)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 312	GFLOPS: 48524.80 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.17, Tstamp:1715259394.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 313	GFLOPS: 34641.96 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259394.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 314	GFLOPS: 44667.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259394.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 315	GFLOPS: 29509.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715259395.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 316	GFLOPS: 44257.17 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.41, Tstamp:1715259395.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 317	GFLOPS: 29529.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715259395.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 318	GFLOPS: 3616.80 / 59748.01	results: MeasureResult(cost:[0.0010], error_no:0, all_cost:0.44, Tstamp:1715259396.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,96)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 319	GFLOPS: 22815.14 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715259396.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 320	GFLOPS: 2832.37 / 59748.01	results: MeasureResult(cost:[0.0013], error_no:0, all_cost:0.45, Tstamp:1715259396.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,768)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,768)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 27.66 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.12 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1665	fail_ct: 383	Time elapsed: 2.57
GA Iter: 0	Max score: 0.8144	Min score: 0.4102	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8411	Min score: 0.6009	#Pop: 128	#M+: 1376	#M-: 72
EvolutionarySearch		#s: 128	Time elapsed: 10.12
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 321	GFLOPS: 37398.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.31, Tstamp:1715259419.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 322	GFLOPS: 57410.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.47, Tstamp:1715259419.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 323	GFLOPS: 46388.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715259419.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 324	GFLOPS: 29409.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.14, Tstamp:1715259420.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 325	GFLOPS: 41433.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.26, Tstamp:1715259420.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 326	GFLOPS: 44154.51 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.89, Tstamp:1715259420.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 327	GFLOPS: 34516.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259421.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 328	GFLOPS: 37467.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.52, Tstamp:1715259421.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 329	GFLOPS: 33016.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.77, Tstamp:1715259421.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 330	GFLOPS: 43857.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.15, Tstamp:1715259421.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 331	GFLOPS: 30464.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259422.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 332	GFLOPS: 30273.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.57, Tstamp:1715259422.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 333	GFLOPS: 47740.12 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715259422.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 334	GFLOPS: 36927.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.11, Tstamp:1715259423.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 335	GFLOPS: 44049.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259423.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 336	GFLOPS: 35941.75 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.76, Tstamp:1715259423.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 337	GFLOPS: 47930.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.28, Tstamp:1715259424.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 338	GFLOPS: 50368.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259424.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 339	GFLOPS: 44789.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.42, Tstamp:1715259424.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 340	GFLOPS: 49066.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259425.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 341	GFLOPS: 32595.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715259425.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 342	GFLOPS: 48507.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259425.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 343	GFLOPS: 45608.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715259426.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 344	GFLOPS: 50861.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.47, Tstamp:1715259426.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 345	GFLOPS: 48629.13 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259426.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 346	GFLOPS: 49376.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259427.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 347	GFLOPS: 45724.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259427.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 348	GFLOPS: 47591.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259427.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 349	GFLOPS: 43473.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.68, Tstamp:1715259428.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 350	GFLOPS: 46002.66 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259428.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 351	GFLOPS: 46484.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259428.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 352	GFLOPS: 35876.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.89, Tstamp:1715259429.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 353	GFLOPS: 49558.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259429.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 354	GFLOPS: 48774.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259429.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 355	GFLOPS: 42508.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.56, Tstamp:1715259430.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 356	GFLOPS: 35246.61 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715259430.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 357	GFLOPS: 49755.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259430.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 358	GFLOPS: 37964.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715259430.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 359	GFLOPS: 49028.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259431.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 360	GFLOPS: 34934.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259431.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 361	GFLOPS: 42694.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715259431.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 362	GFLOPS: 35761.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259432.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 363	GFLOPS: 46780.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.06, Tstamp:1715259432.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 364	GFLOPS: 44075.83 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715259432.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 365	GFLOPS: 44959.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259433.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 366	GFLOPS: 40843.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715259433.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 367	GFLOPS: 48559.89 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259433.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 368	GFLOPS: 40612.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259434.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 369	GFLOPS: 34892.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259434.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 370	GFLOPS: 36406.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259434.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 371	GFLOPS: 48036.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259435.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 372	GFLOPS: 47794.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259435.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 373	GFLOPS: 34616.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259435.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 374	GFLOPS: 39696.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259436.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 375	GFLOPS: 22090.82 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.45, Tstamp:1715259436.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 376	GFLOPS: 35166.09 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259436.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 377	GFLOPS: 25938.16 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259436.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 378	GFLOPS: 39980.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259437.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 379	GFLOPS: 45940.44 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259437.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 380	GFLOPS: 42322.39 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259438.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 381	GFLOPS: 44793.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.03, Tstamp:1715259438.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 382	GFLOPS: 8905.02 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.23, Tstamp:1715259438.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 383	GFLOPS: 8156.63 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.54, Tstamp:1715259439.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,2)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 384	GFLOPS: 1490.74 / 59748.01	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.63, Tstamp:1715259439.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,256)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 29.16 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.98 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1672	fail_ct: 376	Time elapsed: 2.51
GA Iter: 0	Max score: 0.7502	Min score: 0.3736	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8600	Min score: 0.5801	#Pop: 128	#M+: 1374	#M-: 73
EvolutionarySearch		#s: 128	Time elapsed: 10.14
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 385	GFLOPS: 22355.20 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.87, Tstamp:1715259461.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 386	GFLOPS: 23089.48 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715259461.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 387	GFLOPS: 49179.10 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715259461.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 388	GFLOPS: 46924.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715259462.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 389	GFLOPS: 37016.17 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.41, Tstamp:1715259462.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 390	GFLOPS: 49450.55 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715259462.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 391	GFLOPS: 49859.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715259463.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 392	GFLOPS: 48987.18 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259463.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 393	GFLOPS: 49973.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259464.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 394	GFLOPS: 48324.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715259464.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 395	GFLOPS: 45889.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259464.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 396	GFLOPS: 48824.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.10, Tstamp:1715259464.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 397	GFLOPS: 43114.51 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715259465.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 398	GFLOPS: 41672.51 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.98, Tstamp:1715259465.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 399	GFLOPS: 45800.99 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259465.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 400	GFLOPS: 46702.26 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259465.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 401	GFLOPS: 43703.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715259466.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 402	GFLOPS: 45758.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715259466.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 403	GFLOPS: 45579.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259467.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 404	GFLOPS: 34823.83 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259467.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 405	GFLOPS: 42960.47 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259467.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 406	GFLOPS: 46877.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259467.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 407	GFLOPS: 51395.40 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.88, Tstamp:1715259468.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 408	GFLOPS: 45457.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.00, Tstamp:1715259468.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 409	GFLOPS: 49699.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.58, Tstamp:1715259468.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 410	GFLOPS: 48379.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715259469.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 411	GFLOPS: 49696.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259469.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 412	GFLOPS: 45487.10 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715259469.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 413	GFLOPS: 43691.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259469.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 414	GFLOPS: 40565.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715259470.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 415	GFLOPS: 43328.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715259470.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 416	GFLOPS: 40311.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.78, Tstamp:1715259470.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 417	GFLOPS: 46052.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259471.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 418	GFLOPS: 41698.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259471.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 419	GFLOPS: 27989.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715259471.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 420	GFLOPS: 36850.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715259471.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 421	GFLOPS: 39945.43 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259472.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 422	GFLOPS: 42088.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259472.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 423	GFLOPS: 41518.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259473.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 424	GFLOPS: 40102.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259473.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 425	GFLOPS: 44031.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715259473.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 426	GFLOPS: 40326.40 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259474.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 427	GFLOPS: 34771.10 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259474.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 428	GFLOPS: 39115.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715259474.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 429	GFLOPS: 39676.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715259474.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 430	GFLOPS: 45175.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715259475.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 431	GFLOPS: 40717.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259475.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 432	GFLOPS: 33053.44 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259475.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 433	GFLOPS: 33385.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259476.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 434	GFLOPS: 23666.58 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.42, Tstamp:1715259476.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 435	GFLOPS: 35137.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259476.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 436	GFLOPS: 37320.44 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.61, Tstamp:1715259477.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 437	GFLOPS: 47392.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259477.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 438	GFLOPS: 33783.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.22, Tstamp:1715259477.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 439	GFLOPS: 47933.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259477.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 440	GFLOPS: 35377.11 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259478.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 441	GFLOPS: 38222.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.46, Tstamp:1715259478.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 442	GFLOPS: 42562.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.34, Tstamp:1715259478.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 443	GFLOPS: 45626.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259479.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 444	GFLOPS: 39350.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.46, Tstamp:1715259479.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 445	GFLOPS: 35814.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259479.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 446	GFLOPS: 6022.11 / 59748.01	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.32, Tstamp:1715259479.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,48)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,8)
      compute = ...

==================================================
No: 447	GFLOPS: 15997.39 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715259480.19)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 101), 96))
    for i.1 (0,12)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 128)*6), 16) + 5), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,6)
      compute = ...

==================================================
No: 448	GFLOPS: 15295.41 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715259480.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,288)
  compute auto_unroll: 512
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,128)
    vectorize n.1 (0,16)
      compute = ...

Time elapsed for measurement: 27.01 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.21 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1674	fail_ct: 374	Time elapsed: 2.55
GA Iter: 0	Max score: 0.7426	Min score: 0.3834	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8517	Min score: 0.5989	#Pop: 128	#M+: 1380	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 10.16
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 449	GFLOPS: 38126.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.05, Tstamp:1715259504.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 450	GFLOPS: 41311.73 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.63, Tstamp:1715259504.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 451	GFLOPS: 43723.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259505.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 452	GFLOPS: 43431.55 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259505.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 453	GFLOPS: 42952.12 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715259505.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 454	GFLOPS: 43783.96 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.46, Tstamp:1715259506.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 455	GFLOPS: 39493.92 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.71, Tstamp:1715259506.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 456	GFLOPS: 43261.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715259506.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 457	GFLOPS: 41497.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715259506.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 458	GFLOPS: 51314.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259507.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 459	GFLOPS: 44177.72 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715259507.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 460	GFLOPS: 29465.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259508.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 461	GFLOPS: 48892.90 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259508.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 462	GFLOPS: 31118.61 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.77, Tstamp:1715259508.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 463	GFLOPS: 30717.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259509.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 464	GFLOPS: 33555.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.68, Tstamp:1715259509.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 465	GFLOPS: 41733.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.90, Tstamp:1715259509.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 466	GFLOPS: 39390.10 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.68, Tstamp:1715259509.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 467	GFLOPS: 36376.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259510.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 468	GFLOPS: 35658.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715259510.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 469	GFLOPS: 36921.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259510.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 470	GFLOPS: 25206.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259510.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 471	GFLOPS: 41281.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.28, Tstamp:1715259511.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 472	GFLOPS: 30927.40 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259511.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 473	GFLOPS: 43640.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259511.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 474	GFLOPS: 34453.36 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259512.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 475	GFLOPS: 45339.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.16, Tstamp:1715259512.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,48)
        compute = ...

==================================================
No: 476	GFLOPS: 48208.96 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259512.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 477	GFLOPS: 37080.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715259513.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 478	GFLOPS: 32026.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.39, Tstamp:1715259513.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 479	GFLOPS: 46290.44 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715259513.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 480	GFLOPS: 25837.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.23, Tstamp:1715259513.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 481	GFLOPS: 33851.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715259514.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 482	GFLOPS: 34237.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259514.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 483	GFLOPS: 32710.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715259514.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 484	GFLOPS: 48431.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259515.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 485	GFLOPS: 43969.18 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259515.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 486	GFLOPS: 39067.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259515.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 487	GFLOPS: 35007.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.25, Tstamp:1715259516.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 488	GFLOPS: 45834.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715259516.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 489	GFLOPS: 41439.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259516.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 490	GFLOPS: 32241.80 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.12, Tstamp:1715259517.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 491	GFLOPS: 39050.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259517.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 492	GFLOPS: 29731.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259517.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 493	GFLOPS: 43474.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.03, Tstamp:1715259517.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 494	GFLOPS: 30669.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259518.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 495	GFLOPS: 52058.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.36, Tstamp:1715259518.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 496	GFLOPS: 47223.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715259519.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 497	GFLOPS: 43920.89 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259519.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 498	GFLOPS: 39483.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715259519.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 499	GFLOPS: 24480.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.35, Tstamp:1715259519.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 500	GFLOPS: 34450.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259520.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 501	GFLOPS: 26615.72 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.32, Tstamp:1715259520.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 502	GFLOPS: 32408.17 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259520.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 503	GFLOPS: 30145.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259521.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 504	GFLOPS: 30481.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.34, Tstamp:1715259521.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 505	GFLOPS: 43596.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.70, Tstamp:1715259521.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 506	GFLOPS: 34524.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259522.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 507	GFLOPS: 34098.20 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.23, Tstamp:1715259522.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 508	GFLOPS: 32919.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715259522.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 509	GFLOPS: 24157.32 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.63, Tstamp:1715259522.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 510	GFLOPS: 23718.88 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.31, Tstamp:1715259523.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 511	GFLOPS: 12365.89 / 59748.01	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:5.01, Tstamp:1715259523.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,8192)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,3)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 512	GFLOPS: 8974.41 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.20, Tstamp:1715259523.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 29.35 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.20 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1646	fail_ct: 402	Time elapsed: 2.57
GA Iter: 0	Max score: 0.8042	Min score: 0.3686	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8042	Min score: 0.5797	#Pop: 128	#M+: 1385	#M-: 83
EvolutionarySearch		#s: 128	Time elapsed: 10.21
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 513	GFLOPS: 23471.40 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715259545.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 514	GFLOPS: 18902.08 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.89, Tstamp:1715259545.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 515	GFLOPS: 39585.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.19, Tstamp:1715259545.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 516	GFLOPS: 46328.12 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715259546.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 517	GFLOPS: 51554.98 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715259546.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 518	GFLOPS: 59411.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.08, Tstamp:1715259547.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 519	GFLOPS: 48443.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715259547.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 520	GFLOPS: 46585.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715259547.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 521	GFLOPS: 30987.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.31, Tstamp:1715259548.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,12)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 522	GFLOPS: 37597.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715259548.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 523	GFLOPS: 36688.02 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.55, Tstamp:1715259548.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 524	GFLOPS: 35603.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.42, Tstamp:1715259548.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 525	GFLOPS: 31017.36 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.39, Tstamp:1715259549.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 526	GFLOPS: 45172.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259549.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 527	GFLOPS: 46001.99 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715259549.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 528	GFLOPS: 39130.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.89, Tstamp:1715259550.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 529	GFLOPS: 46344.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259550.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 530	GFLOPS: 32703.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.78, Tstamp:1715259550.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 531	GFLOPS: 32528.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.17, Tstamp:1715259551.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 532	GFLOPS: 34281.73 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259551.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 533	GFLOPS: 40604.96 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259551.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 534	GFLOPS: 37533.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.31, Tstamp:1715259551.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 535	GFLOPS: 34134.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715259552.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 536	GFLOPS: 27699.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.81, Tstamp:1715259552.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 537	GFLOPS: 39380.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259552.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 538	GFLOPS: 35774.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259553.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 539	GFLOPS: 37901.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.57, Tstamp:1715259553.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 540	GFLOPS: 25909.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259553.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 541	GFLOPS: 34488.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259554.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 542	GFLOPS: 39486.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.42, Tstamp:1715259554.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 543	GFLOPS: 38960.98 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259555.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 544	GFLOPS: 33722.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.43, Tstamp:1715259555.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 545	GFLOPS: 44566.64 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715259555.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 546	GFLOPS: 41618.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259556.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 547	GFLOPS: 48645.12 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.41, Tstamp:1715259556.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 548	GFLOPS: 32338.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.05, Tstamp:1715259556.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 549	GFLOPS: 42776.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259556.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 550	GFLOPS: 31469.11 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259557.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 551	GFLOPS: 28408.39 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715259557.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 552	GFLOPS: 25386.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715259557.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 553	GFLOPS: 32115.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.80, Tstamp:1715259558.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 554	GFLOPS: 36591.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259558.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 555	GFLOPS: 32077.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259558.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 556	GFLOPS: 32404.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259559.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 557	GFLOPS: 45374.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259559.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 558	GFLOPS: 39380.89 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715259560.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 559	GFLOPS: 39944.03 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259560.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 560	GFLOPS: 36981.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.42, Tstamp:1715259560.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 561	GFLOPS: 36452.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259561.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 562	GFLOPS: 37607.61 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259561.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 563	GFLOPS: 26116.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259561.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 564	GFLOPS: 36909.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259562.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,4)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 565	GFLOPS: 47689.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259562.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 566	GFLOPS: 36134.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259562.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 567	GFLOPS: 43054.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715259563.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 568	GFLOPS: 38033.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259563.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 569	GFLOPS: 22161.78 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715259563.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,16)
    for i.1 (0,32)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 570	GFLOPS: 35454.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715259564.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 571	GFLOPS: 34435.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715259564.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 572	GFLOPS: 35655.33 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259564.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 573	GFLOPS: 21132.92 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.55, Tstamp:1715259565.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 574	GFLOPS: 2335.43 / 59748.01	results: MeasureResult(cost:[0.0016], error_no:0, all_cost:1.04, Tstamp:1715259565.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,64)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 575	GFLOPS: 17039.09 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.73, Tstamp:1715259565.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,48)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    for n.1 (0,24)
      compute = ...

==================================================
No: 576	GFLOPS: 9751.78 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.60, Tstamp:1715259566.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

Time elapsed for measurement: 28.11 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.90 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1675	fail_ct: 373	Time elapsed: 2.53
GA Iter: 0	Max score: 0.6433	Min score: 0.3749	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7944	Min score: 0.5496	#Pop: 128	#M+: 1380	#M-: 80
EvolutionarySearch		#s: 128	Time elapsed: 9.90
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 577	GFLOPS: 43511.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.14, Tstamp:1715259587.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 578	GFLOPS: 43493.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.11, Tstamp:1715259587.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 579	GFLOPS: 34963.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.29, Tstamp:1715259587.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 580	GFLOPS: 35055.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715259588.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 581	GFLOPS: 26614.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.13, Tstamp:1715259588.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 582	GFLOPS: 24012.82 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.90, Tstamp:1715259588.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  for n.1 (0,16)
    compute = ...

==================================================
No: 583	GFLOPS: 32086.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259589.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,24)
    compute = ...

==================================================
No: 584	GFLOPS: 41561.26 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715259589.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 585	GFLOPS: 34495.33 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.93, Tstamp:1715259589.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 586	GFLOPS: 46732.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259590.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 587	GFLOPS: 38374.11 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.25, Tstamp:1715259590.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 588	GFLOPS: 29828.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.78, Tstamp:1715259590.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 589	GFLOPS: 32917.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715259590.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,24)
    compute = ...

==================================================
No: 590	GFLOPS: 37596.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259591.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 591	GFLOPS: 44282.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.75, Tstamp:1715259591.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 592	GFLOPS: 45923.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.63, Tstamp:1715259592.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 593	GFLOPS: 31905.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.18, Tstamp:1715259592.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 594	GFLOPS: 47449.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259592.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 595	GFLOPS: 43598.47 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715259592.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 596	GFLOPS: 49970.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259593.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 597	GFLOPS: 36386.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715259593.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 598	GFLOPS: 30040.43 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.22, Tstamp:1715259593.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 599	GFLOPS: 39238.44 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.90, Tstamp:1715259594.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 600	GFLOPS: 29749.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715259594.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      for n.1 (0,48)
        compute = ...

==================================================
No: 601	GFLOPS: 37813.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259594.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 602	GFLOPS: 39466.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715259595.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 603	GFLOPS: 38499.73 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259595.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 604	GFLOPS: 32951.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715259595.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 605	GFLOPS: 43055.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.88, Tstamp:1715259596.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 606	GFLOPS: 14472.81 / 59748.01	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.53, Tstamp:1715259596.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for n.1 (0,12)
    compute = ...

==================================================
No: 607	GFLOPS: 30689.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.28, Tstamp:1715259596.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 608	GFLOPS: 47681.16 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.36, Tstamp:1715259596.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 609	GFLOPS: 46285.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259597.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 610	GFLOPS: 41031.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259597.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 611	GFLOPS: 36912.09 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.80, Tstamp:1715259598.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 612	GFLOPS: 40069.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715259598.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 613	GFLOPS: 42839.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259598.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 614	GFLOPS: 34098.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259598.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 615	GFLOPS: 42910.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259599.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 616	GFLOPS: 21870.13 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715259599.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  vectorize n.1 (0,12)
    compute = ...

==================================================
No: 617	GFLOPS: 44281.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259599.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 618	GFLOPS: 34014.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259600.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 619	GFLOPS: 36819.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259600.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 620	GFLOPS: 34355.83 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259600.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 621	GFLOPS: 46977.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259601.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 622	GFLOPS: 31372.13 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.35, Tstamp:1715259601.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 623	GFLOPS: 43719.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259601.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 624	GFLOPS: 43618.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259602.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 625	GFLOPS: 42252.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715259602.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 626	GFLOPS: 29997.92 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.27, Tstamp:1715259602.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 627	GFLOPS: 32899.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259603.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 628	GFLOPS: 38927.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259603.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 629	GFLOPS: 34214.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259603.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 630	GFLOPS: 44224.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259604.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 631	GFLOPS: 41401.26 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259604.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 632	GFLOPS: 34178.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259604.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 633	GFLOPS: 30805.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715259605.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 634	GFLOPS: 29494.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.27, Tstamp:1715259605.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 635	GFLOPS: 45360.17 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259605.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 636	GFLOPS: 42465.43 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259605.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 637	GFLOPS: 30953.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.35, Tstamp:1715259606.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 638	GFLOPS: 14306.63 / 59748.01	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.38, Tstamp:1715259606.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 639	GFLOPS: 1510.82 / 59748.01	results: MeasureResult(cost:[0.0024], error_no:0, all_cost:0.29, Tstamp:1715259606.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,64)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,2)
      compute = ...

==================================================
No: 640	GFLOPS: 3177.68 / 59748.01	results: MeasureResult(cost:[0.0011], error_no:0, all_cost:0.36, Tstamp:1715259606.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,576)
  for i.1 (0,128)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,256)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 27.49 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.99 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1679	fail_ct: 369	Time elapsed: 2.58
GA Iter: 0	Max score: 0.7195	Min score: 0.3685	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7425	Min score: 0.5466	#Pop: 128	#M+: 1379	#M-: 84
EvolutionarySearch		#s: 128	Time elapsed: 10.11
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 641	GFLOPS: 24401.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.05, Tstamp:1715259628.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 642	GFLOPS: 31708.02 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715259628.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 643	GFLOPS: 23821.88 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.55, Tstamp:1715259628.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 644	GFLOPS: 28994.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715259629.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 645	GFLOPS: 33215.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715259629.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 646	GFLOPS: 32723.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.20, Tstamp:1715259629.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 647	GFLOPS: 32487.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715259629.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 648	GFLOPS: 33221.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259630.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 649	GFLOPS: 33275.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259630.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 650	GFLOPS: 33884.58 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.53, Tstamp:1715259630.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 651	GFLOPS: 30875.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.01, Tstamp:1715259631.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,3)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,3)
    for n.1 (0,16)
      compute = ...

==================================================
No: 652	GFLOPS: 32134.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.43, Tstamp:1715259631.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 653	GFLOPS: 33337.64 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.36, Tstamp:1715259631.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 654	GFLOPS: 33124.13 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.35, Tstamp:1715259632.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 655	GFLOPS: 33831.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.08, Tstamp:1715259632.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 656	GFLOPS: 38626.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259632.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 657	GFLOPS: 33435.64 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259632.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 658	GFLOPS: 33231.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715259633.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,12)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 659	GFLOPS: 33193.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.22, Tstamp:1715259633.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 660	GFLOPS: 23670.17 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.83, Tstamp:1715259633.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 661	GFLOPS: 33260.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715259634.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 662	GFLOPS: 35194.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259634.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 663	GFLOPS: 24967.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.82, Tstamp:1715259634.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 664	GFLOPS: 36137.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259634.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,8)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 665	GFLOPS: 44945.33 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715259635.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,6)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 666	GFLOPS: 33667.74 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259635.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 667	GFLOPS: 39375.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.88, Tstamp:1715259635.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 668	GFLOPS: 34859.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715259636.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 669	GFLOPS: 34456.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259636.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 670	GFLOPS: 31815.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715259636.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,12)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 671	GFLOPS: 27651.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.23, Tstamp:1715259636.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 672	GFLOPS: 32616.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259637.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 673	GFLOPS: 36727.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259637.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 674	GFLOPS: 34209.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259637.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 675	GFLOPS: 33854.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715259637.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 676	GFLOPS: 33136.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259638.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 677	GFLOPS: 33589.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259638.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 678	GFLOPS: 26026.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259638.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 679	GFLOPS: 33771.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259638.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 680	GFLOPS: 33786.41 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259639.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 681	GFLOPS: 31633.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.57, Tstamp:1715259639.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 682	GFLOPS: 25394.16 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715259639.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 683	GFLOPS: 36749.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259640.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 684	GFLOPS: 25527.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259640.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 685	GFLOPS: 18708.03 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.32, Tstamp:1715259640.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 686	GFLOPS: 25557.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259641.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,2)
    for n.1 (0,48)
      compute = ...

==================================================
No: 687	GFLOPS: 22492.09 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715259641.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,12)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 688	GFLOPS: 37341.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259641.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 689	GFLOPS: 23883.09 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.85, Tstamp:1715259642.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 690	GFLOPS: 36536.49 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259642.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 691	GFLOPS: 36969.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259642.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 692	GFLOPS: 29297.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259643.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 693	GFLOPS: 32887.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259643.54)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 694	GFLOPS: 24857.98 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715259643.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 695	GFLOPS: 20208.84 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.52, Tstamp:1715259644.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 696	GFLOPS: 39579.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.28, Tstamp:1715259644.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 697	GFLOPS: 30338.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.80, Tstamp:1715259645.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,48)
    compute = ...

==================================================
No: 698	GFLOPS: 33553.20 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715259645.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 699	GFLOPS: 30027.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259645.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 700	GFLOPS: 18238.86 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715259646.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 701	GFLOPS: 29895.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259646.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 702	GFLOPS: 2568.88 / 59748.01	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.38, Tstamp:1715259646.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 50), 48))
    for i.1 (0,4)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 256)*3), 16) + 2), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,48)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,3)
      compute = ...

==================================================
No: 703	GFLOPS: 10167.12 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.19, Tstamp:1715259646.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,192)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,64)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,128)
    for n.1 (0,24)
      compute = ...

==================================================
No: 704	GFLOPS: 6221.52 / 59748.01	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.92, Tstamp:1715259647.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for i.1 (0,32)
      for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,12)
      compute = ...

Time elapsed for measurement: 26.65 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.16 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1687	fail_ct: 361	Time elapsed: 2.13
GA Iter: 0	Max score: 0.5909	Min score: 0.3464	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.8030	Min score: 0.5153	#Pop: 128	#M+: 1378	#M-: 78
EvolutionarySearch		#s: 128	Time elapsed: 8.72
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 705	GFLOPS: 21709.19 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.66, Tstamp:1715259667.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 706	GFLOPS: 33193.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.63, Tstamp:1715259667.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 707	GFLOPS: 37361.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:3.03, Tstamp:1715259667.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 708	GFLOPS: 28740.83 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.94, Tstamp:1715259668.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 709	GFLOPS: 33133.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715259668.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 710	GFLOPS: 39598.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259668.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 711	GFLOPS: 31722.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.91, Tstamp:1715259668.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 712	GFLOPS: 25607.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259669.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
    for m.1 (0,3)
      compute = ...

==================================================
No: 713	GFLOPS: 32502.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259669.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 714	GFLOPS: 33176.66 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715259669.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 715	GFLOPS: 35234.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.13, Tstamp:1715259670.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 716	GFLOPS: 34978.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.48, Tstamp:1715259670.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 717	GFLOPS: 27111.60 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715259670.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
    for m.1 (0,2)
      compute = ...

==================================================
No: 718	GFLOPS: 33610.16 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.90, Tstamp:1715259671.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 719	GFLOPS: 37844.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259671.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 720	GFLOPS: 29123.96 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715259671.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 721	GFLOPS: 27742.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715259671.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 722	GFLOPS: 25998.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.27, Tstamp:1715259672.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 723	GFLOPS: 39643.92 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.09, Tstamp:1715259672.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,16)
        compute = ...

==================================================
No: 724	GFLOPS: 42050.12 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.09, Tstamp:1715259672.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 725	GFLOPS: 31179.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715259673.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 726	GFLOPS: 33266.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715259673.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 727	GFLOPS: 33637.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259673.73)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 728	GFLOPS: 31864.11 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.46, Tstamp:1715259673.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 729	GFLOPS: 33471.05 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259674.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 730	GFLOPS: 36957.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259674.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 731	GFLOPS: 31144.92 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.07, Tstamp:1715259674.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 732	GFLOPS: 25155.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.45, Tstamp:1715259675.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 733	GFLOPS: 37750.99 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.77, Tstamp:1715259675.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 734	GFLOPS: 34327.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259675.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 735	GFLOPS: 28951.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715259675.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 736	GFLOPS: 26675.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715259676.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 737	GFLOPS: 28024.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259676.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 738	GFLOPS: 38961.85 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259676.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,16)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 739	GFLOPS: 35095.47 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259677.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 740	GFLOPS: 41006.54 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.92, Tstamp:1715259677.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 741	GFLOPS: 17465.21 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.56, Tstamp:1715259677.77)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,24)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 742	GFLOPS: 35115.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259678.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 743	GFLOPS: 37219.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715259678.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    for n.1 (0,16)
      compute = ...

==================================================
No: 744	GFLOPS: 32322.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259678.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,32)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 745	GFLOPS: 36859.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259678.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 746	GFLOPS: 34337.89 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715259679.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 747	GFLOPS: 33636.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259679.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 748	GFLOPS: 33790.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259679.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 749	GFLOPS: 35690.80 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259680.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 750	GFLOPS: 25615.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259680.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 751	GFLOPS: 49799.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.67, Tstamp:1715259680.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 752	GFLOPS: 21221.86 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.47, Tstamp:1715259680.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for c (0,16)
        compute = ...
    compute = ...

==================================================
No: 753	GFLOPS: 34879.13 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259681.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 754	GFLOPS: 17865.86 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.46, Tstamp:1715259681.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,48)
      for c (0,16)
        compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 755	GFLOPS: 32876.51 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259681.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 756	GFLOPS: 42295.02 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715259682.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 757	GFLOPS: 33218.12 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259682.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,48)
      compute = ...

==================================================
No: 758	GFLOPS: 28019.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259682.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 759	GFLOPS: 33057.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.63, Tstamp:1715259683.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 760	GFLOPS: 35338.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259683.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 761	GFLOPS: 24958.57 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259683.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 762	GFLOPS: 38473.40 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259683.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 763	GFLOPS: 28586.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.46, Tstamp:1715259684.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 764	GFLOPS: 33433.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259684.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 765	GFLOPS: 27374.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.30, Tstamp:1715259684.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 766	GFLOPS: 18040.33 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.10, Tstamp:1715259684.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,2)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,24)
      compute = ...

==================================================
No: 767	GFLOPS: 8220.97 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.70, Tstamp:1715259685.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,96)
  compute auto_unroll: 64
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,32)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,384)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 768	GFLOPS: 16225.98 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715259685.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,128)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,96)
    for n.1 (0,48)
      compute = ...

Time elapsed for measurement: 25.87 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.19 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1663	fail_ct: 385	Time elapsed: 2.64
GA Iter: 0	Max score: 0.5997	Min score: 0.3427	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6889	Min score: 0.5030	#Pop: 128	#M+: 1390	#M-: 70
EvolutionarySearch		#s: 128	Time elapsed: 10.01
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 769	GFLOPS: 23636.34 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.07, Tstamp:1715259706.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 770	GFLOPS: 23727.82 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.62, Tstamp:1715259707.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 771	GFLOPS: 32313.65 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.64, Tstamp:1715259707.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,48)
        compute = ...

==================================================
No: 772	GFLOPS: 26564.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.08, Tstamp:1715259707.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 773	GFLOPS: 35856.16 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.34, Tstamp:1715259708.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 774	GFLOPS: 27762.22 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259708.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 775	GFLOPS: 33312.90 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.91, Tstamp:1715259708.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 776	GFLOPS: 44986.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.26, Tstamp:1715259708.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 777	GFLOPS: 29355.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.96, Tstamp:1715259709.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 778	GFLOPS: 23999.82 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.72, Tstamp:1715259709.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 779	GFLOPS: 34719.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.31, Tstamp:1715259709.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,4)
    for n.1 (0,16)
      compute = ...

==================================================
No: 780	GFLOPS: 34462.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.38, Tstamp:1715259709.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 781	GFLOPS: 27552.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.44, Tstamp:1715259710.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 782	GFLOPS: 36433.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715259710.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 783	GFLOPS: 42252.84 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.68, Tstamp:1715259710.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 784	GFLOPS: 29719.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259711.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 785	GFLOPS: 35160.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.08, Tstamp:1715259711.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 786	GFLOPS: 35070.72 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259711.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 787	GFLOPS: 12637.56 / 59748.01	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.75, Tstamp:1715259711.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,48)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 788	GFLOPS: 35101.75 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259712.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,6)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 789	GFLOPS: 23346.17 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715259712.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 790	GFLOPS: 20814.52 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.80, Tstamp:1715259712.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 791	GFLOPS: 33075.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715259713.04)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 792	GFLOPS: 30026.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259713.31)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 793	GFLOPS: 28603.52 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.53, Tstamp:1715259713.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,48)
        compute = ...

==================================================
No: 794	GFLOPS: 33435.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259713.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 795	GFLOPS: 33011.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715259714.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      for n.1 (0,16)
        compute = ...

==================================================
No: 796	GFLOPS: 17917.67 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.53, Tstamp:1715259714.41)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 797	GFLOPS: 31790.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.52, Tstamp:1715259714.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 798	GFLOPS: 40424.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259714.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 799	GFLOPS: 37165.41 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259715.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 800	GFLOPS: 23045.29 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.63, Tstamp:1715259715.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 16
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,24)
    compute = ...

==================================================
No: 801	GFLOPS: 29561.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.44, Tstamp:1715259716.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 802	GFLOPS: 36962.65 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259716.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 803	GFLOPS: 16354.40 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.65, Tstamp:1715259716.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 804	GFLOPS: 38489.78 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259717.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 805	GFLOPS: 30273.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259717.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 806	GFLOPS: 28271.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.87, Tstamp:1715259717.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 807	GFLOPS: 29119.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.53, Tstamp:1715259718.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 808	GFLOPS: 40255.32 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259718.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 809	GFLOPS: 35064.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715259718.87)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 810	GFLOPS: 33461.09 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715259719.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 811	GFLOPS: 22627.64 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715259719.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 812	GFLOPS: 16742.37 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.48, Tstamp:1715259720.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 813	GFLOPS: 34982.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.15, Tstamp:1715259720.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 814	GFLOPS: 25142.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.55, Tstamp:1715259720.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 815	GFLOPS: 31518.80 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259721.07)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 816	GFLOPS: 33416.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259721.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 817	GFLOPS: 24812.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.43, Tstamp:1715259721.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,32)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 818	GFLOPS: 27611.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259721.99)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 819	GFLOPS: 31414.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259722.29)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 820	GFLOPS: 32570.90 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259722.59)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 821	GFLOPS: 25756.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259722.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  compute auto_unroll: 64
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 822	GFLOPS: 35662.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715259723.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 823	GFLOPS: 30247.72 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259723.38)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for j (0,16)
      for c (0,16)
        compute = ...
  vectorize n.1 (0,16)
    compute = ...

==================================================
No: 824	GFLOPS: 28299.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.40, Tstamp:1715259723.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    for i.1 (0,24)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 825	GFLOPS: 33636.44 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259723.93)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 826	GFLOPS: 34308.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.51, Tstamp:1715259724.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 827	GFLOPS: 31768.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.91, Tstamp:1715259724.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      for n.1 (0,16)
        compute = ...

==================================================
No: 828	GFLOPS: 37392.41 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.47, Tstamp:1715259724.80)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 829	GFLOPS: 31927.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715259725.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 830	GFLOPS: 3912.49 / 59748.01	results: MeasureResult(cost:[0.0009], error_no:0, all_cost:0.65, Tstamp:1715259725.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 831	GFLOPS: 2582.96 / 59748.01	results: MeasureResult(cost:[0.0014], error_no:0, all_cost:0.54, Tstamp:1715259725.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,96)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 832	GFLOPS: 7760.02 / 59748.01	results: MeasureResult(cost:[0.0005], error_no:0, all_cost:0.43, Tstamp:1715259726.12)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,32)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,8)
      compute = ...

Time elapsed for measurement: 26.87 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 0.94 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1677	fail_ct: 371	Time elapsed: 2.16
GA Iter: 0	Max score: 0.5737	Min score: 0.3402	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6983	Min score: 0.4959	#Pop: 128	#M+: 1376	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 8.81
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 833	GFLOPS: 24498.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.66, Tstamp:1715259748.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 834	GFLOPS: 37731.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.97, Tstamp:1715259748.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 835	GFLOPS: 32726.04 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.04, Tstamp:1715259748.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 836	GFLOPS: 36195.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.25, Tstamp:1715259748.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,4)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 837	GFLOPS: 31017.62 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.25, Tstamp:1715259749.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 838	GFLOPS: 24477.36 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715259749.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 839	GFLOPS: 40155.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715259749.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,4)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 840	GFLOPS: 45043.58 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.04, Tstamp:1715259750.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 841	GFLOPS: 16695.39 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715259750.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 842	GFLOPS: 45323.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.46, Tstamp:1715259750.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,8)
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 843	GFLOPS: 27236.91 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715259750.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 844	GFLOPS: 33901.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259751.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 845	GFLOPS: 18623.11 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.22, Tstamp:1715259751.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 846	GFLOPS: 24928.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.33, Tstamp:1715259751.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,6)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 847	GFLOPS: 28836.73 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.14, Tstamp:1715259752.26)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 848	GFLOPS: 28811.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715259752.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 849	GFLOPS: 34960.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.31, Tstamp:1715259752.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 850	GFLOPS: 32862.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715259752.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 851	GFLOPS: 33514.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.24, Tstamp:1715259753.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 852	GFLOPS: 38655.55 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.71, Tstamp:1715259753.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 853	GFLOPS: 33941.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.50, Tstamp:1715259753.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 854	GFLOPS: 25087.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.27, Tstamp:1715259753.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 855	GFLOPS: 31182.85 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.99, Tstamp:1715259754.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,3)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 856	GFLOPS: 34110.53 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.65, Tstamp:1715259754.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 857	GFLOPS: 29945.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259754.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 858	GFLOPS: 27236.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.53, Tstamp:1715259754.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 859	GFLOPS: 34353.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.03, Tstamp:1715259755.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,6)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 860	GFLOPS: 40799.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715259755.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,4)
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 861	GFLOPS: 28946.40 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259755.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 862	GFLOPS: 23034.19 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.99, Tstamp:1715259756.08)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 863	GFLOPS: 35001.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715259756.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 864	GFLOPS: 22356.07 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.69, Tstamp:1715259756.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for c (0,16)
          compute = ...
    for m.1 (0,4)
      compute = ...

==================================================
No: 865	GFLOPS: 42522.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259757.03)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,98304)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,6)
      for c (0,16)
        compute = ...
  for m.1 (0,6)
    compute = ...

==================================================
No: 866	GFLOPS: 32149.60 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.65, Tstamp:1715259757.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,32)
    for n.1 (0,48)
      compute = ...

==================================================
No: 867	GFLOPS: 31546.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259757.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
    for m.1 (0,3)
      compute = ...

==================================================
No: 868	GFLOPS: 30770.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.26, Tstamp:1715259758.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,6)
    for n.1 (0,16)
      compute = ...

==================================================
No: 869	GFLOPS: 29296.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259758.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,3)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 870	GFLOPS: 35309.42 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.51, Tstamp:1715259758.90)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 871	GFLOPS: 27738.39 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259759.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    compute auto_unroll: 512
    for i.1 (0,3)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,2)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 872	GFLOPS: 34496.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259759.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,768)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
    for m.1 (0,8)
      compute = ...

==================================================
No: 873	GFLOPS: 30968.37 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259759.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 874	GFLOPS: 24189.16 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.36, Tstamp:1715259760.06)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 875	GFLOPS: 24294.95 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.60, Tstamp:1715259760.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,12)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 876	GFLOPS: 31238.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259760.51)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 877	GFLOPS: 29522.58 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.02, Tstamp:1715259760.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,6)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,12)
      for n.1 (0,48)
        compute = ...

==================================================
No: 878	GFLOPS: 33013.48 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715259761.05)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 879	GFLOPS: 32839.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.23, Tstamp:1715259761.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 880	GFLOPS: 27317.82 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259761.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,8)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 881	GFLOPS: 30851.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259761.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 882	GFLOPS: 32741.76 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259762.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 883	GFLOPS: 24232.99 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.59, Tstamp:1715259762.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 884	GFLOPS: 18616.13 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.16, Tstamp:1715259762.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,24)
      for c (0,16)
        compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 885	GFLOPS: 23053.01 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.75, Tstamp:1715259763.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,12)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 886	GFLOPS: 34878.64 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715259763.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 887	GFLOPS: 32712.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259763.74)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4096)
  compute auto_unroll: 16
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,3)
    for n.1 (0,48)
      compute = ...

==================================================
No: 888	GFLOPS: 25930.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715259764.00)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 889	GFLOPS: 28233.14 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259764.35)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 890	GFLOPS: 34802.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.64, Tstamp:1715259764.63)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 891	GFLOPS: 35583.84 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.49, Tstamp:1715259765.01)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 892	GFLOPS: 32914.46 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.61, Tstamp:1715259765.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      for n.1 (0,16)
        compute = ...

==================================================
No: 893	GFLOPS: 21310.91 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.44, Tstamp:1715259765.78)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 894	GFLOPS: 8114.50 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:0.32, Tstamp:1715259765.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,192)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,384)
    compute = ...

==================================================
No: 895	GFLOPS: 12254.57 / 59748.01	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:3.89, Tstamp:1715259766.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.0 (0,floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 203), 192))
    for nb_j.1 (0,(floordiv((floormod((floormod(m.outer.n.outer.fused, 64)*12), 16) + 11), 16) + 1))
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,12)
      compute = ...

==================================================
No: 896	GFLOPS: 1735.13 / 59748.01	results: MeasureResult(cost:[0.0021], error_no:0, all_cost:0.52, Tstamp:1715259766.65)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,12)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,192)
    vectorize n.1 (0,2)
      compute = ...

Time elapsed for measurement: 28.56 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.32 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1662	fail_ct: 386	Time elapsed: 2.57
GA Iter: 0	Max score: 0.6242	Min score: 0.3267	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.7391	Min score: 0.4651	#Pop: 128	#M+: 1388	#M-: 77
EvolutionarySearch		#s: 128	Time elapsed: 10.08
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 64 programs to measure:
................................................................****************************************************************
==================================================
No: 897	GFLOPS: 24098.38 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:2.93, Tstamp:1715259788.34)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,2)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,4)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 898	GFLOPS: 30017.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.47, Tstamp:1715259788.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 899	GFLOPS: 20476.02 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.76, Tstamp:1715259788.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,24)
      for c (0,16)
        compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 900	GFLOPS: 30115.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.14, Tstamp:1715259789.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 901	GFLOPS: 24695.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.89, Tstamp:1715259789.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 902	GFLOPS: 24941.38 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259789.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 903	GFLOPS: 30530.13 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.02, Tstamp:1715259790.20)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 904	GFLOPS: 39599.81 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.79, Tstamp:1715259790.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 905	GFLOPS: 28660.92 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.37, Tstamp:1715259790.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 906	GFLOPS: 31144.47 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.69, Tstamp:1715259791.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for n.1 (0,48)
    compute = ...

==================================================
No: 907	GFLOPS: 28545.77 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259791.48)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 908	GFLOPS: 39534.69 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.47, Tstamp:1715259791.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,16)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 909	GFLOPS: 31916.19 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.28, Tstamp:1715259791.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 910	GFLOPS: 20612.39 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.83, Tstamp:1715259792.23)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 911	GFLOPS: 33793.63 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.19, Tstamp:1715259792.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 912	GFLOPS: 33020.07 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.18, Tstamp:1715259792.72)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 913	GFLOPS: 28610.93 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259793.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,768)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,6)
          for c (0,16)
            compute = ...
    for m.1 (0,12)
      compute = ...

==================================================
No: 914	GFLOPS: 11960.00 / 59748.01	results: MeasureResult(cost:[0.0003], error_no:0, all_cost:0.65, Tstamp:1715259793.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,9216)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,64)
    compute = ...

==================================================
No: 915	GFLOPS: 29866.51 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259793.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    for i.1 (0,6)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 916	GFLOPS: 22758.01 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.84, Tstamp:1715259793.92)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,16)
      compute = ...

==================================================
No: 917	GFLOPS: 32993.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.16, Tstamp:1715259794.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,192)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,4)
      for n.1 (0,16)
        compute = ...

==================================================
No: 918	GFLOPS: 29238.20 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259794.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 919	GFLOPS: 21057.79 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.64, Tstamp:1715259794.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 920	GFLOPS: 34900.15 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715259795.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 921	GFLOPS: 32253.87 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.10, Tstamp:1715259795.33)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    for n.1 (0,16)
      compute = ...

==================================================
No: 922	GFLOPS: 29775.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259795.58)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1152)
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 923	GFLOPS: 33160.02 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.41, Tstamp:1715259795.84)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,48)
        compute = ...

==================================================
No: 924	GFLOPS: 22830.68 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.79, Tstamp:1715259796.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,196608)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,3)
      for c (0,16)
        compute = ...
  for m.1 (0,3)
    compute = ...

==================================================
No: 925	GFLOPS: 33784.60 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.44, Tstamp:1715259796.46)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      for n.1 (0,48)
        compute = ...

==================================================
No: 926	GFLOPS: 34675.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.95, Tstamp:1715259796.86)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,3)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 927	GFLOPS: 29792.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715259797.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 928	GFLOPS: 28225.99 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259797.42)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 929	GFLOPS: 26832.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.95, Tstamp:1715259797.69)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 930	GFLOPS: 23189.67 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.59, Tstamp:1715259798.02)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 931	GFLOPS: 28244.35 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.58, Tstamp:1715259798.21)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 64
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 932	GFLOPS: 26471.24 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.48, Tstamp:1715259798.55)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,147456)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,4)
    compute = ...

==================================================
No: 933	GFLOPS: 35756.86 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.83, Tstamp:1715259798.83)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 934	GFLOPS: 28812.60 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.67, Tstamp:1715259799.10)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,16)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 935	GFLOPS: 31890.02 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715259799.36)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 64
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    for n.1 (0,48)
      compute = ...

==================================================
No: 936	GFLOPS: 34099.27 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.68, Tstamp:1715259799.68)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 64
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    for n.1 (0,16)
      compute = ...

==================================================
No: 937	GFLOPS: 32429.85 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.71, Tstamp:1715259799.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  compute auto_unroll: 16
  for i.1 (0,4)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 938	GFLOPS: 32963.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259800.24)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2048)
  compute auto_unroll: 16
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,6)
    for n.1 (0,48)
      compute = ...

==================================================
No: 939	GFLOPS: 27827.59 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.36, Tstamp:1715259800.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 940	GFLOPS: 33061.97 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.44, Tstamp:1715259800.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,2304)
  compute auto_unroll: 16
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 941	GFLOPS: 31866.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259800.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 942	GFLOPS: 24623.94 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259801.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,24)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 943	GFLOPS: 42451.66 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.69, Tstamp:1715259801.53)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 944	GFLOPS: 24413.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.36, Tstamp:1715259801.79)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for c (0,16)
        compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 945	GFLOPS: 30381.03 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.84, Tstamp:1715259802.14)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 946	GFLOPS: 24247.67 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259802.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,16)
      compute = ...

==================================================
No: 947	GFLOPS: 17839.27 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.32, Tstamp:1715259802.66)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  for i.1 (0,12)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    compute = ...

==================================================
No: 948	GFLOPS: 28663.61 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259802.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 16
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 949	GFLOPS: 33239.45 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.85, Tstamp:1715259803.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 950	GFLOPS: 27773.85 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715259803.57)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 16
  for i.1 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 951	GFLOPS: 35535.28 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.78, Tstamp:1715259803.91)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 952	GFLOPS: 37763.71 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.66, Tstamp:1715259804.32)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 953	GFLOPS: 34567.88 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.42, Tstamp:1715259804.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for j (0,16)
        for c (0,16)
          compute = ...
    for n.1 (0,16)
      compute = ...

==================================================
No: 954	GFLOPS: 26231.23 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.30, Tstamp:1715259804.89)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,2)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,2)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 955	GFLOPS: 31582.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.58, Tstamp:1715259805.16)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,24)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 956	GFLOPS: 31281.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259805.45)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,73728)
  compute auto_unroll: 64
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,2)
        for c (0,16)
          compute = ...
  for m.1 (0,8)
    compute = ...

==================================================
No: 957	GFLOPS: 33836.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.21, Tstamp:1715259805.70)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      for n.1 (0,16)
        compute = ...

==================================================
No: 958	GFLOPS: 15044.84 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.40, Tstamp:1715259805.98)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  for i.1 (0,16)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,3)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 959	GFLOPS: 5655.03 / 59748.01	results: MeasureResult(cost:[0.0006], error_no:0, all_cost:0.50, Tstamp:1715259806.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,3072)
  compute auto_unroll: 16
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,4)
      compute = ...

==================================================
No: 960	GFLOPS: 9676.22 / 59748.01	results: MeasureResult(cost:[0.0004], error_no:0, all_cost:1.14, Tstamp:1715259806.67)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 16
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,3)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,12)
    vectorize n.1 (0,4)
      compute = ...

Time elapsed for measurement: 25.95 s
----------------------------------------------------------------------
------------------------------  [ Train cost model ]
----------------------------------------------------------------------
Time elapsed for training: 1.10 s
----------------------------------------------------------------------
------------------------------  [ Search ]
----------------------------------------------------------------------
Sample Initial Population	#s: 1656	fail_ct: 392	Time elapsed: 2.54
GA Iter: 0	Max score: 0.5373	Min score: 0.3288	#Pop: 128	#M+: 0	#M-: 0
GA Iter: 4	Max score: 0.6241	Min score: 0.4694	#Pop: 128	#M+: 1372	#M-: 75
EvolutionarySearch		#s: 128	Time elapsed: 9.85
----------------------------------------------------------------------
------------------------------  [ Measure ]
----------------------------------------------------------------------
Get 40 programs to measure:
........................................****************************************
==================================================
No: 961	GFLOPS: 19122.04 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.89, Tstamp:1715259825.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 962	GFLOPS: 17240.06 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.29, Tstamp:1715259826.18)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 16
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 963	GFLOPS: 35239.75 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.88, Tstamp:1715259826.52)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 16
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,2)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 964	GFLOPS: 15377.18 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.20, Tstamp:1715259826.88)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,8)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,6)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 965	GFLOPS: 34678.56 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.86, Tstamp:1715259827.22)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,768)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for n.1 (0,48)
      compute = ...

==================================================
No: 966	GFLOPS: 29959.00 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:2.10, Tstamp:1715259827.50)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    compute auto_unroll: 512
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,24)
      for n.1 (0,16)
        compute = ...

==================================================
No: 967	GFLOPS: 33287.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.98, Tstamp:1715259827.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
      for i.2 (0,6)
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 968	GFLOPS: 29318.06 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715259828.27)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,3)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 969	GFLOPS: 24024.42 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.82, Tstamp:1715259828.60)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 512
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 970	GFLOPS: 32173.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.92, Tstamp:1715259828.85)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,16)
    compute auto_unroll: 16
    for i.1 (0,2)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,2)
      for n.1 (0,48)
        compute = ...

==================================================
No: 971	GFLOPS: 28891.79 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.94, Tstamp:1715259829.15)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,4608)
  compute auto_unroll: 64
  for i.1 (0,2)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,4)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,16)
      compute = ...

==================================================
No: 972	GFLOPS: 18947.99 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.41, Tstamp:1715259829.37)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,256)
  compute auto_unroll: 512
  for i.1 (0,6)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,48)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 973	GFLOPS: 31949.25 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.54, Tstamp:1715259829.56)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,256)
  for n.0 (0,16)
    compute auto_unroll: 64
    for i.1 (0,3)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,3)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 974	GFLOPS: 29083.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.72, Tstamp:1715259829.75)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,384)
  compute auto_unroll: 64
  for i.1 (0,32)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,32)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 975	GFLOPS: 28934.72 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.63, Tstamp:1715259830.11)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,16)
    for i.1 (0,6)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for i.2 (0,4)
            for j (0,16)
              for c (0,16)
                compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 976	GFLOPS: 39302.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.45, Tstamp:1715259830.39)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,8)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 977	GFLOPS: 26704.20 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.62, Tstamp:1715259830.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,294912)
  compute auto_unroll: 16
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,2)
      for c (0,16)
        compute = ...
  for m.1 (0,2)
    compute = ...

==================================================
No: 978	GFLOPS: 23588.43 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.36, Tstamp:1715259830.97)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,12)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 979	GFLOPS: 16737.52 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.55, Tstamp:1715259831.30)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,6144)
  compute auto_unroll: 512
  for i.1 (0,24)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,4)
        for c (0,16)
          compute = ...
  for m.1 (0,96)
    compute = ...

==================================================
No: 980	GFLOPS: 33005.01 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.50, Tstamp:1715259831.61)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,64)
  for n.0 (0,48)
    compute auto_unroll: 16
    for i.1 (0,4)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,12)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 981	GFLOPS: 25186.64 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:1.29, Tstamp:1715259831.95)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 512
  for i.1 (0,3)
    for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 982	GFLOPS: 35152.17 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.73, Tstamp:1715259832.25)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1024)
  for i.1 (0,2)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,6)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,12)
    for n.1 (0,48)
      compute = ...

==================================================
No: 983	GFLOPS: 22011.12 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.38, Tstamp:1715259832.44)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,768)
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(floordiv(n.outer, 16) + 1)] - placeholder[floordiv(n.outer, 16)]))
        for i.2 (0,3)
          for c (0,16)
            compute = ...
    for m.1 (0,6)
      compute = ...

==================================================
No: 984	GFLOPS: 24403.50 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.70, Tstamp:1715259832.64)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,96)
  for n.0 (0,16)
    compute auto_unroll: 512
    for i.1 (0,8)
      for nb_j.1 (0,3)
        for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,8)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 985	GFLOPS: 28857.73 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.43, Tstamp:1715259832.96)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,49152)
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,12)
      for c (0,16)
        compute = ...
  for m.1 (0,12)
    compute = ...

==================================================
No: 986	GFLOPS: 25609.08 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259833.28)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,18432)
  compute auto_unroll: 512
  for i.1 (0,4)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,32)
    compute = ...

==================================================
No: 987	GFLOPS: 27875.30 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.74, Tstamp:1715259833.62)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,16)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 988	GFLOPS: 23472.47 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.27, Tstamp:1715259833.94)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,512)
  compute auto_unroll: 512
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,24)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,24)
    for n.1 (0,48)
      compute = ...

==================================================
No: 989	GFLOPS: 25607.36 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259834.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,12288)
  compute auto_unroll: 512
  for i.1 (0,6)
    for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
      for i.2 (0,8)
        for c (0,16)
          compute = ...
  for m.1 (0,48)
    compute = ...

==================================================
No: 990	GFLOPS: 33750.34 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.75, Tstamp:1715259834.40)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,36864)
  compute auto_unroll: 512
  for elem_idx (0,(placeholder[(floordiv(floormod(m.outer.n.outer.fused, 768), 16) + 1)] - placeholder[floordiv(floormod(m.outer.n.outer.fused, 768), 16)]))
    for i.2 (0,16)
      for c (0,16)
        compute = ...
  for m.1 (0,16)
    compute = ...

==================================================
No: 991	GFLOPS: 28788.68 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.56, Tstamp:1715259834.81)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,32)
  for n.0 (0,48)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,24)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 992	GFLOPS: 31609.70 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.82, Tstamp:1715259835.13)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,128)
  for n.0 (0,48)
    compute auto_unroll: 64
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,3)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,6)
      for n.1 (0,16)
        compute = ...

==================================================
No: 993	GFLOPS: 33364.18 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.76, Tstamp:1715259835.47)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for nb_j.1 (0,3)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for i.2 (0,8)
        for j (0,16)
          for c (0,16)
            compute = ...
  for m.1 (0,8)
    for n.1 (0,48)
      compute = ...

==================================================
No: 994	GFLOPS: 19584.97 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:1.15, Tstamp:1715259835.76)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,768)
  compute auto_unroll: 512
  for i.1 (0,8)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,2)
          for j (0,16)
            for c (0,16)
              compute = ...
  for m.1 (0,16)
    vectorize n.1 (0,48)
      compute = ...

==================================================
No: 995	GFLOPS: 31101.31 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.93, Tstamp:1715259836.17)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      for n.1 (0,48)
        compute = ...

==================================================
No: 996	GFLOPS: 23927.82 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.50, Tstamp:1715259836.49)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,1536)
  compute auto_unroll: 64
  for elem_idx (0,(placeholder[(floormod(m.outer.n.outer.fused, 48) + 1)] - placeholder[floormod(m.outer.n.outer.fused, 48)]))
    for i.2 (0,24)
      for j (0,16)
        for c (0,16)
          compute = ...
  for m.1 (0,24)
    vectorize n.1 (0,16)
      compute = ...

==================================================
No: 997	GFLOPS: 21692.89 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.94, Tstamp:1715259836.82)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@n.0@ (0,24576)
  compute auto_unroll: 512
  for nb_j.1 (0,2)
    for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
      for j (0,16)
        for c (0,16)
          compute = ...
  vectorize n.1 (0,24)
    compute = ...

==================================================
No: 998	GFLOPS: 33755.29 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.57, Tstamp:1715259837.09)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,48)
  for n.0 (0,16)
    compute auto_unroll: 64
    for nb_j.1 (0,3)
      for elem_idx (0,(placeholder[(nb_j + 1)] - placeholder[nb_j]))
        for i.2 (0,16)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,16)
      vectorize n.1 (0,48)
        compute = ...

==================================================
No: 999	GFLOPS: 29757.21 / 59748.01	results: MeasureResult(cost:[0.0001], error_no:0, all_cost:0.81, Tstamp:1715259837.43)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,384)
  for n.0 (0,48)
    compute auto_unroll: 512
    for i.1 (0,2)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for j (0,16)
          for c (0,16)
            compute = ...
    for m.1 (0,2)
      vectorize n.1 (0,16)
        compute = ...

==================================================
No: 1000	GFLOPS: 21946.38 / 59748.01	results: MeasureResult(cost:[0.0002], error_no:0, all_cost:0.51, Tstamp:1715259837.71)
==================================================
Placeholder: placeholder, placeholder, placeholder, placeholder
parallel m.0@ (0,24)
  for n.0 (0,48)
    for i.1 (0,8)
      for elem_idx (0,(placeholder[(n.outer + 1)] - placeholder[n.outer]))
        for i.2 (0,4)
          for j (0,16)
            for c (0,16)
              compute = ...
    for m.1 (0,32)
      for n.1 (0,16)
        compute = ...

Time elapsed for measurement: 17.46 s
----------------------------------------------------------------------
------------------------------  [ Done ]
----------------------------------------------------------------------
Lowered TIR:
@main = primfn(placeholder_4: handle, placeholder_5: handle, placeholder_6: handle, placeholder_7: handle, compute_1: handle) -> ()
  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}
  buffers = {placeholder: Buffer(placeholder_8: Pointer(float32), float32, [768, 3072], []),
             placeholder_1: Buffer(placeholder_9: Pointer(float32), float32, [48, 16, 16], []),
             placeholder_2: Buffer(placeholder_10: Pointer(int32), int32, [48], []),
             placeholder_3: Buffer(placeholder_11: Pointer(int32), int32, [49], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [768, 768], [])}
  buffer_map = {placeholder_4: placeholder, placeholder_5: placeholder_1, placeholder_6: placeholder_2, placeholder_7: placeholder_3, compute_1: compute} {
  for (m.outer.n.outer.fused: int32, 0, 1024) "parallel" {
    allocate(compute_3: Pointer(global float32), float32, [576]), storage_scope = global {
      for (i.outer.inner: int32, 0, 2) {
        for (nb_j.inner: int32, 0, 3) {
          let cse_var_1: int32 = ((i.outer.inner*288) + (nb_j.inner*16))
           {
            compute_4: Buffer(compute_3, float32, [576], [])[cse_var_1] = 0f32
            compute_4[(cse_var_1 + 1)] = 0f32
            compute_4[(cse_var_1 + 2)] = 0f32
            compute_4[(cse_var_1 + 3)] = 0f32
            compute_4[(cse_var_1 + 4)] = 0f32
            compute_4[(cse_var_1 + 5)] = 0f32
            compute_4[(cse_var_1 + 6)] = 0f32
            compute_4[(cse_var_1 + 7)] = 0f32
            compute_4[(cse_var_1 + 8)] = 0f32
            compute_4[(cse_var_1 + 9)] = 0f32
            compute_4[(cse_var_1 + 10)] = 0f32
            compute_4[(cse_var_1 + 11)] = 0f32
            compute_4[(cse_var_1 + 12)] = 0f32
            compute_4[(cse_var_1 + 13)] = 0f32
            compute_4[(cse_var_1 + 14)] = 0f32
            compute_4[(cse_var_1 + 15)] = 0f32
            compute_4[(cse_var_1 + 48)] = 0f32
            compute_4[(cse_var_1 + 49)] = 0f32
            compute_4[(cse_var_1 + 50)] = 0f32
            compute_4[(cse_var_1 + 51)] = 0f32
            compute_4[(cse_var_1 + 52)] = 0f32
            compute_4[(cse_var_1 + 53)] = 0f32
            compute_4[(cse_var_1 + 54)] = 0f32
            compute_4[(cse_var_1 + 55)] = 0f32
            compute_4[(cse_var_1 + 56)] = 0f32
            compute_4[(cse_var_1 + 57)] = 0f32
            compute_4[(cse_var_1 + 58)] = 0f32
            compute_4[(cse_var_1 + 59)] = 0f32
            compute_4[(cse_var_1 + 60)] = 0f32
            compute_4[(cse_var_1 + 61)] = 0f32
            compute_4[(cse_var_1 + 62)] = 0f32
            compute_4[(cse_var_1 + 63)] = 0f32
            compute_4[(cse_var_1 + 96)] = 0f32
            compute_4[(cse_var_1 + 97)] = 0f32
            compute_4[(cse_var_1 + 98)] = 0f32
            compute_4[(cse_var_1 + 99)] = 0f32
            compute_4[(cse_var_1 + 100)] = 0f32
            compute_4[(cse_var_1 + 101)] = 0f32
            compute_4[(cse_var_1 + 102)] = 0f32
            compute_4[(cse_var_1 + 103)] = 0f32
            compute_4[(cse_var_1 + 104)] = 0f32
            compute_4[(cse_var_1 + 105)] = 0f32
            compute_4[(cse_var_1 + 106)] = 0f32
            compute_4[(cse_var_1 + 107)] = 0f32
            compute_4[(cse_var_1 + 108)] = 0f32
            compute_4[(cse_var_1 + 109)] = 0f32
            compute_4[(cse_var_1 + 110)] = 0f32
            compute_4[(cse_var_1 + 111)] = 0f32
            compute_4[(cse_var_1 + 144)] = 0f32
            compute_4[(cse_var_1 + 145)] = 0f32
            compute_4[(cse_var_1 + 146)] = 0f32
            compute_4[(cse_var_1 + 147)] = 0f32
            compute_4[(cse_var_1 + 148)] = 0f32
            compute_4[(cse_var_1 + 149)] = 0f32
            compute_4[(cse_var_1 + 150)] = 0f32
            compute_4[(cse_var_1 + 151)] = 0f32
            compute_4[(cse_var_1 + 152)] = 0f32
            compute_4[(cse_var_1 + 153)] = 0f32
            compute_4[(cse_var_1 + 154)] = 0f32
            compute_4[(cse_var_1 + 155)] = 0f32
            compute_4[(cse_var_1 + 156)] = 0f32
            compute_4[(cse_var_1 + 157)] = 0f32
            compute_4[(cse_var_1 + 158)] = 0f32
            compute_4[(cse_var_1 + 159)] = 0f32
            compute_4[(cse_var_1 + 192)] = 0f32
            compute_4[(cse_var_1 + 193)] = 0f32
            compute_4[(cse_var_1 + 194)] = 0f32
            compute_4[(cse_var_1 + 195)] = 0f32
            compute_4[(cse_var_1 + 196)] = 0f32
            compute_4[(cse_var_1 + 197)] = 0f32
            compute_4[(cse_var_1 + 198)] = 0f32
            compute_4[(cse_var_1 + 199)] = 0f32
            compute_4[(cse_var_1 + 200)] = 0f32
            compute_4[(cse_var_1 + 201)] = 0f32
            compute_4[(cse_var_1 + 202)] = 0f32
            compute_4[(cse_var_1 + 203)] = 0f32
            compute_4[(cse_var_1 + 204)] = 0f32
            compute_4[(cse_var_1 + 205)] = 0f32
            compute_4[(cse_var_1 + 206)] = 0f32
            compute_4[(cse_var_1 + 207)] = 0f32
            compute_4[(cse_var_1 + 240)] = 0f32
            compute_4[(cse_var_1 + 241)] = 0f32
            compute_4[(cse_var_1 + 242)] = 0f32
            compute_4[(cse_var_1 + 243)] = 0f32
            compute_4[(cse_var_1 + 244)] = 0f32
            compute_4[(cse_var_1 + 245)] = 0f32
            compute_4[(cse_var_1 + 246)] = 0f32
            compute_4[(cse_var_1 + 247)] = 0f32
            compute_4[(cse_var_1 + 248)] = 0f32
            compute_4[(cse_var_1 + 249)] = 0f32
            compute_4[(cse_var_1 + 250)] = 0f32
            compute_4[(cse_var_1 + 251)] = 0f32
            compute_4[(cse_var_1 + 252)] = 0f32
            compute_4[(cse_var_1 + 253)] = 0f32
            compute_4[(cse_var_1 + 254)] = 0f32
            compute_4[(cse_var_1 + 255)] = 0f32
            for (elem_idx: int32, 0, let cse_var_2: int32 = ((floormod(m.outer.n.outer.fused, 16)*3) + nb_j.inner) in (placeholder_12: Buffer(placeholder_11, int32, [49], [])[(cse_var_2 + 1)] - placeholder_12[cse_var_2])) {
              for (i.inner: int32, 0, 6) {
                let cse_var_21: int32 = (elem_idx*256)
                let cse_var_20: int32 = ((floormod(m.outer.n.outer.fused, 16)*3) + nb_j.inner)
                let cse_var_19: int32 = (((i.outer.inner*288) + (i.inner*48)) + (nb_j.inner*16))
                let cse_var_18: int32 = (((floordiv(m.outer.n.outer.fused, 16)*36864) + (i.outer.inner*18432)) + (i.inner*3072))
                let cse_var_17: int32 = (cse_var_19 + 9)
                let cse_var_16: int32 = (cse_var_19 + 8)
                let cse_var_15: int32 = (cse_var_19 + 7)
                let cse_var_14: int32 = (cse_var_19 + 6)
                let cse_var_13: int32 = (cse_var_19 + 5)
                let cse_var_12: int32 = (cse_var_19 + 4)
                let cse_var_11: int32 = (cse_var_19 + 3)
                let cse_var_10: int32 = (cse_var_19 + 2)
                let cse_var_9: int32 = (cse_var_19 + 15)
                let cse_var_8: int32 = (cse_var_19 + 14)
                let cse_var_7: int32 = (cse_var_19 + 13)
                let cse_var_6: int32 = (cse_var_19 + 12)
                let cse_var_5: int32 = (cse_var_19 + 11)
                let cse_var_4: int32 = (cse_var_19 + 10)
                let cse_var_3: int32 = (cse_var_19 + 1)
                 {
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13: Buffer(placeholder_9, float32, [12288], [])[((placeholder_12[cse_var_20]*256) + cse_var_21)]*placeholder_14: Buffer(placeholder_8, float32, [2359296], [])[(cse_var_18 + (placeholder_15: Buffer(placeholder_10, int32, [48], [])[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 1)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 2)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 3)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 4)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 5)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 6)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 7)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 8)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 9)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 10)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 11)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 12)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 13)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 14)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_19] = (compute_4[cse_var_19] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 15)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 16)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 17)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 18)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 19)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 20)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 21)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 22)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 23)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 24)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 25)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 26)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 27)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 28)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 29)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 30)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_3] = (compute_4[cse_var_3] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 31)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 32)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 33)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 34)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 35)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 36)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 37)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 38)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 39)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 40)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 41)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 42)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 43)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 44)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 45)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 46)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_10] = (compute_4[cse_var_10] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 47)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 48)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 49)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 50)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 51)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 52)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 53)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 54)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 55)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 56)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 57)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 58)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 59)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 60)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 61)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 62)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_11] = (compute_4[cse_var_11] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 63)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 64)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 65)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 66)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 67)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 68)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 69)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 70)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 71)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 72)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 73)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 74)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 75)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 76)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 77)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 78)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_12] = (compute_4[cse_var_12] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 79)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 80)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 81)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 82)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 83)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 84)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 85)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 86)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 87)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 88)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 89)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 90)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 91)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 92)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 93)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 94)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_13] = (compute_4[cse_var_13] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 95)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 96)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 97)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 98)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 99)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 100)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 101)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 102)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 103)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 104)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 105)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 106)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 107)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 108)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 109)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 110)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_14] = (compute_4[cse_var_14] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 111)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 112)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 113)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 114)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 115)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 116)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 117)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 118)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 119)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 120)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 121)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 122)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 123)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 124)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 125)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 126)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_15] = (compute_4[cse_var_15] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 127)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 128)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 129)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 130)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 131)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 132)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 133)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 134)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 135)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 136)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 137)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 138)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 139)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 140)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 141)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 142)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_16] = (compute_4[cse_var_16] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 143)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 144)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 145)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 146)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 147)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 148)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 149)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 150)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 151)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 152)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 153)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 154)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 155)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 156)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 157)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 158)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_17] = (compute_4[cse_var_17] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 159)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 160)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 161)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 162)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 163)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 164)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 165)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 166)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 167)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 168)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 169)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 170)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 171)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 172)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 173)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 174)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_4] = (compute_4[cse_var_4] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 175)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 176)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 177)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 178)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 179)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 180)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 181)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 182)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 183)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 184)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 185)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 186)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 187)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 188)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 189)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 190)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_5] = (compute_4[cse_var_5] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 191)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 192)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 193)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 194)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 195)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 196)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 197)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 198)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 199)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 200)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 201)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 202)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 203)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 204)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 205)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 206)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_6] = (compute_4[cse_var_6] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 207)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 208)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 209)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 210)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 211)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 212)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 213)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 214)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 215)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 216)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 217)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 218)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 219)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 220)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 221)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 222)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_7] = (compute_4[cse_var_7] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 223)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 224)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 225)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 226)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 227)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 228)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 229)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 230)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 231)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 232)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 233)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 234)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 235)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 236)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 237)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 238)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_8] = (compute_4[cse_var_8] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 239)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 240)]*placeholder_14[(cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16))]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 241)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 1)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 242)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 2)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 243)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 3)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 244)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 4)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 245)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 5)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 246)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 6)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 247)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 7)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 248)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 8)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 249)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 9)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 250)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 10)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 251)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 11)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 252)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 12)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 253)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 13)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 254)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 14)]))
                  compute_4[cse_var_9] = (compute_4[cse_var_9] + (placeholder_13[(((placeholder_12[cse_var_20]*256) + cse_var_21) + 255)]*placeholder_14[((cse_var_18 + (placeholder_15[(placeholder_12[cse_var_20] + elem_idx)]*16)) + 15)]))
                }
              }
            }
          }
        }
      }
      for (m.inner: int32, 0, 12) {
        compute_5: Buffer(compute_2, float32, [589824], [])[ramp((((floordiv(m.outer.n.outer.fused, 16)*9216) + (m.inner*768)) + (floormod(m.outer.n.outer.fused, 16)*48)), 1, 48)] = compute_4[ramp((m.inner*48), 1, 48)]
      }
    }
  }
}

/home/qxj/.local/lib/python3.8/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)

(768, 768)
(768, 768)
encoder.layer.9.output.dense.weight Execution time of this operator: 0.080 ms
strides_mask: num_row = 4096, num_col = 4096, nnz = 264192
Traceback (most recent call last):
  File "tune_sparse_x86_usages.py", line 288, in <module>
    tune_for_spmm(name, 3072)
  File "tune_sparse_x86_usages.py", line 230, in evaluate_best_record
    BS_R,
  File "/home/qxj/.local/lib/python3.8/site-packages/tvm/auto_scheduler/search_task.py", line 461, in __init__
    register_task_input_buffer(
  File "/home/qxj/.local/lib/python3.8/site-packages/tvm/auto_scheduler/search_task.py", line 313, in register_task_input_buffer
    raise RuntimeError(
RuntimeError: Tensor sparse_dense_bsr_4096_4096_16_16_16512_257_W_data exists in TASK_INPUT_BUFFER_TABLE, set overwrite to True or this Tensor will not be registered
